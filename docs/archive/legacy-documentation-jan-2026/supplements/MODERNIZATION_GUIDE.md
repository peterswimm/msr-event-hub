# Knowledge Agent POC - Modernized Architecture

## ğŸš€ What Changed

This workspace has been **comprehensively modernized** for production-ready agentic development with:

### âœ… Modern Agent Framework
- **Before:** Direct LLM client calls (OpenAI, Azure OpenAI)
- **After:** Microsoft Agent Framework with built-in orchestration
- **Benefits:** Multi-agent workflows, automatic tracing, tool calling, streaming

### âœ… Observability & Tracing
- **New:** Distributed tracing with OpenTelemetry
- **New:** Automatic LLM call telemetry (prompts, tokens, latency)
- **New:** Agent decision logging
- **View traces:** AI Toolkit integration

### âœ… Evaluation Framework
- **New:** Automated evaluation with Azure AI Evaluation SDK
- **New:** Built-in + custom evaluators
- **New:** Test datasets and agent runner
- **New:** Regression testing support

### âœ… Multi-Agent Orchestration
- **New:** Sequential workflows (pipeline pattern)
- **New:** Concurrent workflows (fan-out/fan-in)
- **New:** Group chat workflows (manager-directed)
- **New:** Agent-to-agent handoffs

### âœ… Tool Integration
- **New:** MCP (Model Context Protocol) support
- **New:** Function calling with custom tools
- **New:** OpenAPI integration ready

### âœ… Configuration Management
- **New:** `pyproject.toml` for modern Python packaging
- **New:** Structured settings with validation
- **New:** Environment-specific configs

---

## ğŸ“ New Structure

```
knowledge-agent-poc/
â”œâ”€â”€ config/                    # â­ NEW: Configuration management
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py           # Centralized settings with validation
â”‚
â”œâ”€â”€ observability/            # â­ NEW: Tracing & monitoring
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ tracing.py           # OpenTelemetry setup
â”‚
â”œâ”€â”€ evaluation/               # â­ NEW: Evaluation framework
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ evaluators.py        # Custom evaluators
â”‚   â”œâ”€â”€ runner.py            # Evaluation orchestration
â”‚   â””â”€â”€ datasets.py          # Test dataset utilities
â”‚
â”œâ”€â”€ workflows/                # â­ NEW: Multi-agent patterns
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ sequential_workflow.py    # Pipeline pattern
â”‚   â”œâ”€â”€ concurrent_workflow.py    # Parallel execution
â”‚   â””â”€â”€ group_chat_workflow.py    # Manager-directed
â”‚
â”œâ”€â”€ tools/                    # â­ NEW: Tool integration
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ mcp_tools.py         # Model Context Protocol
â”‚   â””â”€â”€ function_tools.py    # Custom function calling
â”‚
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ modern_base_agent.py # â­ NEW: Agent Framework base
â”‚   â”œâ”€â”€ base_agent.py        # Legacy (for reference)
â”‚   â”œâ”€â”€ paper_agent.py
â”‚   â”œâ”€â”€ talk_agent.py
â”‚   â””â”€â”€ repository_agent.py
â”‚
â”œâ”€â”€ pyproject.toml           # â­ NEW: Modern Python config
â”œâ”€â”€ requirements.txt         # â­ UPDATED: New dependencies
â””â”€â”€ .env                     # â­ UPDATE THIS: New config needed
```

---

## ğŸ”§ Setup Instructions

### 1. Install Dependencies

```bash
# Install with preview flag (Agent Framework is in preview)
pip install --pre -r requirements.txt

# Or use specific package
pip install --pre agent-framework-azure-ai
```

### 2. Configure Environment

Update your `.env` file with new required settings:

```bash
# Microsoft Foundry (Azure AI Foundry) - REQUIRED
FOUNDRY_PROJECT_ENDPOINT=https://your-project.api.azureml.ms
FOUNDRY_MODEL_DEPLOYMENT=gpt-4o

# Legacy Azure OpenAI (optional - for evaluation judge model)
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_KEY=your-key
AZURE_OPENAI_API_VERSION=2024-12-01-preview

# Agent Settings
AGENT_TEMPERATURE=0.3
AGENT_MAX_TOKENS=4096

# Observability
ENABLE_TRACING=true
OTLP_ENDPOINT=http://localhost:4317
ENABLE_SENSITIVE_DATA=true

# Evaluation
EVALUATION_OUTPUT_DIR=./outputs/evaluation
```

### 3. Start Trace Collector (for observability)

**Before running agents with tracing:**

1. Open VS Code Command Palette (`Ctrl+Shift+P` / `Cmd+Shift+P`)
2. Run: **"AI Toolkit: Start Trace Collector"**
3. This starts the OTLP collector at `http://localhost:4317`

**After running agents:**
4. Run: **"AI Toolkit: View Trace"** to visualize traces

---

## ğŸ“š Usage Examples

### Basic Agent (Modern Framework)

```python
import asyncio
from agent_framework import ChatAgent
from agent_framework_azure_ai import AzureAIAgentClient
from azure.identity import DefaultAzureCredential
from config import get_settings
from observability import setup_tracing

async def main():
    # Setup tracing
    setup_tracing()
    
    settings = get_settings()
    
    # Create agent
    agent = ChatAgent(
        chat_client=AzureAIAgentClient(
            project_endpoint=settings.foundry_project_endpoint,
            model_deployment_name=settings.foundry_model_deployment,
            async_credential=DefaultAzureCredential(),
            agent_name="KnowledgeExtractor",
        ),
        instructions="You extract structured knowledge from text."
    )
    
    # Run with streaming
    thread = agent.get_new_thread()
    async for chunk in agent.run_stream("Extract key points from..."):
        if chunk.text:
            print(chunk.text, end='', flush=True)

asyncio.run(main())
```

### Sequential Workflow (Pipeline)

```python
from workflows import create_sequential_workflow

# Create pipeline: Extract â†’ Structure â†’ Validate
workflow = create_sequential_workflow(
    agents=[extractor, structurer, validator],
    workflow_name="extraction_pipeline"
)

# Run pipeline
async for message in workflow.run_stream("Process this paper..."):
    print(message.text)
```

### Concurrent Workflow (Parallel)

```python
from workflows import create_concurrent_workflow

# Multiple perspectives simultaneously
workflow = create_concurrent_workflow(
    agents=[technical_reviewer, domain_expert, user_reviewer],
    workflow_name="parallel_review"
)

async for message in workflow.run_stream("Review this extraction..."):
    print(message.text)
```

### Group Chat (Manager-Directed)

```python
from workflows import create_group_chat_workflow

participants = {
    "researcher": researcher_agent,
    "analyzer": analyzer_agent,
    "synthesizer": synthesizer_agent,
}

workflow = create_group_chat_workflow(
    participants=participants,
    max_rounds=10,
    workflow_name="collaborative_extraction"
)

async for message in workflow.run_stream("Extract knowledge..."):
    print(message.text)
```

### Agent with MCP Tools

```python
from tools import create_mcp_tools, MICROSOFT_LEARN_MCP, GITHUB_MCP

# Add external tool access
mcp_tools = create_mcp_tools([MICROSOFT_LEARN_MCP, GITHUB_MCP])

agent = ChatAgent(
    chat_client=client,
    instructions="You can search docs and analyze repos.",
    tools=mcp_tools  # Agent can now call external tools
)
```

### Agent with Function Tools

```python
from tools import get_text_analysis_tools

# Add custom Python functions
tools = get_text_analysis_tools()  # metadata, citations, code blocks

agent = ChatAgent(
    chat_client=client,
    instructions="You can analyze text structure.",
    tools=tools  # Agent can call Python functions
)
```

### Evaluation

```python
from evaluation import EvaluationRunner, create_test_dataset

# Create test dataset
test_dataset = create_test_dataset(
    test_cases=[
        {"source_text": "...", "expected_title": "..."},
        # more cases...
    ],
    output_path="./evaluation/datasets/test.jsonl"
)

# Run evaluation
runner = EvaluationRunner(agent=my_agent)
results = await runner.run_evaluation(
    test_dataset=test_dataset,
    run_name="paper_extraction_v1"
)

print(f"Avg structure score: {results['metrics']['structure_completeness_score']}")
```

---

## ğŸ”„ Migration from Legacy Code

### Legacy Pattern (OLD)
```python
# Direct LLM client usage
from openai import AzureOpenAI

client = AzureOpenAI(...)
response = client.chat.completions.create(...)
```

### Modern Pattern (NEW)
```python
# Agent Framework
from agent_framework import ChatAgent
from agent_framework_azure_ai import AzureAIAgentClient

agent = ChatAgent(chat_client=AzureAIAgentClient(...))
result = await agent.run("query")  # Automatic tracing, tools, etc.
```

---

## ğŸ¯ Key Benefits

| Feature | Before | After |
|---------|--------|-------|
| **Agent Framework** | âŒ Manual LLM calls | âœ… Standardized agent interface |
| **Tracing** | âŒ None | âœ… Automatic with OpenTelemetry |
| **Multi-Agent** | âŒ Manual coordination | âœ… Built-in patterns (sequential, concurrent, group chat) |
| **Tool Calling** | âŒ Manual | âœ… MCP + function calling support |
| **Evaluation** | âŒ Manual testing | âœ… Automated framework with metrics |
| **Config** | âŒ Scattered .env | âœ… Structured + validated |

---

## ğŸ“– Additional Resources

- **Agent Framework Docs:** [github.com/microsoft/agent-framework](https://github.com/microsoft/agent-framework)
- **Azure AI Evaluation:** [Azure SDK Docs](https://learn.microsoft.com/azure/ai-services/)
- **MCP Protocol:** [modelcontextprotocol.io](https://modelcontextprotocol.io)
- **AI Toolkit:** VS Code extension for tracing & debugging

---

## ğŸš¦ Next Steps

1. **Update .env** with Foundry endpoint and credentials
2. **Install dependencies** with `--pre` flag
3. **Start trace collector** in AI Toolkit
4. **Run example** from `workflows/` to test setup
5. **Create evaluation dataset** for your agents
6. **Explore MCP tools** for external integrations

---

## ğŸ’¡ Tips

- **Always use async/await:** Agent Framework is async-first
- **Stream by default:** Use `run_stream()` for better UX
- **Enable tracing:** View traces in AI Toolkit for debugging
- **Test with evaluation:** Catch regressions early
- **Use workflows:** Don't coordinate manually - use patterns

---

**Your workspace is now optimized for production-ready agentic development! ğŸ‰**
