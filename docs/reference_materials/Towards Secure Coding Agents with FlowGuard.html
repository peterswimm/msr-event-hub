<!DOCTYPE html>
<!-- saved from url=(0055)https://rrs25.azurewebsites.net/projects/RRS25-PROJ-091 -->
<html lang="en" class="dark" data-theme="dark"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover"><title>Towards Secure Coding Agents with FlowGuard</title><link rel="icon" href="https://rrs25.azurewebsites.net/favicon.ico" type="image/x-icon"><link rel="preconnect" href="https://fonts.googleapis.com/"><link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin="anonymous"><link rel="stylesheet" href="./Towards Secure Coding Agents with FlowGuard_files/root-DlQlzowL.css"><link rel="stylesheet" href="./Towards Secure Coding Agents with FlowGuard_files/css2"><script>
              (function() {
                // Load Azure Monitor script asynchronously with error handling
                // This prevents SSL/certificate issues from blocking page load
                const script = document.createElement('script');
                script.type = 'text/javascript';
                script.src = 'https://js.monitor.azure.com/scripts/c/ms.analytics-web-3.min.js';
                script.async = true;
                script.defer = true;
                
                script.onload = function() {
                  try {
                    if (typeof oneDS !== 'undefined' && oneDS.ApplicationInsights) {
                      const analytics = new oneDS.ApplicationInsights();
                      var config = {
                        instrumentationKey: "aa725b41beb74355a0aac6c77857f438-53965fd3-b9d8-45b6-9196-b00bcfa4a001-6890",
                        channelConfiguration: {
                            eventsLimitInMem: 50
                        },
                        propertyConfiguration: {
                          env: "prod"
                        },
                        webAnalyticsConfiguration: {
                          coreData: {
                            appName: "Showcase App",
                            appVersion: "1.0.0",
                            appEnvironment: "production",
                            appPlatform: "web",
                            appLocation: "East US",
                            appTimestamp: new Date().toISOString()
                          },
                          urlCollectionQuery: true,
                          urlCollectionHash: true,
                          autoCapture: {
                            scroll: true,
                            pageView: true,
                            onLoad: true,
                            onUnload: true,
                            click: true,
                            scroll: true,
                            resize: true,
                            jsError: true
                          }
                        }
                      };
                      analytics.initialize(config, []);
                    }
                  } catch (error) {
                    // Silently fail - analytics is not critical for app functionality
                    if (typeof console !== 'undefined' && console.error) {
                      console.error('Azure Monitor initialization failed:', error);
                    }
                  }
                };
                
                script.onerror = function() {
                  // Script failed to load (likely due to network/SSL issues)
                  // This is non-critical, so we silently continue
                  if (typeof console !== 'undefined' && console.warn) {
                    console.warn('Azure Monitor script failed to load - continuing without analytics');
                  }
                };
                
                document.head.appendChild(script);
              })();
            </script><script type="text/javascript" src="https://js.monitor.azure.com/scripts/c/ms.analytics-web-3.min.js" async="" defer=""></script><script>
              window.__ENV_DATA__ = {"isDev":false,"environment":"production","imagesBaseUrl":"https://rrs25content.blob.core.windows.net/prod/images","assetsBaseUrl":"https://rrs25content.blob.core.windows.net/prod/assets"};
            </script><meta name="description" content="Artificial intelligence (AI) coding agents are autonomous software systems that can perform complex tasks like fixing bugs on behalf of a human operator. Coding agents are already capable and rapidly improving. Today’s best agents consistently resolve 70% of the issues on the SWE-Bench benchmark, compared to only 2% when the benchmark was introduced. But despite this promise, researchers have demonstrated numerous prompt-injection attacks that allow an attacker to lead an agent astray through adversarial inputs. For example, an attacker can post a malicious bug report that instructs an agent with access to private repositories to exfiltrate secret data.

FlowGuard is an information flow control (IFC) system for preventing data exfiltration by coding agents and other AI. Unlike prior applications of IFC to AI agents, FlowGuard adopts Flume’s coarse-grained IFC labeling and propagation model, as well as a new spawn primitive that allows an agent to safely create sub-agents. We have implemented a FlowGuard prototype called GitGuard for protecting workflows on GitHub data and will demonstrate how it prevents prompt-injection attacks while also enabling complex coding tasks involving multiple public and private repositories. "></head><body class="overflow-x-hidden" style="background-color: var(--colorNeutralBackground1); color: var(--colorNeutralForeground1); overflow: unset;"><div class="min-h-screen flex flex-col" style="background-color: var(--colorNeutralBackground1);"><header class="sticky top-0 z-50 shadow-sm border-b" style="background-color: var(--colorNeutralBackground1); border-color: var(--colorNeutralStroke1);"><div class="content-max-width-wide"><div class="flex justify-between items-center h-16 min-h-16"><div class="flex items-center"><a class="flex items-center min-w-0" aria-label="Redmond Research Showcase 2025 - Home" href="https://rrs25.azurewebsites.net/" data-discover="true"><div class="w-8 h-8 flex items-center justify-center flex-shrink-0"><svg width="32" height="32" viewBox="0 0 32 32" fill="none" xmlns="http://www.w3.org/2000/svg" class="w-8 h-8" aria-hidden="true"><rect x="1" y="1" width="14" height="14" fill="#F25022"></rect><rect x="17" y="1" width="14" height="14" fill="#7FBA00"></rect><rect x="1" y="17" width="14" height="14" fill="#00A4EF"></rect><rect x="17" y="17" width="14" height="14" fill="#FFB900"></rect></svg></div></a></div><div class="hidden md:flex flex-1 max-w-lg mx-4 lg:mx-8"><form class="w-full"><input placeholder="Search projects..." class="input-base px-3 w-full" type="text" value=""></form></div><div class="hidden md:flex items-center space-x-4"><nav class="flex space-x-1"><a class="flex items-center px-3 py-2 rounded-lg text-sm font-medium transition-colors m-1 whitespace-nowrap" href="https://rrs25.azurewebsites.net/" data-discover="true" style="background-color: transparent; color: var(--colorNeutralForeground1); outline: none;"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-house w-4 h-4 mr-2" aria-hidden="true"><path d="M15 21v-8a1 1 0 0 0-1-1h-4a1 1 0 0 0-1 1v8"></path><path d="M3 10a2 2 0 0 1 .709-1.528l7-6a2 2 0 0 1 2.582 0l7 6A2 2 0 0 1 21 10v9a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"></path></svg>Home</a><a class="flex items-center px-3 py-2 rounded-lg text-sm font-medium transition-colors m-1 whitespace-nowrap" href="https://rrs25.azurewebsites.net/projects" data-discover="true" style="background-color: transparent; color: var(--colorNeutralForeground1); outline: none;"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-layout-grid w-4 h-4 mr-2" aria-hidden="true"><rect width="7" height="7" x="3" y="3" rx="1"></rect><rect width="7" height="7" x="14" y="3" rx="1"></rect><rect width="7" height="7" x="14" y="14" rx="1"></rect><rect width="7" height="7" x="3" y="14" rx="1"></rect></svg>Projects</a><a class="flex items-center px-3 py-2 rounded-lg text-sm font-medium transition-colors m-1 whitespace-nowrap" href="https://rrs25.azurewebsites.net/agenda" data-discover="true" style="background-color: transparent; color: var(--colorNeutralForeground1); outline: none;"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-calendar w-4 h-4 mr-2" aria-hidden="true"><path d="M8 2v4"></path><path d="M16 2v4"></path><rect width="18" height="18" x="3" y="4" rx="2"></rect><path d="M3 10h18"></path></svg>Agenda</a><a class="flex items-center px-3 py-2 rounded-lg text-sm font-medium transition-colors m-1 whitespace-nowrap" href="https://rrs25.azurewebsites.net/bookmarks" data-discover="true" style="background-color: transparent; color: var(--colorNeutralForeground1); outline: none;"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-bookmark w-4 h-4 mr-2" aria-hidden="true"><path d="m19 21-7-4-7 4V5a2 2 0 0 1 2-2h10a2 2 0 0 1 2 2v16z"></path></svg>Bookmarks</a></nav><div class="flex items-center space-x-4"><button class="p-2 rounded-lg transition-colors cursor-pointer m-1" title="Switch to high contrast mode" aria-label="Switch to high contrast mode" style="color: var(--colorNeutralForeground1); background-color: transparent;"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-sun w-5 h-5" aria-hidden="true"><circle cx="12" cy="12" r="4"></circle><path d="M12 2v2"></path><path d="M12 20v2"></path><path d="m4.93 4.93 1.41 1.41"></path><path d="m17.66 17.66 1.41 1.41"></path><path d="M2 12h2"></path><path d="M20 12h2"></path><path d="m6.34 17.66-1.41 1.41"></path><path d="m19.07 4.93-1.41 1.41"></path></svg></button><a class="flex items-center p-2 rounded-lg transition-colors" href="https://rrs25.azurewebsites.net/profile" data-discover="true" style="background-color: transparent; cursor: pointer;"><div class="w-8 h-8 bg-blue-600 text-white rounded-full flex items-center justify-center text-sm font-medium flex-shrink-0">PS</div></a></div></div><div class="md:hidden"><button class="inline-flex items-center justify-center p-2 rounded-lg transition-colors m-1 cursor-pointer" style="background-color: transparent; color: var(--colorNeutralForeground1);"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-menu w-6 h-6" aria-hidden="true"><path d="M4 5h16"></path><path d="M4 12h16"></path><path d="M4 19h16"></path></svg></button></div></div><div class="md:hidden pb-4 w-full"><form class="w-full"><input placeholder="Search projects..." class="input-base px-3 w-full" type="text" value=""></form></div></div></header><main class="flex-grow"><div class="min-h-screen" style="background-color: var(--colorNeutralBackground1);"><main class="content-max-width-wide" style="padding-top: var(--spacingVerticalL); padding-bottom: var(--spacingVerticalL);"><div class="mb-6"><nav class="flex items-center space-x-1 text-sm " aria-label="Breadcrumb" style="color: var(--colorNeutralForeground3);"><div class="flex items-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-house w-4 h-4 mr-1" aria-hidden="true"><path d="M15 21v-8a1 1 0 0 0-1-1h-4a1 1 0 0 0-1 1v8"></path><path d="M3 10a2 2 0 0 1 .709-1.528l7-6a2 2 0 0 1 2.582 0l7 6A2 2 0 0 1 21 10v9a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"></path></svg><a class="transition-colors duration-200" href="https://rrs25.azurewebsites.net/" data-discover="true" style="color: var(--colorNeutralForeground3);">Home</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right w-4 h-4 mx-2" aria-hidden="true" style="color: var(--colorNeutralForeground3);"><path d="m9 18 6-6-6-6"></path></svg></div><div class="flex items-center"><a class="transition-colors duration-200" href="https://rrs25.azurewebsites.net/projects" data-discover="true" style="color: var(--colorNeutralForeground3);">Projects</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right w-4 h-4 mx-2" aria-hidden="true" style="color: var(--colorNeutralForeground3);"><path d="m9 18 6-6-6-6"></path></svg></div><div class="flex items-center"><span class="font-medium" style="color: var(--colorNeutralForeground1);">Towards Secure Coding Agents with FlowGuard</span></div></nav></div><div class="grid grid-cols-1 lg:grid-cols-3 gap-8"><div class="lg:col-span-2"><div class="mb-8 relative"><div class="w-full rounded-lg shadow-lg overflow-hidden video-embed" style="aspect-ratio: 16 / 9; background-color: var(--colorNeutralBackground2);"><iframe src="./Towards Secure Coding Agents with FlowGuard_files/embed.html" width="640" height="360" frameborder="0" scrolling="no" allowfullscreen="" title="flowguard-demo.mp4"></iframe></div></div><div class="mb-6"><h1 class="text-4xl font-bold mb-2" style="color: var(--colorNeutralForeground1);">Towards Secure Coding Agents with FlowGuard</h1><div class="flex items-center gap-2 text-sm mb-4" style="color: var(--colorNeutralForeground3);"><span>Project ID: RRS25-PROJ-091</span><button class="flex items-center justify-center w-5 h-5 rounded hover:bg-gray-100 dark:hover:bg-gray-700 transition-colors cursor-pointer" title="Copy project ID"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-copy w-3 h-3" aria-hidden="true"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div></div><div class="mb-8"><h2 class="text-2xl font-semibold mb-4" style="color: var(--colorNeutralForeground1);">Team Members</h2><div class="flex flex-wrap gap-3"><button class="flex items-center gap-2 px-3 py-2 rounded-lg border transition-all duration-200 hover:shadow-md cursor-pointer" style="background-color: var(--colorNeutralBackground2); border-color: var(--colorNeutralStroke1); color: var(--colorNeutralForeground1);"><div class="inline-flex items-center justify-center rounded-full font-medium text-white w-6 h-6 text-xs " style="background-color: rgb(236, 72, 153); font-size: 10px;">LC</div><span class="text-sm font-medium">Landon Cox</span></button><button class="flex items-center gap-2 px-3 py-2 rounded-lg border transition-all duration-200 hover:shadow-md cursor-pointer" style="background-color: var(--colorNeutralBackground2); border-color: var(--colorNeutralStroke1); color: var(--colorNeutralForeground1);"><div class="inline-flex items-center justify-center rounded-full font-medium text-white w-6 h-6 text-xs " style="background-color: rgb(99, 102, 241); font-size: 10px;">PH</div><span class="text-sm font-medium">Pedro Henrique Penna</span></button><button class="flex items-center gap-2 px-3 py-2 rounded-lg border transition-all duration-200 hover:shadow-md cursor-pointer" style="background-color: var(--colorNeutralBackground2); border-color: var(--colorNeutralStroke1); color: var(--colorNeutralForeground1);"><div class="inline-flex items-center justify-center rounded-full font-medium text-white w-6 h-6 text-xs " style="background-color: rgb(99, 102, 241); font-size: 10px;">RF</div><span class="text-sm font-medium">Rodrigo Fonseca</span></button><button class="flex items-center gap-2 px-3 py-2 rounded-lg border transition-all duration-200 hover:shadow-md cursor-pointer" style="background-color: var(--colorNeutralBackground2); border-color: var(--colorNeutralStroke1); color: var(--colorNeutralForeground1);"><div class="inline-flex items-center justify-center rounded-full font-medium text-white w-6 h-6 text-xs " style="background-color: rgb(59, 130, 246); font-size: 10px;">XF</div><span class="text-sm font-medium">Xenofon Foukas</span></button></div></div><div class="mb-8"><h2 class="text-2xl font-semibold mb-4" style="color: var(--colorNeutralForeground1);">Location <span class="text-sm font-normal">(<a href="https://rrs25.azurewebsites.net/assets/RRS25-Floor-Map.pdf" target="_blank" rel="noopener noreferrer" class="underline" style="color: var(--colorBrandForeground);">map of the showcase</a>)</span></h2><div class="grid grid-cols-2 gap-4"><div class="flex items-center gap-2"><span class="text-sm font-medium" style="color: var(--colorNeutralForeground2);">Building:</span><span class="text-sm" style="color: var(--colorNeutralForeground1);">99</span></div><div class="flex items-center gap-2"><span class="text-sm font-medium" style="color: var(--colorNeutralForeground2);">Floor:</span><span class="text-sm" style="color: var(--colorNeutralForeground1);">1st Floor</span></div><div class="flex items-center gap-2"><span class="text-sm font-medium" style="color: var(--colorNeutralForeground2);">Room:</span><span class="text-sm" style="color: var(--colorNeutralForeground1);">1919</span></div></div></div><div class="mb-8"><h2 class="text-2xl font-semibold mb-4" style="color: var(--colorNeutralForeground1);">About This Project</h2><p class="leading-relaxed" style="color: var(--colorNeutralForeground1);">Artificial intelligence (AI) coding agents are autonomous software systems that can perform complex tasks like fixing bugs on behalf of a human operator. Coding agents are already capable and rapidly improving. Today’s best agents consistently resolve 70% of the issues on the SWE-Bench benchmark, compared to only 2% when the benchmark was introduced. But despite this promise, researchers have demonstrated numerous prompt-injection attacks that allow an attacker to lead an agent astray through adversarial inputs. For example, an attacker can post a malicious bug report that instructs an agent with access to private repositories to exfiltrate secret data.

FlowGuard is an information flow control (IFC) system for preventing data exfiltration by coding agents and other AI. Unlike prior applications of IFC to AI agents, FlowGuard adopts Flume’s coarse-grained IFC labeling and propagation model, as well as a new spawn primitive that allows an agent to safely create sub-agents. We have implemented a FlowGuard prototype called GitGuard for protecting workflows on GitHub data and will demonstrate how it prevents prompt-injection attacks while also enabling complex coding tasks involving multiple public and private repositories. </p></div></div><div class="lg:col-span-1"><div class="rounded-lg shadow-sm border p-6 mb-6" style="background-color: var(--colorNeutralBackground1); border-color: var(--colorNeutralStroke1);"><h3 class="text-lg font-semibold mb-4" style="color: var(--colorNeutralForeground1);">Project Info</h3><div class="space-y-4"><div><span class="text-sm" style="color: var(--colorNeutralForeground3);">Research Theme</span><div class="mt-2"><a class="inline-flex items-center gap-2 px-3 py-2 rounded-lg font-medium transition-colors cursor-pointer" href="https://rrs25.azurewebsites.net/projects?theme=Security%2C%20Privacy%20%26%20Cryptography" data-discover="true" style="background-color: rgba(215, 60, 60, 0.19); color: rgb(255, 255, 255); border: 1px solid rgba(215, 60, 60, 0.25); text-decoration: none; font-weight: 600;"><svg width="24" height="24" viewBox="0 0 96 96" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" overflow="hidden" class="w-6 h-6" style="color: rgb(255, 255, 255);"><g transform="translate(-871 -77)" fill="currentColor"><path d="M921 146.2 921 151.5 917 151.5 917 146.2C914.7 145.4 913 143.2 913 140.5 913 137.2 915.7 134.5 919 134.5 922.3 134.5 925 137.2 925 140.5 925 143.1 923.3 145.3 921 146.2ZM904 109.5C904 101.2 910.7 94.5 919 94.5 927.3 94.5 934 101.2 934 109.5L934 120.6 919 119.5 904 120.6 904 109.5ZM940 121 940 109.5C940 97.9 930.6 88.5 919 88.5 907.4 88.5 898 97.9 898 109.5L898 121 891 121.5 891 159.5 919 161.5 947 159.5 947 121.5 940 121Z"></path></g></svg><span class="text-sm">Security, Privacy &amp; Cryptography</span></a></div></div></div></div><div class="rounded-lg shadow-sm border p-6 mb-6" style="background-color: var(--colorNeutralBackground1); border-color: var(--colorNeutralStroke1);"><h3 class="text-lg font-semibold mb-4" style="color: var(--colorNeutralForeground1);">Links</h3><div class="flex flex-wrap gap-2"><a href="https://microsoft-my.sharepoint.com/:p:/p/lacox/IQDd4WmpS8HIQZaq8fiUYDTjAaC3YPD65OdO9mPKSuqCqUg?e=kwwhdP&amp;xsdata=MDV8MDJ8di1icmVucG90dHNAbWljcm9zb2Z0LmNvbXwyMmY4OGU3ZWZlZjA0MDc0ZTE1ZjA4ZGUxNjMzODY5YXw3MmY5ODhiZjg2ZjE0MWFmOTFhYjJkN2NkMDExZGI0N3wxfDB8NjM4OTcyNjA3NzA4MTU5MzI5fFVua25vd258VFdGcGJHWnNiM2Q4ZXlKRmJYQjBlVTFoY0draU9uUnlkV1VzSWxZaU9pSXdMakF1TURBd01DSXNJbEFpT2lKWGFXNHpNaUlzSWtGT0lqb2lUV0ZwYkNJc0lsZFVJam95ZlE9PXwwfHx8&amp;sdata=Y0JmZW5jdytrWTJ1ZFZQd0k3ei84VEUvcWFJd1lRR3hSUjVYTVo5Y3NUVT0%3d" target="_blank" rel="noopener noreferrer" class="flex items-center gap-2 px-3 py-2 rounded-lg font-medium transition-colors cursor-pointer text-sm" title="Presentation" style="background-color: var(--colorNeutralBackground2); color: var(--colorNeutralForeground1); border: 1px solid var(--colorNeutralStroke1); text-decoration: none;"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-presentation w-4 h-4" aria-hidden="true"><path d="M2 3h20"></path><path d="M21 3v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V3"></path><path d="m7 21 5-5 5 5"></path></svg><span class="truncate max-w-24">Presentation</span></a><a href="https://microsoft-my.sharepoint.com/personal/lacox_microsoft_com/_layouts/15/embed.aspx?UniqueId=f65944c5-6e91-445d-9754-eabbec1a8b28&amp;embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D&amp;referrer=StreamWebApp&amp;referrerScenario=EmbedDialog.Create" target="_blank" rel="noopener noreferrer" class="flex items-center gap-2 px-3 py-2 rounded-lg font-medium transition-colors cursor-pointer text-sm" title="Video: Project Overview" style="background-color: var(--colorNeutralBackground2); color: var(--colorNeutralForeground1); border: 1px solid var(--colorNeutralStroke1); text-decoration: none;"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-video w-4 h-4" aria-hidden="true"><path d="m16 13 5.223 3.482a.5.5 0 0 0 .777-.416V7.87a.5.5 0 0 0-.752-.432L16 10.5"></path><rect x="2" y="6" width="14" height="12" rx="2"></rect></svg><span class="truncate max-w-24">Video: Project Overview</span></a><a href="https://rrs25.azurewebsites.net/api/proxy/assets/assets/RRS25-PROJ-091.pdf" target="_blank" rel="noopener noreferrer" class="flex items-center gap-3 w-full px-4 py-3 rounded-lg font-medium transition-colors cursor-pointer" style="background-color: var(--colorPaletteBlueBackground); color: var(--colorPaletteBlueForeground1); border: 1px solid var(--colorPaletteBlueBorder); text-decoration: none;"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-download w-5 h-5" aria-hidden="true"><path d="M12 15V3"></path><path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"></path><path d="m7 10 5 5 5-5"></path></svg>Download Poster</a></div></div><div class="rounded-lg shadow-sm border p-6" style="background-color: var(--colorNeutralBackground1); border-color: var(--colorNeutralStroke1);"><h3 class="text-lg font-semibold mb-4" style="color: var(--colorNeutralForeground1);">Actions</h3><div class="space-y-3"><button class="flex items-center gap-3 w-full px-4 py-3 rounded-lg font-medium transition-colors cursor-pointer disabled:cursor-not-allowed" style="background-color: transparent; color: var(--colorNeutralForeground1); border: 1px solid var(--colorNeutralStroke1);"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-bookmark-check w-5 h-5" aria-hidden="true"><path d="m19 21-7-4-7 4V5a2 2 0 0 1 2-2h10a2 2 0 0 1 2 2Z"></path><path d="m9 10 2 2 4-4"></path></svg>Bookmark Project</button><button class="flex items-center gap-3 w-full px-4 py-3 rounded-lg font-medium transition-colors cursor-pointer" style="background-color: transparent; color: var(--colorNeutralForeground1); border: 1px solid var(--colorNeutralStroke1);"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-mail w-5 h-5" aria-hidden="true"><path d="m22 7-8.991 5.727a2 2 0 0 1-2.009 0L2 7"></path><rect x="2" y="4" width="20" height="16" rx="2"></rect></svg>Contact Project Team</button></div></div></div></div></main></div></main><footer style="background-color: var(--colorNeutralBackground2); border-top: 1px solid var(--colorNeutralStroke1);"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8"><div><div class="flex flex-col sm:flex-row justify-between items-center"><div class="text-sm mb-4 sm:mb-0" style="color: var(--colorNeutralForeground2);"><p>Microsoft Research Showcase 2025</p><p class="mt-1">Redmond, Washington</p></div><div class="flex flex-wrap gap-4 sm:gap-6"><a rel="noopener noreferrer" class="text-sm transition-colors" href="https://www.microsoft.com/en-us/privacy/data-privacy-notice" target="_blank" style="color: var(--colorNeutralForeground2);">Data Privacy Notice</a><a class="text-sm transition-colors" href="mailto:mcrinfo@microsoft.com" style="color: var(--colorNeutralForeground2);">Feedback / Opt-out Request</a><button class="text-sm transition-colors cursor-pointer" style="color: var(--colorNeutralForeground2);">Microsoft Event Code of Conduct</button></div></div></div></div></footer></div><script>((u,h)=>{if(!window.history.state||!window.history.state.key){let f=Math.random().toString(32).slice(2);window.history.replaceState({key:f},"")}try{let p=JSON.parse(sessionStorage.getItem(u)||"{}")[h||window.history.state.key];typeof p=="number"&&window.scrollTo(0,p)}catch(f){console.error(f),sessionStorage.removeItem(u)}})("react-router-scroll-positions", null)</script><!--$--><script>window.__reactRouterContext.streamController.enqueue("[{\"_1\":2,\"_2919\":-5,\"_2920\":-5},\"loaderData\",{\"_3\":4,\"_13\":14},\"root\",{\"_5\":6,\"_7\":8,\"_9\":10,\"_11\":12},\"isDev\",false,\"environment\",\"production\",\"imagesBaseUrl\",\"https://rrs25content.blob.core.windows.net/prod/images\",\"assetsBaseUrl\",\"https://rrs25content.blob.core.windows.net/prod/assets\",\"routes/home\",{\"_15\":16},\"projects\",[17,70,103,151,182,219,244,293,322,341,402,424,452,472,516,554,580,614,630,651,707,732,802,833,884,907,937,960,1001,1013,1029,1069,1104,1130,1143,1192,1214,1237,1269,1291,1312,1331,1352,1383,1483,1514,1529,1553,1582,1598,1629,1643,1662,1720,1738,1758,1781,1878,1912,1944,1972,1986,2017,2040,2055,2079,2099,2131,2154,2167,2209,2251,2272,2292,2311,2326,2357,2424,2442,2463,2486,2499,2520,2535,2569,2587,2605,2619,2640,2656,2674,2694,2718,2741,2758,2771,2798,2817,2830,2850,2868,2883,2900],{\"_18\":19,\"_20\":21,\"_22\":23,\"_24\":25,\"_26\":27,\"_28\":29,\"_43\":44,\"_48\":49,\"_50\":51,\"_52\":53,\"_62\":63,\"_64\":65,\"_66\":67,\"_68\":69},\"id\",\"RRS25-PROJ-105\",\"title\",\"ACON: Optimizing Context Compression for Long-horizon LLM Agents\",\"description\",\"Large language models (LLMs) are increasingly deployed as agents in dynamic, real-world environments, where success requires both reasoning and effective tool use. A central challenge for agentic tasks is the growing context length, as agents must accumulate long histories of actions and observations. This expansion raises costs and reduces efficiency in long-horizon tasks, yet prior work on context compression has mostly focused on single-step tasks or narrow applications.\\n\\nWe introduce Agent Context Optimization (ACON), a unified framework that optimally compresses both environment observations and interaction histories into concise yet informative condensations. ACON leverages compression guideline optimization in natural language space: given paired trajectories where full context succeeds but compressed context fails, capable LLMs analyze the causes of failure, and the compression guideline is updated accordingly. Furthermore, we propose distilling the optimized LLM compressor into smaller models to reduce the overhead of the additional module. Experiments on AppWorld, OfficeBench, and Multi-objective QA show that ACON reduces memory usage by 26-54% (peak tokens) while largely preserving task performance, preserves over 95% of accuracy when distilled into smaller compressors, and enhances smaller LMs as long-horizon agents with up to 46% performance improvement.\",\"theme\",\"AI Agents (Interactive, Embodied, Devices)\",\"videoIframe\",\"\",\"teamMembers\",[30,37],{\"_31\":32,\"_33\":34,\"_35\":36},\"alias\",\"weiningchen\",\"displayName\",\"Wei-Ning Chen\",\"email\",\"weiningchen@microsoft.com\",{\"_31\":38,\"_33\":39,\"_35\":40,\"_41\":42},\"rsim\",\"Robert Sim\",\"rsim@microsoft.com\",\"contact\",true,\"tags\",[45,46,47],\"Optimization\",\"Memory\",\"Retrieval\",\"createdAt\",\"2025-10-29T23:26:30.102067+00:00\",\"updatedAt\",\"2025-10-30T19:21:52.607Z\",\"links\",[54,59],{\"_55\":56,\"_57\":58,\"_20\":27},\"type\",\"Paper\",\"url\",\"https://arxiv.org/abs/2510.00615\",{\"_55\":60,\"_57\":61,\"_20\":27},\"Repo\",\"https://github.com/microsoft/acon\",\"qa\",[],\"building\",\"Building 99\",\"floor\",\"1st Floor\",\"room\",\"Atrium\",{\"_18\":71,\"_20\":72,\"_22\":73,\"_24\":25,\"_26\":27,\"_28\":74,\"_43\":95,\"_48\":97,\"_50\":98,\"_52\":99,\"_62\":100,\"_64\":101,\"_66\":67,\"_68\":102},\"RRS25-PROJ-004\",\"AI for Racing: Using Human-like AI to Coach Humans\",\"We use diverse human data to train human-like AI that can race at any skill level (e.g., top 1%) and style (e.g., how you drive), and provide humans with individualized coaching, partnering, and competition.\",[75,79,83,87,91],{\"_31\":76,\"_33\":77,\"_35\":78},\"adamile\",\"Adam Miles\",\"adamile@microsoft.com\",{\"_31\":80,\"_33\":81,\"_35\":82},\"jcl\",\"John Langford\",\"jcl@microsoft.com\",{\"_31\":84,\"_33\":85,\"_35\":86},\"v-naomi\",\"Nabil Omi (POPULUS GROUP LLC)\",\"v-naomi@microsoft.com\",{\"_31\":88,\"_33\":89,\"_35\":90},\"raaboulh\",\"Rafah Hosn\",\"raaboulh@microsoft.com\",{\"_31\":92,\"_33\":93,\"_35\":94,\"_41\":42},\"sidsen\",\"Siddhartha Sen\",\"sidsen@microsoft.com\",[96],\"AI Agents\",\"2025-10-30T14:13:53.277Z\",\"2025-10-30T22:37:54.092Z\",[],[],\"99\",\"1919\",{\"_18\":104,\"_20\":105,\"_22\":106,\"_24\":107,\"_26\":27,\"_28\":108,\"_43\":145,\"_48\":49,\"_50\":146,\"_52\":147,\"_62\":148,\"_64\":101,\"_66\":149,\"_68\":150},\"RRS25-PROJ-020\",\"Accelerating the Drug Discovery Pipeline with AI \",\"The process of drug discovery is a vast and complex pipeline, with target identification (determining which genes/molecules to target) on one end and lead identification (finding molecular leads to address those targets) on the other. On our team, we are using AI in various forms to accelerate all parts of this process. On the target identification side, we are leveraging agentic approaches to connect a wide variety of known information sources about genes and diseases to generate new hypotheses of potential causal genes/molecules (targets). On the lead identification side, we are mining bacterial and fungal genomes for hypothetical therapeutics with genomic large language models. Finally, to connect the two sides together, we are working with high bandwidth assays to test large numbers of compounds against large numbers of genes to prioritize potential lead-target interactions for further investigation. Our vision is that these technologies will work in concert to greatly accelerate the rate at which we can discover new therapeutics for improving human health. \",\"AI for Health, Work \u0026 Society\",[109,113,117,121,125,129,133,137,141],{\"_31\":110,\"_33\":111,\"_35\":112},\"ssaponas\",\"Scott Saponas (HE/HIM)\",\"ssaponas@microsoft.com\",{\"_31\":114,\"_33\":115,\"_35\":116},\"ropau\",\"Ron Paulsen (He/Him)\",\"ropau@microsoft.com\",{\"_31\":118,\"_33\":119,\"_35\":120},\"hopetw\",\"Hope Twede\",\"hopetw@microsoft.com\",{\"_31\":122,\"_33\":123,\"_35\":124},\"gabe\",\"Gabe Cohn\",\"gabe@microsoft.com\",{\"_31\":126,\"_33\":127,\"_35\":128},\"miah\",\"Miah Wander (HE/HIM)\",\"miah@microsoft.com\",{\"_31\":130,\"_33\":131,\"_35\":132},\"ashleyconard\",\"Ashley Conard\",\"ashleyconard@microsoft.com\",{\"_31\":134,\"_33\":135,\"_35\":136},\"gregsmi\",\"Greg Smith (FOX)\",\"gregsmi@microsoft.com\",{\"_31\":138,\"_33\":139,\"_35\":140},\"jlester\",\"Jonathan Lester\",\"jlester@microsoft.com\",{\"_31\":142,\"_33\":143,\"_35\":144,\"_41\":42},\"sumitb\",\"Sumit Basu\",\"sumitb@microsoft.com\",[],\"2025-11-01T02:54:31.065Z\",[],[],\"3rd Floor\",\"Hallway\",{\"_18\":152,\"_20\":153,\"_22\":154,\"_24\":25,\"_26\":155,\"_28\":156,\"_43\":177,\"_48\":178,\"_50\":179,\"_52\":180,\"_62\":181,\"_64\":101,\"_66\":67,\"_68\":102},\"RRS25-PROJ-001\",\"Action Engine\",\"Action Engine is an AI-driven system designed to perform complex tasks on existing apps and websites using natural language instructions. Action Engine uses \\\"Action Index\\\" which is a structured representation of possible actions on a given website or app, enabling the system to plan and execute tasks efficiently.\",\"\u003ciframe src=\\\"https://microsoft.sharepoint.com/teams/MSRNVA01/_layouts/15/embed.aspx?UniqueId=4a4ee020-d28b-4f09-8daf-67c389e12fbb\u0026embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D\u0026referrer=StreamWebApp\u0026referrerScenario=EmbedDialog.Create\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" allowfullscreen title=\\\"58407.mp4\\\" style=\\\"border:none; position: absolute; top: 0; left: 0; right: 0; bottom: 0; height: 100%; max-width: 100%;\\\"\u003e\u003c/iframe\u003e\",[157,161,165,169,173],{\"_31\":158,\"_33\":159,\"_35\":160},\"fafaisal\",\"Fazle Faisal\",\"fafaisal@microsoft.com\",{\"_31\":162,\"_33\":163,\"_35\":164},\"lamorimfranc\",\"Luis França\",\"lamorimfranc@microsoft.com\",{\"_31\":166,\"_33\":167,\"_35\":168},\"qiq\",\"Qianqian Qi\",\"qiq@microsoft.com\",{\"_31\":170,\"_33\":171,\"_35\":172},\"sumann\",\"Suman Nath\",\"sumann@microsoft.com\",{\"_31\":174,\"_33\":175,\"_35\":176,\"_41\":42},\"taleesat\",\"Tanakorn Leesatapornwongsa (He/Him)\",\"taleesat@microsoft.com\",[96],\"2025-10-30T14:13:52.908Z\",\"2025-10-30T22:35:41.056Z\",[],[],{\"_18\":183,\"_20\":184,\"_22\":185,\"_24\":186,\"_26\":27,\"_28\":187,\"_43\":212,\"_48\":214,\"_50\":215,\"_52\":216,\"_62\":217,\"_64\":101,\"_66\":67,\"_68\":218},\"RRS25-PROJ-071\",\"Adaptive Scheduler for LLM Inference Request Routing and Migration\",\"Current LLM inference workloads include tool usage (with system prompts), multi-turn conversations, and application-specific user level prompts. LLM inference workloads are characterized by unpredictability of request processing time both due to dynamic response lengths and due to the KV cache state that could be reused across requests. Reusing the KV cache for previously seen prompts avoids recomputing the KV cache, thereby providing better performance. The potential KV cache reuse over requests is affected by how long the KV cache can stay in the GPU memory before being evicted by incoming requests. To meet the guarantees of SLA attainment of such workloads coupled with unpredictable arrival rates, current pools are typically over-provisioned with multiple replicas serving the same model. This may lead to resource-underutilization. Prior pool-level schedulers assume a static prioritization of KV-cache-hit versus load balancing. Prioritizing KV-cache-hit over load balancing may hurt tail latency. In this project, we build a pool-level scheduler that dynamically adapts based on the current workload and resource characteristics while ensuring SLA attainment, high throughput, and/or low energy usage. We also eagerly offload the KV cache to a memory server shared among replicas, which enables novel performance optimizations including migrating failed requests to new serving replicas with minimal disruption.\",\"Inference 2030\",[188,192,196,200,204,208],{\"_31\":189,\"_33\":190,\"_35\":191},\"aashakashah\",\"Aashaka Shah\",\"aashakashah@microsoft.com\",{\"_31\":193,\"_33\":194,\"_35\":195},\"ajangda\",\"Abhinav Jangda\",\"ajangda@microsoft.com\",{\"_31\":197,\"_33\":198,\"_35\":199},\"burcucanakci\",\"Burcu Canakci\",\"burcucanakci@microsoft.com\",{\"_31\":201,\"_41\":42,\"_33\":202,\"_35\":203},\"rdathathri\",\"Roshan Dathathri\",\"rdathathri@microsoft.com\",{\"_31\":205,\"_33\":206,\"_35\":207},\"samehe\",\"Sameh Elnikety\",\"samehe@microsoft.com\",{\"_31\":209,\"_33\":210,\"_35\":211},\"dnarayan\",\"Dushyanth Narayanan\",\"dnarayan@microsoft.com\",[213],\"LLM workloads\",\"2025-10-30T14:13:52.979Z\",\"2025-10-31T23:20:23.178Z\",[],[],\"1505\",{\"_18\":220,\"_20\":221,\"_22\":222,\"_24\":107,\"_26\":27,\"_28\":223,\"_43\":236,\"_48\":239,\"_50\":240,\"_52\":241,\"_62\":242,\"_64\":101,\"_66\":149,\"_68\":243},\"RRS25-PROJ-021\",\"Aether Psi Working Group: Identifying and Addressing Psychological Influences of AI\",\"The Aether Working Group on the Psychological Influences of AI (Psi WG) was formed to investigate the psychological impacts of AI on the human psyche, both individually and collectively. Psychological influences of AI span emotional, cognitive, and behavioral realms, including effects of interactions with AI systems on mood, relationships, self-concept, agency, and overall well-being. Topics include seeking better understandings of trust, reliance, and dependencies on AI systems as well as their impact on attention, perception, memory, judgment, and decision making.  \\n\\nThis working group is a cross-company v-team, bringing together stakeholders from research, product, and policy and legal together. We aim to cover our progress so far which includes 1) mapping out the risk surface of psychological risks of AI, 2) lessons learned based on our red teaming of AI models and systems for psychological risks, 3) our research on understanding dependency on AI , 4) Our research on understanding how and why people form special relationships with AI, 5) Our approach on translating research to actionable policy, and 6) challenges and paths forward to address these risks.\",[224,228,232],{\"_31\":225,\"_33\":226,\"_35\":227},\"fpoursabzi\",\"Forough Poursabzi\",\"fpoursabzi@microsoft.com\",{\"_31\":229,\"_33\":230,\"_35\":231,\"_41\":42},\"jinsuh\",\"Jina Suh\",\"jinsuh@microsoft.com\",{\"_31\":233,\"_33\":234,\"_35\":235},\"mivorvor\",\"Mihaela Vorvoreanu (she/her)\",\"mivorvor@microsoft.com\",[237,238],\"Healthcare\",\"Medical\",\"2025-10-30T14:13:53.037Z\",\"2025-10-30T22:46:00.518Z\",[],[],\"3046\",{\"_18\":245,\"_20\":246,\"_22\":247,\"_24\":248,\"_26\":249,\"_28\":250,\"_43\":263,\"_48\":264,\"_50\":265,\"_52\":266,\"_62\":291,\"_64\":101,\"_66\":67,\"_68\":292},\"RRS25-PROJ-084\",\"Agentic Engineering\",\"Agentic Engineering is an emerging field focused on the creation and application of robust, secure agent-based workflows to solve complex, multi-step problems with minimal human intervention. This discipline brings together advances in AI, software engineering, and systems design to enable agents that can reason, plan, and execute tasks across diverse domains. \\n\\nKey research areas include: Extracting and validating user intent; building hybrid workflows that combine agentic and traditional code; ensuring security, privacy, and explainability throughout the process; and managing increasingly scaled AI-driven workflows with minimal human intervention.\\n\\nFlagship projects under the Agentic Engineering umbrella include: Agentic Workflows, which orchestrates agents using GitHub Actions for end-to-end repository-level tasks; Agent-Pex, an automated tool for evaluating and testing agentic traces at scale, which builds on our PromptPex open-source framework; Symbolic Guidance for LLM Agents,  reasoning from and mitigating agent failures.\\n\\nThe initiative is a collaboration between researchers at Microsoft, GitHub Next, the University of Washington, and UIUC, and is grounded in both foundational research and real-world applications.\",\"Programming Languages \u0026 Software\",\"\u003ciframe src=\\\"https://microsoft.sharepoint.com/teams/MSRNVA01/_layouts/15/embed.aspx?UniqueId=66310991-bfda-4586-95d4-4f059c00c6df\u0026embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D\u0026referrer=StreamWebApp\u0026referrerScenario=EmbedDialog.Create\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" allowfullscreen title=\\\"58447.mp4\\\"\u003e\u003c/iframe\u003e\",[251,255,259],{\"_31\":252,\"_33\":253,\"_35\":254},\"zorn\",\"Ben Zorn\",\"zorn@microsoft.com\",{\"_31\":256,\"_33\":257,\"_35\":258},\"jhalleux\",\"Peli de Halleux\",\"jhalleux@microsoft.com\",{\"_31\":260,\"_33\":261,\"_35\":262,\"_41\":42},\"sbarke\",\"Shraddha Barke\",\"sbarke@microsoft.com\",[],\"2025-10-30T14:13:53.098Z\",\"2025-11-05T19:44:35.636Z\",[267,271,274,278,281,284,288],{\"_55\":268,\"_57\":269,\"_20\":270},\"Presentation\",\"https://microsoft-my.sharepoint.com/:p:/p/zorn/IQANlcit44pATIO7zwFF9_b-Af9hp9SZ-opiDjtYewZtd3Q?e=pmKzhf\",\"Agentic Engineering deck\",{\"_55\":60,\"_57\":272,\"_20\":273},\"https://githubnext.com/projects/continuous-ai/\",\"GitHub Repo: Continuous AI\",{\"_55\":275,\"_57\":276,\"_20\":277},\"Blog\",\"https://blog.sigplan.org/2025/08/29/ai-models-need-a-virtual-machine/\",\"Blog: AI Models Need a Virtual Machine\",{\"_55\":275,\"_57\":279,\"_20\":280},\"https://blog.sigplan.org/2024/10/22/prompts-are-programs/\",\"Blog: Prompts are Programs\",{\"_55\":275,\"_57\":282,\"_20\":283},\"https://blog.sigplan.org/2025/03/20/testing-ai-software-isnt-like-testing-plain-old-software/\",\"Blog: Testing AI Software Isn’t Like Testing Plain Old Software\",{\"_55\":285,\"_57\":286,\"_20\":287},\"Other\",\"https://githubnext.com/projects/agentic-workflows/\",\"Agentic Workflows overview\",{\"_55\":285,\"_57\":289,\"_20\":290},\"https://microsoft.github.io/promptpex/\",\"PromptPex overview\",[],\"1915\",{\"_18\":294,\"_20\":295,\"_22\":296,\"_24\":297,\"_26\":298,\"_28\":299,\"_43\":316,\"_48\":318,\"_50\":319,\"_52\":320,\"_62\":321,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-047\",\"Agora Datacenter Sustainability\",\"Enhancing the efficiency of datacenter power usage and infrastructure not only lowers Microsoft’s capital and operational costs but also drives global sustainability. By harnessing cutting-edge AI agents and scientific models, our team is partnering with CO+I on two initiatives: Liquid Power and Direct Air Capture in datacenters. \\n\\nFor Liquid Power, we are collaborating with Azure Quantum Discovery to apply agentic AI to the rapid design of a more effective liquid charge carrier. \\n\\nFor Direct Air Capture, we are leveraging advanced molecular simulations and AI-powered process design to rapidly evaluate the viability of carbon capture media.\",\"Cloud \u0026 Infrastructure\",\"\u003ciframe src=\\\"https://microsoft.sharepoint.com/teams/MSRNVA01/_layouts/15/embed.aspx?UniqueId=5bf8012a-fba4-4d1d-8093-0a88b7a0def3\u0026embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D\u0026referrer=StreamWebApp\u0026referrerScenario=EmbedDialog.Create\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" allowfullscreen title=\\\"58428.mp4\\\"\u003e\u003c/iframe\u003e\",[300,304,308,312],{\"_31\":301,\"_33\":302,\"_35\":303,\"_41\":42},\"bnguy\",\"Bichlien Nguyen\",\"bnguy@microsoft.com\",{\"_31\":305,\"_33\":306,\"_35\":307},\"jakesmith\",\"Jake Smith (MSR)\",\"jakesmith@microsoft.com\",{\"_31\":309,\"_33\":310,\"_35\":311},\"kstrauss\",\"Karin Strauss\",\"kstrauss@microsoft.com\",{\"_31\":313,\"_33\":314,\"_35\":315},\"morrissharp\",\"Morris Sharp\",\"morrissharp@microsoft.com\",[45,317],\"Power management\",\"2025-10-30T14:13:53.162Z\",\"2025-10-31T16:36:01.170Z\",[],[],{\"_18\":323,\"_20\":324,\"_22\":325,\"_24\":25,\"_26\":326,\"_28\":327,\"_43\":336,\"_48\":337,\"_50\":338,\"_52\":339,\"_62\":340,\"_64\":101,\"_66\":67,\"_68\":102},\"RRS25-PROJ-003\",\"Agora Grid: AI Agent for Intelligent Power Grid Management and Decision Making\",\"Securing timely access to power has become the primary bottleneck for datacenter growth. Around the world, power grid operators are grappling with limited capacity, excessive demand that results in interconnection queues exceeding five years, aging infrastructure vulnerabilities, and insufficient clean energy sources that raise carbon intensity of the grid. Our agentic system is designed to improve decision making for grid operators and our datacenter planning teams by allowing an AI agent that incorporates multi-modal data streams to forecast scenarios, perform analysis, provide suggestions, and others – all to ensure we meet our growth objectives with minimal environmental impact.\",\"\u003ciframe src=\\\"https://microsoft.sharepoint.com/teams/MSRNVA01/_layouts/15/embed.aspx?UniqueId=beafc5d3-37b8-4877-af42-1b3f6dd28b2b\u0026embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D\u0026referrer=StreamWebApp\u0026referrerScenario=EmbedDialog.Create\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" allowfullscreen title=\\\"58425.mp4\\\"\u003e\u003c/iframe\u003e\",[328,329,333,334,335],{\"_31\":301,\"_33\":302,\"_35\":303,\"_41\":42},{\"_31\":330,\"_33\":331,\"_35\":332},\"danrongzhang\",\"Danrong Zhang\",\"danrongzhang@microsoft.com\",{\"_31\":305,\"_33\":306,\"_35\":307},{\"_31\":309,\"_33\":310,\"_35\":311},{\"_31\":313,\"_33\":314,\"_35\":315},[96],\"2025-10-30T14:13:53.218Z\",\"2025-10-30T22:37:41.319Z\",[],[],{\"_18\":342,\"_20\":343,\"_22\":344,\"_24\":25,\"_26\":27,\"_28\":345,\"_43\":394,\"_48\":398,\"_50\":399,\"_52\":400,\"_62\":401,\"_64\":101,\"_66\":67,\"_68\":102},\"RRS25-PROJ-005\",\"Aurora Web Agent\",\"Meet our web agent, Aurora: a multimodal model fine-tuned on hundreds of thousands of diverse web tasks from our Magentic Data Generation pipeline. Magentic Data Generation is a multi-agent pipeline, built on Magentic-One, that can scalably synthesize tasks, create trajectories to solve them, and verify those solutions. By learning from these trajectories, Fara can help users shop for items, book flights, make reservations, research topics, and more, bringing intelligent, practical automation to everyday online tasks.\",[346,350,354,358,362,366,370,374,378,382,386,390],{\"_31\":347,\"_33\":348,\"_35\":349},\"hassanam\",\"Ahmed Awadallah\",\"hassanam@microsoft.com\",{\"_31\":351,\"_33\":352,\"_35\":353},\"akshayn\",\"Akshay Nambi\",\"akshayn@microsoft.com\",{\"_31\":355,\"_33\":356,\"_35\":357},\"ataymano\",\"Alexey Taymanov\",\"ataymano@microsoft.com\",{\"_31\":359,\"_33\":360,\"_35\":361},\"andrewzhao\",\"Andrew Zhao\",\"andrewzhao@microsoft.com\",{\"_31\":363,\"_33\":364,\"_35\":365},\"arrajeswaran\",\"Aravind Rajeswaran\",\"arrajeswaran@microsoft.com\",{\"_31\":367,\"_33\":368,\"_35\":369},\"corbyrosset\",\"Corby Rosset\",\"corbyrosset@microsoft.com\",{\"_31\":371,\"_33\":372,\"_35\":373},\"hmozannar\",\"Hussein Mozannar\",\"hmozannar@microsoft.com\",{\"_31\":375,\"_33\":376,\"_35\":377},\"t-rmagazine\",\"Raghav Magazine\",\"t-rmagazine@microsoft.com\",{\"_31\":379,\"_33\":380,\"_35\":381,\"_41\":42},\"spwhitehead\",\"Spencer Whitehead\",\"spwhitehead@microsoft.com\",{\"_31\":383,\"_33\":384,\"_35\":385},\"vivineet\",\"Vibhav Vineet\",\"vivineet@microsoft.com\",{\"_31\":387,\"_33\":388,\"_35\":389},\"yashlara\",\"Yash Lara\",\"yashlara@microsoft.com\",{\"_31\":391,\"_33\":392,\"_35\":393},\"yashpandya\",\"Yash Pandya\",\"yashpandya@microsoft.com\",[395,396,397],\"AI Agents (Interactive\",\"Embodied\",\"Devices)\",\"2025-10-30T14:13:54.526Z\",\"2025-11-06T19:54:30.657Z\",[],[],{\"_18\":403,\"_20\":404,\"_22\":405,\"_24\":248,\"_26\":27,\"_28\":406,\"_43\":419,\"_48\":420,\"_50\":421,\"_52\":422,\"_62\":423,\"_64\":101,\"_66\":67,\"_68\":292},\"RRS25-PROJ-086\",\"AutoVeruSys: Automated Proof Generation for Rust System Code\",\"Increasingly more code development work is done by AI (LLMs) these days, with increasing concerns of the correctness and security of AI-generated code. In this project, we explore how to teach AI to write proof that can mathematically verify code written in Rust satisfies user-specified properties. We will show that with carefully designed agentic systems working together with state of the art Rust verifier (Verus), LLMs like GPT-o4 are able to automatically write proof for a large portion of functions in our evaluated Rust systems, including a storage system, a memory allocator, and a distributed system, and others. We believe the collaboration between LLMs and formal verifier can lead to productive code development with quality guarantees.\",[407,411,415],{\"_31\":408,\"_33\":409,\"_35\":410},\"chrishaw\",\"Chris Hawblitzel\",\"chrishaw@microsoft.com\",{\"_31\":412,\"_33\":413,\"_35\":414},\"lorch\",\"Jay Lorch\",\"lorch@microsoft.com\",{\"_31\":416,\"_33\":417,\"_35\":418,\"_41\":42},\"shanlu\",\"Shan Lu\",\"shanlu@microsoft.com\",[],\"2025-10-30T14:13:53.395Z\",\"2025-10-31T16:52:14.764Z\",[],[],{\"_18\":425,\"_20\":426,\"_22\":427,\"_24\":428,\"_26\":27,\"_28\":429,\"_43\":446,\"_48\":447,\"_50\":448,\"_52\":449,\"_62\":450,\"_64\":101,\"_66\":149,\"_68\":451},\"RRS25-PROJ-057\",\"Automated Query Hint Recommendation\",\"Microsoft SQL Server and Azure SQL offer a suite of query hints that can guide the query optimizer to generate alternative query execution plans with potentially better performance (lower actual execution cost). Since the release of Microsoft SQL Server 2022, these query hints can be applied through the query store, offering a user-friendly way to shape query plans without changing the application code. Despite the convenience of query store hints, manually identifying the optimal hint for a specific query remains largely a trial-and-error process, which can be very time-consuming for database administrators. \\n\\nThe Query Hint Recommendation Tool, developed by Microsoft Research, is an extension for SQL Server Management Studio (SSMS) designed to automate the identification of optimal query hints to enhance SQL query performance. This allows users to tune queries directly within the SSMS query window and skips irrelevant hints to make the process efficient without compromising the quality of resulting plans.\",\"Data Systems\",[430,434,438,442],{\"_31\":431,\"_33\":432,\"_35\":433,\"_41\":42},\"andut\",\"Anshuman Dutt\",\"andut@microsoft.com\",{\"_31\":435,\"_33\":436,\"_35\":437},\"kulee\",\"Kukjin Lee\",\"kulee@microsoft.com\",{\"_31\":439,\"_33\":440,\"_35\":441},\"surajitc\",\"Surajit Chaudhuri\",\"surajitc@microsoft.com\",{\"_31\":443,\"_33\":444,\"_35\":445},\"viveknar\",\"Vivek Narasayya\",\"viveknar@microsoft.com\",[],\"2025-10-30T14:13:53.337Z\",\"2025-10-31T16:39:58.409Z\",[],[],\"3042\",{\"_18\":453,\"_20\":454,\"_22\":455,\"_24\":456,\"_26\":27,\"_28\":457,\"_43\":466,\"_48\":468,\"_50\":469,\"_52\":470,\"_62\":471,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-031\",\"Beyond Similarity for LLM Personalization: User Memory Selection via Response-Utility Optimization\",\"Personalization makes AI feel more human, but only if it uses the right information at the right time. We present PersonBOED, a new method grounded in information theory that helps LLMs decide when and how to use personal information. By selecting only the most useful memories that lead to better responses for each input, our approach improves both the relevance and efficiency of LLM personalization.\",\"AI/ML Foundations\",[458,462],{\"_31\":459,\"_33\":460,\"_35\":461,\"_41\":42},\"v-chanypark\",\"Chan Young Park (AQUENT LLC)\",\"v-chanypark@microsoft.com\",{\"_31\":463,\"_33\":464,\"_35\":465},\"jenneville\",\"Jennifer Neville\",\"jenneville@microsoft.com\",[467],\"AI ML Foundations\",\"2025-10-30T14:13:53.453Z\",\"2025-10-30T22:49:08.468Z\",[],[],{\"_18\":473,\"_20\":474,\"_22\":475,\"_24\":186,\"_26\":27,\"_28\":476,\"_43\":511,\"_48\":512,\"_50\":513,\"_52\":514,\"_62\":515,\"_64\":101,\"_66\":67,\"_68\":218},\"RRS25-PROJ-072\",\"Breaking the Memory Wall with Model-System-Hardware Co-design\",\"As LLMs grow—in both model size and context length—the need for high-bandwidth memory (HBM) increases, especially for storing key-value (KV) caches and model weights. This creates significant capacity and bandwidth constraints. The memory workstream of Inference 2030 addresses this challenge through holistic co-design of models, systems, and memory technologies. We propose to enable infinite memory for LLM inference by making LLMs “memory-prefetchable”. We are developing new model techniques of sparsity prefetching that exploits the sparsity in KV caches and MoE weights. The new system of LLM token generation will predict and prefetch only the small, newly activated data from off-package memory sources like host CPU or remote servers, utilizing brief intervals between token generations. This approach will overcome the challenge of HBM capacity limit and small off-GPU memory bandwidth without changing the underlying memory hardware. We will prototype these techniques on distributed GPU systems to greatly increase the batch size for higher GPU utilization, while balancing model accuracy with memory efficiency. With reduced on-package memory capacity pressure, we are advancing next-generation memory technologies that will reshape the future memory systems for AI inference. Our hardware exploration spans across microLED-based optical IO, integration and interconnect architecture for 3D memory, and managed-retention memory cell technologies. This involves LLM workload analysis, distributed GPU system simulation, hardware modelling, and the collaboration with external partners of memory hardware. Together, these innovations will break our reliance on HBMs and introduce heterogeneous memory systems optimized for bandwidth, capacity, energy, and cost.\",[477,478,482,486,490,494,498,502,503,507],{\"_31\":197,\"_33\":198,\"_35\":199},{\"_31\":479,\"_33\":480,\"_35\":481},\"hleblanc\",\"Hayley LeBlanc\",\"hleblanc@microsoft.com\",{\"_31\":483,\"_33\":484,\"_35\":485},\"hiballan\",\"Hitesh Ballani\",\"hiballan@microsoft.com\",{\"_31\":487,\"_33\":488,\"_35\":489},\"iostefan\",\"Ioan Stefanovici\",\"iostefan@microsoft.com\",{\"_31\":491,\"_41\":42,\"_33\":492,\"_35\":493},\"jacnels\",\"Jacob Nelson\",\"Jacob.Nelson@microsoft.com\",{\"_31\":495,\"_33\":496,\"_35\":497},\"junyili\",\"Junyi Liu\",\"junyili@microsoft.com\",{\"_31\":499,\"_33\":500,\"_35\":501},\"pcosta\",\"Paolo Costa\",\"pcosta@microsoft.com\",{\"_31\":209,\"_33\":210,\"_35\":211},{\"_31\":504,\"_33\":505,\"_35\":506},\"serleg\",\"Sergey Legtchenko\",\"serleg@microsoft.com\",{\"_31\":508,\"_33\":509,\"_35\":510},\"thomkar\",\"Thomas Karagiannis\",\"thomkar@microsoft.com\",[46],\"2025-10-30T14:13:53.512Z\",\"2025-10-31T23:21:14.587Z\",[],[],{\"_18\":517,\"_20\":518,\"_22\":519,\"_24\":25,\"_26\":27,\"_28\":520,\"_43\":549,\"_48\":550,\"_50\":551,\"_52\":552,\"_62\":553,\"_64\":101,\"_66\":67,\"_68\":102},\"RRS25-PROJ-019\",\"CRing: Wearable Ring as a Low-Friction Interface for Agentic AI\",\"We will present a wearable device in the form of a ring that enables always available user interaction primarily through speech input and haptics-based output. The goal of the project is to develop an always available wearable device with low-friction speech-based invocation of user commands for execution by a remote agent-based system.\\n\\nThe CRing prototype consists of a microphone for speech input, a buzzer for haptic output, and a touch sensor with tap and swipe capability. The device communicates wirelessly using Bluetooth Low Energy (BLE) and uses BLE audio to achieve low-power consumption. It also has gesture recognition capability for gesture-based user interactions. \\n\\nWe will demonstrate integration with multiple agentic frameworks such as VSCode Copilot agent, Action Engine, and Type Agent. We will demonstrate several speech-based agentic backend interactions such as emailing a meeting summery, planning a weekend hike, draft PowerPoint slides based on stock market analysis.  \\n\\nWe plan to distribute several hundreds of V2 devices within MSR for a wider community engagement.\",[521,525,529,533,537,541,545],{\"_31\":522,\"_33\":523,\"_35\":524,\"_41\":42},\"bodhip\",\"Bodhi Priyantha\",\"bodhip@microsoft.com\",{\"_31\":526,\"_33\":527,\"_35\":528},\"clovett\",\"Chris Lovett\",\"clovett@microsoft.com\",{\"_31\":530,\"_33\":531,\"_35\":532},\"judithamores\",\"Judith Amores\",\"judithamores@microsoft.com\",{\"_31\":534,\"_33\":535,\"_35\":536},\"alstory\",\"Lex Story\",\"alstory@microsoft.com\",{\"_33\":538,\"_31\":539,\"_35\":540,\"_41\":6},\"Christina Burger (ASG)\",\"cburger\",\"cburger@microsoft.com\",{\"_33\":542,\"_31\":543,\"_35\":544,\"_41\":6},\"Matt Galloway (ASG)\",\"magallow\",\"magallow@microsoft.com\",{\"_33\":546,\"_31\":547,\"_35\":548,\"_41\":6},\"Vaishnavi Ranganathan\",\"vnattar\",\"vnattar@microsoft.com\",[395,396,397],\"2025-10-30T14:13:53.689Z\",\"2025-10-31T22:11:12.550Z\",[],[],{\"_18\":555,\"_20\":556,\"_22\":557,\"_24\":558,\"_26\":559,\"_28\":560,\"_43\":573,\"_48\":576,\"_50\":577,\"_52\":578,\"_62\":579,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-089\",\"Collaborative Applications with End-to-End Encryption\",\"Instant messaging has used end-to-end encryption successfully for years, keeping private messages hidden from service providers, but other multi-user applications simply reveal all application data to the service provider. This project builds a platform to add end-to-end encryption to collaborative applications, like text editors, calendars, source control, and rich group chat platforms (e.g., Teams, Zulip, Slack, Discord). It introduces the concept of an encrypted collaboration space where only trusted participants can read or modify data.\\n\\nSpaces are modular, encrypted environments that support concurrent, multi-user workflows while preserving privacy. The platform handles dynamic group key management and encrypted data structures, enabling secure synchronization, conflict resolution, and authenticated change logs. The server acts only as a relay for encrypted data and cannot access content, and server operations are made verifiable to clients with zero-knowledge proofs. It supports advanced security features such as post-quantum privacy, deniability, and anonymity. Developers can build collaborative apps without compromising user privacy or managing complex cryptographic details.\",\"Security, Privacy \u0026 Cryptography\",\"\u003ciframe src=\\\"https://microsoft-my.sharepoint.com/personal/gregz_microsoft_com/_layouts/15/embed.aspx?UniqueId=b2f6b475-8d6b-4ad4-9e41-f727bb944004\u0026embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D\u0026referrer=StreamWebApp\u0026referrerScenario=EmbedDialog.Create\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" allowfullscreen title=\\\"RRS-2025-Collaborative Applications with End-to-End Encryption.mp4\\\"\u003e\u003c/iframe\u003e\",[561,565,569],{\"_31\":562,\"_33\":563,\"_35\":564,\"_41\":42},\"cpaquin\",\"Christian Paquin\",\"cpaquin@microsoft.com\",{\"_31\":566,\"_33\":567,\"_35\":568},\"gregz\",\"Greg Zaverucha\",\"gregz@microsoft.com\",{\"_31\":570,\"_33\":571,\"_35\":572},\"ljoy\",\"Larry Joy\",\"ljoy@microsoft.com\",[574,575],\"Security\",\"Privacy \u0026 Cryptography\",\"2025-10-30T14:13:53.572Z\",\"2025-11-05T23:39:50.619Z\",[],[],{\"_18\":581,\"_20\":582,\"_22\":583,\"_24\":107,\"_26\":27,\"_28\":584,\"_43\":609,\"_48\":610,\"_50\":611,\"_52\":612,\"_62\":613,\"_64\":101,\"_66\":149,\"_68\":150},\"RRS25-PROJ-023\",\"Collaborative LLM Training for Human Empowerment\",\"Our goal in this work is to train LLMs to better support human empowerment, both in the near term by helping users achieve their goals quickly and accurately, and in the long term by strengthening their knowledge and skills so they become more capable—e.g., in leveraging AI effectively. Our prior work on CollabLLM advanced near-term empowerment by making LLMs more steerable and responsive to user intent. It introduced collaborative simulation and multi-turn rewards, moving beyond single-turn correctness to optimize for long-term interaction value.\\n\\nLooking ahead, our current work focuses on long-term human empowerment—helping users become more capable and skilled. This is achieved through a two-agent collaborative reinforcement learning (RL) environment, where the increase in capabilities of the simulated user becomes a training objective for the LLM agent. Our poster will present our ongoing work aligned with these objectives, including two-agent collaborative RL training, fostering creativity and proactivity in LLMs, Human-AI alignment in simulation, and going ‘Beyond chat’ interfaces to harness AI capabilities.\",[585,589,593,597,601,605],{\"_31\":586,\"_33\":587,\"_35\":588},\"abanburski\",\"Andrzej Banburski-Fahey\",\"abanburski@microsoft.com\",{\"_31\":590,\"_33\":591,\"_35\":592},\"chenwang\",\"Chenglong Wang\",\"chenwang@microsoft.com\",{\"_31\":594,\"_33\":595,\"_35\":596},\"jinala\",\"Jeevana Priya Inala\",\"jinala@microsoft.com\",{\"_31\":598,\"_33\":599,\"_35\":600,\"_41\":42},\"mgalley\",\"Michel Galley\",\"mgalley@microsoft.com\",{\"_31\":602,\"_33\":603,\"_35\":604},\"swads\",\"Swadheen Shukla\",\"swads@microsoft.com\",{\"_31\":606,\"_33\":607,\"_35\":608},\"weijiaxu\",\"Weijia Xu\",\"weijiaxu@microsoft.com\",[395,396,397],\"2025-10-30T14:13:53.630Z\",\"2025-10-30T22:46:15.052Z\",[],[],{\"_18\":615,\"_20\":616,\"_22\":617,\"_24\":456,\"_26\":618,\"_28\":619,\"_43\":625,\"_48\":626,\"_50\":627,\"_52\":628,\"_62\":629,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-032\",\"Data Dignity: Attributing model behavior back to pretraining data\",\"The goal of the project is to demonstrate that an LLM can be trained in a way that enables run-time correlation of generated outputs back to examples of the most indispensable training data.  While this idea has origins in economic models for AI in society, in this case the purpose is to apply provenance as a redundant channel of inputs for enhancing security and quality, roughly analogous to the use of multifactor authentication.\",\"\u003ciframe src=\\\"https://microsoft.sharepoint.com/teams/MSRNVA01/_layouts/15/embed.aspx?UniqueId=47e51032-9b80-40bc-8f93-97e0d47fd8b7\u0026embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D\u0026referrer=StreamWebApp\u0026referrerScenario=EmbedDialog.Create\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" allowfullscreen title=\\\"58427.mp4\\\"\u003e\u003c/iframe\u003e\",[620,621],{\"_31\":586,\"_33\":587,\"_35\":588,\"_41\":42},{\"_31\":622,\"_33\":623,\"_35\":624},\"jalani\",\"Jaron Lanier\",\"jalani@microsoft.com\",[467],\"2025-10-30T14:13:53.747Z\",\"2025-10-31T16:50:49.099Z\",[],[],{\"_18\":631,\"_20\":632,\"_22\":633,\"_24\":428,\"_26\":27,\"_28\":634,\"_43\":646,\"_48\":647,\"_50\":648,\"_52\":649,\"_62\":650,\"_64\":101,\"_66\":149,\"_68\":451},\"RRS25-PROJ-058\",\"Data Formulator: Vibe With Your Data\",\"The new edition of Data Formulator is an agentic data exploration tool for you to vibe with data. No matter if the data you are interested in lies in your data lake database, local files, web page, or images, agents in Data Formulator can interactively suggest you new exploration directions, transform the data and visualize it to provide you new insights that you may have never considered. When you want to take in control of the analysis direction, simply leverage the multi-modal \\\"data threads\\\" interface to steer the exploration -- either you want to branch out, revisit, reuse or followup for a deep dive. Behind the scene, Data Formulator leverages an event-driven asynchronous agent design where different AI agents collaboratively work with the user to recommend, code, and explain data to let users fluently VIBE with data.\",[635,636,640,644,645],{\"_31\":590,\"_33\":591,\"_35\":592,\"_41\":42},{\"_31\":637,\"_33\":638,\"_35\":639},\"jfgao\",\"Jianfeng Gao\",\"jfgao@microsoft.com\",{\"_31\":641,\"_33\":642,\"_35\":643},\"midunlap\",\"Michael Dunlap\",\"midunlap@microsoft.com\",{\"_31\":598,\"_33\":599,\"_35\":600},{\"_31\":602,\"_33\":603,\"_35\":604},[428],\"2025-10-30T14:13:53.808Z\",\"2025-10-31T16:40:51.633Z\",[],[],{\"_18\":652,\"_20\":653,\"_22\":654,\"_24\":248,\"_26\":27,\"_28\":655,\"_43\":702,\"_48\":703,\"_50\":704,\"_52\":705,\"_62\":706,\"_64\":101,\"_66\":67,\"_68\":292},\"RRS25-PROJ-073\",\"Deep Program Intelligence: LLMs for Rigorous Software Reasoning\",\"We have developed an RL (reinforcement learning) based post-training pipeline to\\nimprove the ability of LLMs on a range of program reasoning tasks. Our\\nmodel is capable of writing high-coverage test suites backed by\\ntest oracles in Python and C#; proposing static analysis annotations,\\ntriaging and fixing warnings (including SAL for C/C++ code); and even conducting\\nformal proofs of program correctness using proof assistants such as F*, Coq, and\\nLean. In all cases, we incorporate feedback from trustworthy symbolic tools as\\nrewards in our RL pipeline, ensuring that the program intelligence our model\\nexhibit is rigorous. Our initial results indicate that a multi-lingual,\\nmulti-task model such as ours can exhibit state-of-the-art performance on a\\nrange of program proof tasks.\",[656,657,661,665,669,673,677,681,685,689,693,697,698],{\"_31\":189,\"_33\":190,\"_35\":191},{\"_31\":658,\"_33\":659,\"_35\":660},\"gabrielebner\",\"Gabriel Ebner\",\"gabrielebner@microsoft.com\",{\"_31\":662,\"_33\":663,\"_35\":664},\"jakul\",\"Janardhan Kulkarni\",\"jakul@microsoft.com\",{\"_31\":666,\"_33\":667,\"_35\":668},\"eioannidis\",\"Lef Ioannidis\",\"eioannidis@microsoft.com\",{\"_31\":670,\"_33\":671,\"_35\":672,\"_41\":42},\"madanm\",\"Madan Musuvathi\",\"madanm@microsoft.com\",{\"_31\":674,\"_33\":675,\"_35\":676},\"matthaip\",\"Matthai Philipose (HE/HIM)\",\"matthaip@microsoft.com\",{\"_31\":678,\"_33\":679,\"_35\":680,\"_41\":6},\"meerachander\",\"Meera Chander\",\"meerachander@microsoft.com\",{\"_31\":682,\"_33\":683,\"_35\":684},\"nswamy\",\"Nikhil Swamy\",\"nswamy@microsoft.com\",{\"_31\":686,\"_33\":687,\"_35\":688},\"nbjorner\",\"Nikolaj Bjorner\",\"nbjorner@microsoft.com\",{\"_31\":690,\"_33\":691,\"_35\":692},\"saikatc\",\"Saikat Chakraborty\",\"saikatc@microsoft.com\",{\"_31\":694,\"_33\":695,\"_35\":696},\"sfakhoury\",\"Sarah Fakhoury\",\"sfakhoury@microsoft.com\",{\"_31\":260,\"_33\":261,\"_35\":262},{\"_33\":699,\"_31\":700,\"_35\":701,\"_41\":6},\"Angélica Moreira\",\"anmoreira\",\"anmoreira@microsoft.com\",[],\"2025-10-30T14:13:53.870Z\",\"2025-11-03T17:31:28.421Z\",[],[],{\"_18\":708,\"_20\":709,\"_22\":710,\"_24\":248,\"_26\":27,\"_28\":711,\"_43\":727,\"_48\":728,\"_50\":729,\"_52\":730,\"_62\":731,\"_64\":101,\"_66\":67,\"_68\":292},\"RRS25-PROJ-074\",\"DeepTest: Agents for Generating High Quality Tests\",\"DeepTest generates high-quality tests to cover deep, hard-to-reach branches in code. It hierarchically builds semantic understanding of a codebase, identifies semantic predicates that control function behavior, modularly composes these predicates to identify semantically meaningful tests paths, and generates tests that cover these paths using existing test harnesses. The project leverages agentic capabilities to statically predicate uncovered execution paths and for structural and modular analysis of large codebases. \\n\\nDeepTest is a collaboration between MSR and CoreOS and has successfully improved the coverage of 40 drivers and found critical bugs.\",[712,716,717,718,722,726],{\"_31\":713,\"_33\":714,\"_35\":715},\"elhouha\",\"Elaine Houha\",\"elhouha@microsoft.com\",{\"_31\":670,\"_33\":671,\"_35\":672},{\"_31\":682,\"_33\":683,\"_35\":684},{\"_31\":719,\"_33\":720,\"_35\":721},\"omarm\",\"Omar Maabreh\",\"omarm@microsoft.com\",{\"_31\":723,\"_33\":724,\"_35\":725},\"poornag\",\"Poorna Gaddehosur\",\"poornag@ntdev.microsoft.com\",{\"_31\":694,\"_33\":695,\"_35\":696,\"_41\":42},[],\"2025-10-30T14:13:53.929Z\",\"2025-11-04T15:30:20.379Z\",[],[],{\"_18\":733,\"_20\":734,\"_22\":735,\"_24\":107,\"_26\":736,\"_28\":737,\"_43\":794,\"_48\":798,\"_50\":799,\"_52\":800,\"_62\":801,\"_64\":101,\"_66\":149,\"_68\":243},\"RRS25-PROJ-024\",\"Democratizing Decision Intelligence with Fabric Data Scientist \",\"Our goal with Fabric Data Scientist is to make data-driven decisions accessible to all, by designing a no-code Data Agent that empowers users to define business intent and receive plain-language, actionable recommendations. To this end, Fabric Data Scientist leverages advanced research and analytics tools from multiple research labs across Microsoft: universal predictor (GSL, Azure Data), causality (EconML, MSR tri-labs), and optimization techniques (OptiGuide, MSR Redmond). The combination of tools allows answering complex business questions that would normally require expert knowledge from multiple fields. We will show a demo of Fabric Data Scientist in action, and discuss ongoing work and research challenges, including tool selection, dealing with ambiguity, and interpretation of LLM outputs.\",\"\u003ciframe src=\\\"https://microsoft.sharepoint.com/teams/MSRNVA01/_layouts/15/embed.aspx?UniqueId=9ee88c6a-ef02-4f25-90b0-ede556757311\u0026embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D\u0026referrer=StreamWebApp\u0026referrerScenario=EmbedDialog.Create\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" allowfullscreen title=\\\"58426.mp4\\\"\u003e\u003c/iframe\u003e\",[738,742,746,750,754,758,762,766,770,774,778,782,786,790],{\"_31\":739,\"_33\":740,\"_35\":741},\"ansonho\",\"Anson Ho\",\"ansonho@microsoft.com\",{\"_31\":743,\"_33\":744,\"_35\":745},\"ccurino\",\"Carlo Curino\",\"ccurino@microsoft.com\",{\"_31\":747,\"_33\":748,\"_35\":749},\"dmoldavskaya\",\"Darya Moldavskaya\",\"dmoldavskaya@microsoft.com\",{\"_31\":751,\"_33\":752,\"_35\":753},\"eldillon\",\"Eleanor Dillon\",\"eldillon@microsoft.com\",{\"_31\":755,\"_33\":756,\"_35\":757},\"amueller\",\"Andreas Mueller\",\"amueller@microsoft.com\",{\"_31\":759,\"_33\":760,\"_35\":761},\"hugobarbalho\",\"Hugo de Oliveira Barbalho\",\"hugobarbalho@microsoft.com\",{\"_31\":763,\"_33\":764,\"_35\":765},\"ishai\",\"Ishai Menache\",\"ishai@microsoft.com\",{\"_31\":767,\"_33\":768,\"_35\":769},\"kebatt\",\"Keith Battocchi (he/him)\",\"kebatt@microsoft.com\",{\"_31\":771,\"_33\":772,\"_35\":773},\"kevingao\",\"Kevin Gao\",\"kevingao@microsoft.com\",{\"_31\":775,\"_33\":776,\"_35\":777},\"kmellou\",\"Konstantina Mellou\",\"kmellou@microsoft.com\",{\"_31\":779,\"_33\":780,\"_35\":781},\"lumarsha\",\"Luke Marshall\",\"lumarsha@microsoft.com\",{\"_31\":783,\"_33\":784,\"_35\":785},\"marcozo\",\"Markus Cozowicz\",\"marcozo@microsoft.com\",{\"_31\":787,\"_33\":788,\"_35\":789},\"mweimer\",\"Markus Weimer\",\"mweimer@microsoft.com\",{\"_31\":791,\"_33\":792,\"_35\":793,\"_41\":42},\"pkovaleski\",\"Patricia Kovaleski\",\"pkovaleski@microsoft.com\",[795,45,796,797],\"AI agents\",\"Edge computing\",\"IOT\",\"2025-10-30T14:13:53.986Z\",\"2025-11-01T00:13:40.376Z\",[],[],{\"_18\":803,\"_20\":804,\"_22\":805,\"_24\":456,\"_26\":27,\"_28\":806,\"_43\":828,\"_48\":829,\"_50\":830,\"_52\":831,\"_62\":832,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-033\",\"Distributed Orthonormal Update Revolution is Here!\",\"We have developed a new optimizer that can potentially dethrone Adam(-W)!\",[807,811,812,816,820,824],{\"_31\":808,\"_33\":809,\"_35\":810},\"byronxu\",\"Byron Xu\",\"byronxu@microsoft.com\",{\"_31\":80,\"_33\":81,\"_35\":82},{\"_31\":813,\"_33\":814,\"_35\":815,\"_41\":42},\"kwangjunahn\",\"Kwangjun Ahn\",\"kwangjunahn@microsoft.com\",{\"_31\":817,\"_33\":818,\"_35\":819},\"pratysharma\",\"Pratyusha Sharma\",\"pratysharma@microsoft.com\",{\"_31\":821,\"_33\":822,\"_35\":823},\"fanying\",\"Ying Fan\",\"fanying@microsoft.com\",{\"_31\":825,\"_33\":826,\"_35\":827},\"zhengzhan\",\"Zheng Zhan\",\"zhengzhan@microsoft.com\",[467],\"2025-10-30T14:13:54.050Z\",\"2025-10-30T22:49:35.538Z\",[],[],{\"_18\":834,\"_20\":835,\"_22\":836,\"_24\":837,\"_26\":27,\"_28\":838,\"_43\":879,\"_48\":880,\"_50\":881,\"_52\":882,\"_62\":883,\"_64\":101,\"_66\":149,\"_68\":150},\"RRS25-PROJ-063\",\"Dittos: Agents with Benefits\",\"By completing the cycle of interaction with Dittos, we have demonstrated our future with mimetic agents. We validated how mining the Microsoft Substrate data on previous social interactions can streamline and personalize the Ditto Context to prepare it to interact with people. We explored user needs for the Ditto Recap experience so Sources keep apprised of their Ditto’s interactions with people. During a 2 week deployment of Dittos, we saw the benefits Dittos offered in sharing information and scaffolding social relationships. Our experiences show how Dittos extend availability and enhance the opportunity to strengthen social relationships among work colleagues.\",\"HCI\",[839,843,847,851,855,859,863,867,871,875],{\"_31\":840,\"_33\":841,\"_35\":842},\"ashleyf\",\"Ashley Feniello\",\"ashleyf@microsoft.com\",{\"_31\":844,\"_33\":845,\"_35\":846},\"denae\",\"Denae Ford Robinson\",\"denae@microsoft.com\",{\"_31\":848,\"_33\":849,\"_35\":850},\"cutrell\",\"Ed Cutrell\",\"cutrell@microsoft.com\",{\"_31\":852,\"_33\":853,\"_35\":854},\"javierh\",\"Javier Hernandez\",\"javierh@microsoft.com\",{\"_31\":856,\"_33\":857,\"_35\":858,\"_41\":42},\"johntang\",\"John Tang\",\"johntang@microsoft.com\",{\"_31\":860,\"_33\":861,\"_35\":862},\"kori\",\"Kori Inkpen\",\"kori@microsoft.com\",{\"_31\":864,\"_33\":865,\"_35\":866},\"mamott\",\"Martez Mott\",\"mamott@microsoft.com\",{\"_31\":868,\"_33\":869,\"_35\":870},\"patricsw\",\"Pat Sweeney\",\"patricsw@microsoft.com\",{\"_31\":872,\"_33\":873,\"_35\":874},\"sasajun\",\"Sasa Junuzovic\",\"sasajun@microsoft.com\",{\"_33\":876,\"_31\":877,\"_35\":878,\"_41\":6},\"Dan Marshall\",\"danmar\",\"danmar@microsoft.com\",[837],\"2025-10-30T14:13:54.109Z\",\"2025-10-31T22:37:18.780Z\",[],[],{\"_18\":885,\"_20\":886,\"_22\":887,\"_24\":25,\"_26\":27,\"_28\":888,\"_43\":902,\"_48\":903,\"_50\":904,\"_52\":905,\"_62\":906,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-006\",\"Echoes in AI: Quantifying Lack of Plot Diversity in LLM Outputs\",\"With rapid advances in large language models (LLMs), there has been an increasing application of LLMs in creative content ideation and generation. A critical question emerges: can current LLMs provide ideas that are diverse enough to truly bolster the collective creativity?\\n\\nWe examine two state-of-the-art LLMs, GPT-4 and LLaMA-3, on story generation and discover that LLM-generated stories often consist of plot elements that are echoed across a number of generations. This repetition lends itself to less unique outputs that are deterministic and predictable. To quantify this phenomenon, we introduce the Sui Generis (Latin for “of its own kind”) score, an automatic metric that estimates how unlikely a plot element is to appear in alternative storylines generated by the same LLM. It helps quantify creativity at the narrative level, not just by counting unique words or topics and it also correlates with human judgement of surprise, a factor in how we experience stories.\\n\\nEvaluating 100 short stories, we find that LLM-generated stories often contain combinations of idiosyncratic plot elements echoed frequently across generations, while the original human-written stories are far more diverse and rarely recreated or even echoed in pieces. Our experiments with the Sui Generis score demonstrated the lack of plot-level diversity in LLM-generated stories, in contrast to the more varied and unique elements found in human-written stories. Human creativity brings something truly unique to the pages of a story that LLMs can’t recreate.\",[889,893,897,901],{\"_31\":890,\"_33\":891,\"_35\":892},\"billdol\",\"Bill Dolan\",\"billdol@microsoft.com\",{\"_31\":894,\"_33\":895,\"_35\":896},\"jojic\",\"Nebojsa Jojic\",\"jojic@microsoft.com\",{\"_31\":898,\"_33\":899,\"_35\":900,\"_41\":42},\"sudhra\",\"Sudha Rao\",\"sudhra@microsoft.com\",{\"_31\":606,\"_33\":607,\"_35\":608},[395,396,397],\"2025-10-30T14:13:54.170Z\",\"2025-10-30T22:39:11.523Z\",[],[],{\"_18\":908,\"_20\":909,\"_22\":910,\"_24\":107,\"_26\":27,\"_28\":911,\"_43\":930,\"_48\":933,\"_50\":934,\"_52\":935,\"_62\":936,\"_64\":101,\"_66\":149,\"_68\":243},\"RRS25-PROJ-025\",\"Empowering Self-Advocacy and Crisis Response: Designing AI for Workplace Well-being and Mental Health Support\",\"We present two complementary investigations into how AI can be applied to promote offline resilience in the workplace and be guided to support people as they navigate crisis even beyond the confines of work. The first investigation, focused on AI for self-advocacy, introduces a conceptual framework and empirical findings that reveal how AI systems can empower employees to articulate needs, build confidence, and seek guidance to mitigate psychosocial hazards at work. Our results underscore the importance of personalized interventions, visibility, and organizational support, while also surfacing concerns around trust, privacy, and cultural nuance. Building on this foundation, the second investigation examines the role of AI agents in mental health crisis management, drawing on testimonial surveys and expert interviews to understand why individuals turn to AI for immediate, nonjudgmental support when traditional resources are inaccessible. Responsible AI interventions are shown to facilitate evidence-based positive actions and validate user autonomy, leveraging empathetic dialogue and behavioral change models to guide users from contemplation to preparedness and action. Together, these projects inform the design of AI systems that not only empower strategic self-advocacy but also serve as responsible partners in moments of crisis, advancing technology that meets people in their nuance and supports them through uncertainty through the complexities of life.\",[912,916,917,921,925,926],{\"_31\":913,\"_33\":914,\"_35\":915},\"annpar\",\"Ann Paradiso\",\"annpar@microsoft.com\",{\"_31\":844,\"_33\":845,\"_35\":846,\"_41\":42},{\"_31\":918,\"_33\":919,\"_35\":920},\"ebeleokoli\",\"Ebele Okoli\",\"ebeleokoli@microsoft.com\",{\"_31\":922,\"_33\":923,\"_35\":924},\"eugeniakim\",\"Eugenia Kim\",\"eugeniakim@microsoft.com\",{\"_31\":229,\"_33\":230,\"_35\":231},{\"_31\":927,\"_33\":928,\"_35\":929},\"knamuduri\",\"Keertana Namuduri\",\"knamuduri@microsoft.com\",[237,238,931,932],\"Federated-learning\",\"Privacy\",\"2025-10-30T14:13:54.226Z\",\"2025-10-30T22:47:42.049Z\",[],[],{\"_18\":938,\"_20\":939,\"_22\":940,\"_24\":297,\"_26\":27,\"_28\":941,\"_43\":954,\"_48\":956,\"_50\":957,\"_52\":958,\"_62\":959,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-090\",\"Enabling DRAM Aliasing for Cloud Server Memory Performance and Security\",\"Modern cloud servers operate under a rigid physical address translation model where physical-to-media (i.e., DRAM) address mappings are one-to-one. Allocating a 2MB physical page translates to allocating 2MB of DRAM. This inflexibility leads to inefficiencies in memory usage and introduces security risks in memory sharing context.\\n\\nThis invention introduces DRAM aliasing: an abstraction that changes physical-to-media address mappings by making multiple physical address point to the same DRAM address. We also demonstrate three primitives enabled by this abstraction that benefit cloud server memory management and security: (1) Cache-DRAM decoupling for secure memory sharing; (2) Custom-sized huge pages; and (3) Leveraging lack of cache coherency for fine-grained performance profiling. We have validated each primitive on an existing class of Azure servers (Gen6).\",[942,946,950],{\"_31\":943,\"_33\":944,\"_35\":945},\"alecw\",\"Alec Wolman\",\"alecw@microsoft.com\",{\"_31\":947,\"_33\":948,\"_35\":949,\"_41\":42},\"liangchengyu\",\"Liangcheng Yu\",\"liangchengyu@microsoft.com\",{\"_31\":951,\"_33\":952,\"_35\":953},\"ssaroiu\",\"Stefan Saroiu\",\"ssaroiu@microsoft.com\",[955],\"Memory allocation\",\"2025-10-30T14:13:54.283Z\",\"2025-10-31T16:53:35.989Z\",[],[],{\"_18\":961,\"_20\":962,\"_22\":963,\"_24\":456,\"_26\":27,\"_28\":964,\"_43\":996,\"_48\":997,\"_50\":998,\"_52\":999,\"_62\":1000,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-034\",\"Eureka ML Insights: Evaluating and Understanding Large Foundation Models\",\"Eureka is an open-source framework for standardizing evaluations of large foundation models, beyond single-score reporting and rankings. Powered by eureka, we will present findings from our extensive evaluations studying i) capabilities that are still challenging for state-of-the-art foundation models and represent fundamental but overlooked capabilities for completing tasks in both language and vision modalities and ii) the benefits and limitations of inference-time scaling models and methods across challenging tasks, including math and STEM reasoning, calendar planning, NP-hard problems, navigation, and spatial reasoning.\",[965,969,973,974,978,982,986,990,991,995],{\"_31\":966,\"_33\":967,\"_35\":968},\"edus\",\"Eduardo Salinas\",\"edus@microsoft.com\",{\"_31\":970,\"_33\":971,\"_35\":972},\"jingyachen\",\"Jingya Chen\",\"jingyachen@microsoft.com\",{\"_31\":80,\"_33\":81,\"_35\":82},{\"_31\":975,\"_33\":976,\"_35\":977},\"lingjiaochen\",\"Lingjiao Chen\",\"lingjiaochen@microsoft.com\",{\"_31\":979,\"_33\":980,\"_35\":981},\"neel\",\"Neel Joshi\",\"neel@microsoft.com\",{\"_31\":983,\"_33\":984,\"_35\":985},\"sayouse\",\"Safoora Yousefi (they/them)\",\"sayouse@microsoft.com\",{\"_31\":987,\"_33\":988,\"_35\":989},\"shigarg\",\"Shivam Garg\",\"shigarg@microsoft.com\",{\"_31\":383,\"_33\":384,\"_35\":385},{\"_31\":992,\"_33\":993,\"_35\":994,\"_41\":42},\"vidhishab\",\"Vidhisha Balachandran\",\"vidhishab@microsoft.com\",{\"_31\":387,\"_33\":388,\"_35\":389},[467],\"2025-10-30T14:13:54.346Z\",\"2025-10-31T23:04:05.179Z\",[],[],{\"_18\":1002,\"_20\":1003,\"_22\":1004,\"_24\":428,\"_26\":27,\"_28\":1005,\"_43\":1008,\"_48\":1009,\"_50\":1010,\"_52\":1011,\"_62\":1012,\"_64\":101,\"_66\":149,\"_68\":451},\"RRS25-PROJ-059\",\"Examining the Practicality of LLMs for Query Rewriting\",\"Query rewriting is one the techniques used by application developers and DBAs to tune queries that perform poorly. LLM-based query rewriting techniques show significant performance improvements on the industry benchmark queries. However, since LLMs cannot guarantee semantic equivalence of the rewrite, checking if the rewritten query is indeed equivalent is a major impediment that limits practicality of LLM-based rewriting today. We present sound techniques that leverage built-in capabilities of the query optimizer of a database engine to verify if the rewritten query is semantically equivalent. We also conduct an extensive empirical evaluation to quantify the effectiveness of LLM-based query rewriting on real-world queries.\",[1006,1007],{\"_31\":439,\"_33\":440,\"_35\":441},{\"_31\":443,\"_33\":444,\"_35\":445,\"_41\":42},[428],\"2025-10-30T14:13:54.405Z\",\"2025-10-31T16:40:41.364Z\",[],[],{\"_18\":1014,\"_20\":1015,\"_22\":1016,\"_24\":186,\"_26\":27,\"_28\":1017,\"_43\":1023,\"_48\":1025,\"_50\":1026,\"_52\":1027,\"_62\":1028,\"_64\":101,\"_66\":67,\"_68\":218},\"RRS25-PROJ-075\",\"Exploring and Automating Novel Optimizations for GPU Matrix Multiplication Kernels using LLMs\",\"GPU based MatMul (Matrix Multiplication) kernels are central to large scale AI systems, especially LLM inference. Thus, optimizing these MatMul kernels can decrease time, energy, and cost of inference, one of the critical services provided by Microsoft. Existing MatMul kernels implement the classic O(n3) algorithm; however, it has been shown that other algorithms, i.e., Strassen, have lower algorithmic complexity of O(n2.81). Despite these theoretical improvements, it is extremely difficult to implement these algorithms in practice due to their irregular and recursive nature, which are not well suited for GPU programming models. In this poster/demo, we present the first highly optimized MatMul implementation (for both single-precision and mixed-precision) using the Strassen algorithm for NVIDIA GPUs. For the critical MatMul kernels found in several popular LLMs (including Llama 3 and Qwen 3-32b), our FP16 Tensor Core implementation runs up to 12% faster than NVIDIA’s optimized kernels.\\n \\nWriting the above optimized Strassen MatMul kernels took several months of tedious manual programming effort, requiring detailed knowledge of low-level architecture features of NVIDIA GPUs. To aid in such development, we have been developing GPUGenie: an LLM-based GPU kernel optimizer. GPUGenie has a knowledge base of GPU kernel optimizations (written in natural language and easily extensible) and then utilizes this knowledge to iteratively transform (optimize) a GPU kernel. After transformation, GPUGenie automatically validates and profiles the kernel, providing a detailed report to the kernel developer. Currently, GPUGenie can apply complex MatMul kernel optimizations resulting in kernels that are competitive with NVIDIA’s hand optimized kernels. We plan to extend GPUGenie to more complex optimizations, such as the ones that are required for Strassen algorithm, and thus, automating the optimization of performance critical GPU kernels that drive important Microsoft services.\",[1018,1019],{\"_31\":193,\"_33\":194,\"_35\":195,\"_41\":42},{\"_31\":1020,\"_33\":1021,\"_35\":1022},\"tsorensen\",\"Tyler Sorensen\",\"tsorensen@microsoft.com\",[1024],\"Optimizing\",\"2025-10-30T14:13:54.463Z\",\"2025-10-31T16:48:13.256Z\",[],[],{\"_18\":1030,\"_20\":1031,\"_22\":1032,\"_24\":837,\"_26\":27,\"_28\":1033,\"_43\":1063,\"_48\":1064,\"_50\":1065,\"_52\":1066,\"_62\":1067,\"_64\":101,\"_66\":149,\"_68\":1068},\"RRS25-PROJ-064\",\"FX ~ AI Manifestations \u0026 Affordances\",\"To move beyond training people to prompt AI or training AI agents to operate interfaces built for humans, we must radically rethink how we design for intelligence. This research explores how AI can be manifested in interfaces, and what affordances those manifestations create. The way AI shows up—whether as a human-like agent, an ambient presence, or embedded in creative tools—shapes how people engage, what they expect, and how much value they derive. Manifestations are not just aesthetic choices \u0026 eye candy, they are invitations to interact and they directly translate into what value people get from using our software. In this demo, we share a range of explorations across intelligent workspaces \u0026 canvases, next generation of tools, human-like agents and ubiquitous living presence existing in the real world. These examples challenge us to imagine interfaces of the future, where AI is not a feature to be learned, but a presence to be felt.\",[1034,1038,1039,1043,1044,1045,1046,1050,1054,1058,1059],{\"_31\":1035,\"_33\":1036,\"_35\":1037},\"awilson\",\"Andy Wilson\",\"awilson@microsoft.com\",{\"_31\":848,\"_33\":849,\"_35\":850},{\"_31\":1040,\"_33\":1041,\"_35\":1042},\"romathugo\",\"Hugo ROMAT\",\"romathugo@microsoft.com\",{\"_31\":852,\"_33\":853,\"_35\":854},{\"_31\":530,\"_33\":531,\"_35\":532},{\"_31\":860,\"_33\":861,\"_35\":862},{\"_31\":1047,\"_33\":1048,\"_35\":1049},\"maiastiber\",\"Maia Stiber\",\"maiastiber@microsoft.com\",{\"_31\":1051,\"_33\":1052,\"_35\":1053},\"mpahud\",\"Michel Pahud\",\"mpahud@microsoft.com\",{\"_31\":1055,\"_33\":1056,\"_35\":1057},\"nicmarquardt\",\"Nic Marquardt\",\"nicmarquardt@microsoft.com\",{\"_31\":872,\"_33\":873,\"_35\":874},{\"_31\":1060,\"_33\":1061,\"_35\":1062,\"_41\":42},\"nath\",\"Nathalie Riche\",\"nath@microsoft.com\",[837],\"2025-10-30T14:13:54.703Z\",\"2025-11-06T17:37:17.320Z\",[],[],\"3368\",{\"_18\":1070,\"_20\":1071,\"_22\":1072,\"_24\":456,\"_26\":27,\"_28\":1073,\"_43\":1098,\"_48\":1099,\"_50\":1100,\"_52\":1101,\"_62\":1102,\"_64\":101,\"_66\":67,\"_68\":1103},\"RRS25-PROJ-035\",\"Frantic\",\"Robot foundation models in action.\",[1074,1078,1082,1086,1090,1094],{\"_31\":1075,\"_33\":1076,\"_35\":1077,\"_41\":42},\"akolobov\",\"Andrey Kolobov\",\"akolobov@microsoft.com\",{\"_31\":1079,\"_33\":1080,\"_35\":1081},\"v-defortier\",\"Dean Fortier (Actalent Services LLC)\",\"v-defortier@microsoft.com\",{\"_31\":1083,\"_33\":1084,\"_35\":1085},\"galenmullins\",\"Galen Mullins\",\"galenmullins@microsoft.com\",{\"_31\":1087,\"_33\":1088,\"_35\":1089},\"michaemurray\",\"Michael Murray\",\"michaemurray@microsoft.com\",{\"_31\":1091,\"_33\":1092,\"_35\":1093},\"tanreuben\",\"Reuben Tan\",\"tanreuben@microsoft.com\",{\"_31\":1095,\"_33\":1096,\"_35\":1097},\"tessh\",\"Tess Hellebrekers\",\"tessh@microsoft.com\",[467],\"2025-10-30T14:13:54.583Z\",\"2025-11-03T19:20:37.601Z\",[],[],\"1535 (Robotics Lab)\",{\"_18\":1105,\"_20\":1106,\"_22\":1107,\"_24\":558,\"_26\":1108,\"_28\":1109,\"_43\":1125,\"_48\":1126,\"_50\":1127,\"_52\":1128,\"_62\":1129,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-092\",\"From Lab to Fleet: A Practical Rowhammer Defense for Cloud SoCs\",\"Rowhammer attacks pose a significant threat to modern DRAM, with potentially serious security consequences for a cloud vendor, such as data corruption or infrastructure outages. Existing defenses fail to satisfy key industry requirements, including minimal overhead in the absence of attacks, predictable performance when under attack, system liveness, low hardware cost, adaptability to diverse hardware configurations, and tunable security guarantees.\\n\\nThis project describes Sigries, a hybrid Rowhammer defense implemented by Microsoft in the upcoming Cobalt 200 SoC. Sigries combines the Misra-Gries algorithm for efficient row tracking with a fallback row-sampling mode for robustness under all attack scenarios. Sigries’s design meets all our performance goals and offers configurable security guarantees allowing a cloud vendor to assess the security risks to its fleet. Our trace-driven evaluation shows that Sigries maintains minimal DRAM bandwidth overhead and ensures robust performance.\",\"\u003ciframe src=\\\"https://microsoft.sharepoint.com/teams/MSRNVA01/_layouts/15/embed.aspx?UniqueId=6e7eb067-d0de-43a6-9c33-b76bc4572c3c\u0026embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D\u0026referrer=StreamWebApp\u0026referrerScenario=EmbedDialog.Create\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" allowfullscreen title=\\\"58441.mp4\\\"\u003e\u003c/iframe\u003e\",[1110,1111,1115,1119,1120,1121],{\"_31\":943,\"_33\":944,\"_35\":945},{\"_31\":1112,\"_33\":1113,\"_35\":1114},\"daberg\",\"Daniel Berger\",\"daberg@microsoft.com\",{\"_31\":1116,\"_33\":1117,\"_35\":1118},\"ishernan\",\"Isaac Hernandez Luna\",\"ishernan@microsoft.com\",{\"_31\":412,\"_33\":413,\"_35\":414},{\"_31\":951,\"_41\":42,\"_33\":952,\"_35\":953},{\"_31\":1122,\"_33\":1123,\"_35\":1124},\"peremakl\",\"Will Remaklus\",\"peremakl@microsoft.com\",[],\"2025-10-30T14:13:54.642Z\",\"2025-11-04T02:56:03.839Z\",[],[],{\"_18\":1131,\"_20\":1132,\"_22\":1133,\"_24\":248,\"_26\":27,\"_28\":1134,\"_43\":1137,\"_48\":1139,\"_50\":1140,\"_52\":1141,\"_62\":1142,\"_64\":101,\"_66\":67,\"_68\":292},\"RRS25-PROJ-087\",\"GitHub Agentic Workflows\",\"Write agentic workflows in natural language markdown, and run them safely in GitHub Actions.\",[1135,1136],{\"_31\":252,\"_35\":254,\"_33\":253},{\"_31\":256,\"_33\":257,\"_35\":258,\"_41\":42},[1138],\"Programming Languages/Software\",\"2025-10-30T14:13:54.763Z\",\"2025-10-31T23:30:15.315Z\",[],[],{\"_18\":1144,\"_20\":1145,\"_22\":1146,\"_24\":248,\"_26\":1147,\"_28\":1148,\"_43\":1185,\"_48\":1186,\"_50\":1187,\"_52\":1188,\"_62\":1191,\"_64\":101,\"_66\":67,\"_68\":102},\"RRS25-PROJ-083\",\"GraphRAG Code Next\",\"GraphRAG Code applies GraphRAG to your source code using the semantics of the source code to enhance code understanding. GraphRAG Code has been rebuilt with scalability and improved speed in mind.\",\"\u003ciframe src=\\\"https://microsoft.sharepoint.com/teams/MSRNVA01/_layouts/15/embed.aspx?UniqueId=d321a2a1-7c33-45f5-8d4d-61b860d6bffd\u0026embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D\u0026referrer=StreamWebApp\u0026referrerScenario=EmbedDialog.Create\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" allowfullscreen title=\\\"58420.mp4\\\"\u003e\u003c/iframe\u003e\",[1149,1153,1157,1161,1165,1169,1173,1177,1181],{\"_31\":1150,\"_33\":1151,\"_35\":1152,\"_41\":42},\"brtower\",\"Bryan Tower\",\"brtower@microsoft.com\",{\"_31\":1154,\"_33\":1155,\"_35\":1156},\"caburact\",\"Carolyn Buractaon\",\"caburact@microsoft.com\",{\"_31\":1158,\"_33\":1159,\"_35\":1160},\"chtrevin\",\"Chris Trevino\",\"chtrevin@microsoft.com\",{\"_31\":1162,\"_33\":1163,\"_35\":1164},\"daxpryce\",\"Dax Pryce\",\"daxpryce@microsoft.com\",{\"_31\":1166,\"_33\":1167,\"_35\":1168},\"jolarso\",\"Jonathan Larson\",\"jolarso@microsoft.com\",{\"_31\":1170,\"_33\":1171,\"_35\":1172},\"jomclean\",\"Jonathan McLean\",\"jomclean@microsoft.com\",{\"_31\":1174,\"_33\":1175,\"_35\":1176},\"nicaurvi\",\"Nick Caurvina\",\"nicaurvi@microsoft.com\",{\"_31\":1178,\"_33\":1179,\"_35\":1180},\"pbourke\",\"Patrick Bourke\",\"pbourke@microsoft.com\",{\"_31\":1182,\"_33\":1183,\"_35\":1184},\"rracanicci\",\"Rodrigo Racanicci\",\"rracanicci@microsoft.com\",[],\"2025-10-30T14:13:54.820Z\",\"2025-10-31T22:41:24.255Z\",[1189],{\"_55\":60,\"_57\":1190,\"_20\":27},\"https://github.com/research-at-redmond/graphragcode\",[],{\"_18\":1193,\"_20\":1194,\"_22\":1195,\"_24\":107,\"_26\":1196,\"_28\":1197,\"_43\":1208,\"_48\":1210,\"_50\":1211,\"_52\":1212,\"_62\":1213,\"_64\":101,\"_66\":67,\"_68\":102},\"RRS25-PROJ-026\",\"GraphRAG Zero on Enterprise Productivity Data\",\"In this demonstration, we will showcase our new GraphRAG Zero technology, which is the successor to both GraphRAG and LazyGraphRAG.  This will focus on applications of the technology to Enterprise Productivity Data and demonstrate new product capabilities that are enabled by use of these new LLM memory structures.\",\"\u003ciframe src=\\\"https://microsoft.sharepoint.com/teams/MSRNVA01/_layouts/15/embed.aspx?UniqueId=c21a2e25-fd36-44d7-ac55-3ef7442b7cb2\u0026embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D\u0026referrer=StreamWebApp\u0026referrerScenario=EmbedDialog.Create\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" allowfullscreen title=\\\"58411.mp4\\\"\u003e\u003c/iframe\u003e\",[1198,1202,1206,1207],{\"_31\":1199,\"_33\":1200,\"_35\":1201},\"daedge\",\"Darren Edge\",\"daedge@microsoft.com\",{\"_31\":1203,\"_33\":1204,\"_35\":1205},\"trinhha\",\"Ha Trinh\",\"trinhha@microsoft.com\",{\"_31\":1166,\"_33\":1167,\"_35\":1168,\"_41\":42},{\"_31\":1182,\"_33\":1183,\"_35\":1184},[47,1209],\"Knowledge graph\",\"2025-10-30T14:13:54.877Z\",\"2025-10-31T16:27:16.642Z\",[],[],{\"_18\":1215,\"_20\":1216,\"_22\":1217,\"_24\":248,\"_26\":1218,\"_28\":1219,\"_43\":1232,\"_48\":1233,\"_50\":1234,\"_52\":1235,\"_62\":1236,\"_64\":101,\"_66\":67,\"_68\":102},\"RRS25-PROJ-088\",\"GraphRAG Σ: Software Insights and Guidance from Myriad Artifacts\",\"GraphRAG SIGMA (Software Insights and Guidance from Multiple Artifacts) is a flexible, agentic AI platform designed to leverage large-scale software engineering artifacts including source code, build data, test results, code reviews, work items, team knowledge bases, and telemetry to address pain points in the software development lifecycle.  By combining advanced reasoning through GraphRAG and GraphRAGCode with specialized agents for information retrieval, GraphRag SIGMA empowers engineering teams to make faster, evidence-based decisions with full transparency and human-in-the-loop control. In the November Research Showcase, we’ll demonstrate this platform in a differential testing scenario, showing how it assembles evidence, explains its reasoning, and responds to human guidance. GraphRAG SIGMA’s flexibility and extensibility enable it to support scenarios as diverse as incident analysis, release readiness reviews, security investigations, and bug triage, ultimately boosting productivity and decision quality across the software organization.\",\"\u003ciframe src=\\\"https://microsoft.sharepoint.com/teams/MSRNVA01/_layouts/15/embed.aspx?UniqueId=55b0012d-83ee-422b-a44c-9608311b2b62\u0026embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D\u0026referrer=StreamWebApp\u0026referrerScenario=EmbedDialog.Create\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" allowfullscreen title=\\\"58446.mp4\\\"\u003e\u003c/iframe\u003e\",[1220,1224,1228],{\"_31\":1221,\"_33\":1222,\"_35\":1223},\"cabadea\",\"Carmen Badea\",\"cabadea@microsoft.com\",{\"_31\":1225,\"_33\":1226,\"_35\":1227,\"_41\":42},\"cbird\",\"Christian Bird\",\"cbird@microsoft.com\",{\"_31\":1229,\"_33\":1230,\"_35\":1231},\"rdeline\",\"Rob DeLine (HE/HIM)\",\"rdeline@microsoft.com\",[],\"2025-10-30T14:13:54.934Z\",\"2025-11-04T02:57:52.867Z\",[],[],{\"_18\":1238,\"_20\":1239,\"_22\":1240,\"_24\":297,\"_26\":1241,\"_28\":1242,\"_43\":1263,\"_48\":1265,\"_50\":1266,\"_52\":1267,\"_62\":1268,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-049\",\"GridFM - Foundational Power Grid Modeling\",\"GridFM is a physics-aware foundation model for power systems that approximates AC optimal power flow (AC-OPF) solutions across diverse network topologies and operating regimes. It produces limit-safe operating points (voltage, thermal, generator) with low-latency, high-throughput inference and built-in guardrails—AC power-flow residual checks plus solver fallback—for real-time decisions. It can be used by many stakeholders across grid operations—for example: datacenter developers to screen and rank sites by cost, reliability, and grid headroom; renewable developers/operators to assess hosting capacity, curtailment risk, and congestion impacts; and grid operators to triage N-k contingencies, surface vulnerable buses/lines, and guide reconfiguration and targeted upgrades.\",\"\u003ciframe src=\\\"https://microsoft.sharepoint.com/teams/MSRNVA01/_layouts/15/embed.aspx?UniqueId=a395957a-cf40-4677-84d5-3287129add6e\u0026embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D\u0026referrer=StreamWebApp\u0026referrerScenario=EmbedDialog.Create\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" allowfullscreen title=\\\"58415.mp4\\\"\u003e\u003c/iframe\u003e\",[1243,1247,1251,1255,1259],{\"_31\":1244,\"_33\":1245,\"_35\":1246},\"andreabri\",\"Andrea Britto\",\"andreabri@microsoft.com\",{\"_31\":1248,\"_33\":1249,\"_35\":1250},\"kalytv\",\"Kate Lytvynets\",\"kalytv@microsoft.com\",{\"_31\":1252,\"_33\":1253,\"_35\":1254},\"sfowers\",\"Spencer Fowers\",\"sfowers@microsoft.com\",{\"_31\":1256,\"_33\":1257,\"_35\":1258},\"tvallinspina\",\"Thiago Spina\",\"tvallinspina@microsoft.com\",{\"_31\":1260,\"_33\":1261,\"_35\":1262,\"_41\":42},\"weiwya\",\"Weiwei Yang\",\"weiwya@microsoft.com\",[45,1264],\"power management\",\"2025-10-30T14:13:54.991Z\",\"2025-10-31T16:36:13.578Z\",[],[],{\"_18\":1270,\"_20\":1271,\"_22\":1272,\"_24\":558,\"_26\":27,\"_28\":1273,\"_43\":1286,\"_48\":1287,\"_50\":1288,\"_52\":1289,\"_62\":1290,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-093\",\"Hardware Acceleration for Zero-Knowledge Proof (ZKP) Systems\",\"Zero-knowledge proofs (ZKPs) have emerged as powerful cryptographic tools for ensuring privacy and security in various applications, offering a way to authenticate information without revealing the underlying data. Applications that are motivated by ZKPs range from privacy-preserving identity verification, secure and private voting systems to privacy-preserving data usage in AI and machine learning systems, among others. With the increasing focus on confidential computing, one can envision applications that combine ZKPs with other techniques for secure computing such as TEE and MPC. On the downside, the computing-intensive nature of ZKPs, especially on the prover (typically, server) side, has long been a barrier for their widespread adoption.\\nIn this project, we study, design, and implement hardware accelerators to optimize the most computationally intensive operations in ZKP systems. In particular, we are interested in exploring some of the recent hash-based ZKP constructions, in order to assess their feasibility for hardware acceleration.\",[1274,1278,1282],{\"_31\":1275,\"_33\":1276,\"_35\":1277,\"_41\":42},\"plonga\",\"Patrick Longa\",\"plonga@microsoft.com\",{\"_31\":1279,\"_33\":1280,\"_35\":1281},\"sfuller\",\"Scott Fuller (SECURITY)\",\"sfuller@microsoft.com\",{\"_31\":1283,\"_33\":1284,\"_35\":1285},\"yuctao\",\"Yucong Tao\",\"yuctao@microsoft.com\",[574,575],\"2025-10-30T14:13:55.049Z\",\"2025-10-31T16:54:25.369Z\",[],[],{\"_18\":1292,\"_20\":1293,\"_22\":1294,\"_24\":837,\"_26\":27,\"_28\":1295,\"_43\":1304,\"_48\":1307,\"_50\":1308,\"_52\":1309,\"_62\":1310,\"_64\":101,\"_66\":149,\"_68\":1311},\"RRS25-PROJ-065\",\"Headphones? Who Needs Them? Spatial Audio for Your Laptop and Tablet!\",\"In the demo, we use an array of 2 to 5 loudspeakers integrated into a laptop or tablet to deliver two distinct audio beams - one to each ear. Computer vision techniques, combined with the laptop’s camera, enable real-time tracking of head position and orientation. Spatial audio rendering is handled by Windows Sonic for Headphones, the built-in spatial audio system in Windows.\",[1296,1300],{\"_31\":1297,\"_33\":1298,\"_35\":1299,\"_41\":42},\"davidjo\",\"David Johnston\",\"davidjo@microsoft.com\",{\"_31\":1301,\"_33\":1302,\"_35\":1303},\"ivantash\",\"Ivan Tashev\",\"ivantash@microsoft.com\",[1305,1306],\"Spatial audio\",\"Computer vision\",\"2025-10-30T14:13:55.109Z\",\"2025-11-03T21:54:44.971Z\",[],[],\"3311\",{\"_18\":1313,\"_20\":1314,\"_22\":1315,\"_24\":428,\"_26\":27,\"_28\":1316,\"_43\":1326,\"_48\":1327,\"_50\":1328,\"_52\":1329,\"_62\":1330,\"_64\":101,\"_66\":149,\"_68\":451},\"RRS25-PROJ-060\",\"How to Value Your Database Cache: Improved Memory Management for Serverless OLTP Databases\",\"Serverless cloud data management systems like Azure SQL Serverless and Amazon Aurora Serverless aim to provision sufficient compute and memory to serve customers' fluctuating workloads. Unlike statically provisioned alternatives, the value proposition of serverless offerings is a \\\"set and forget\\\" interface to automatically choose a ``good'' provisioning as the resource requirements of the workload grow and shrink. However, we find that current serverless provisioning mechanisms systematically over-provision memory for a wide range of reasonable workload patterns. That is, current solutions tend to acquire and hold vast amounts of memory with small marginal benefits to workload performance. We propose a new cache management mechanism for serverless databases that allows both users and providers to trade off cost and performance for a wide range of workloads.\",[1317,1321,1325],{\"_31\":1318,\"_33\":1319,\"_35\":1320},\"chrisko\",\"Christian Konig\",\"chrisko@microsoft.com\",{\"_31\":1322,\"_41\":42,\"_33\":1323,\"_35\":1324},\"matperron\",\"Matt Perron\",\"matperron@microsoft.com\",{\"_31\":443,\"_33\":444,\"_35\":445},[428],\"2025-10-30T14:13:55.167Z\",\"2025-10-31T16:41:09.000Z\",[],[],{\"_18\":1332,\"_20\":1333,\"_22\":1334,\"_24\":186,\"_26\":27,\"_28\":1335,\"_43\":1347,\"_48\":1348,\"_50\":1349,\"_52\":1350,\"_62\":1351,\"_64\":101,\"_66\":67,\"_68\":218},\"RRS25-PROJ-076\",\"Improving KV-cache efficiency for LLM inference\",\"As large language models are deployed for increasingly complex workloads and extended user interactions, the accumulation of context presents significant challenges. The KV-cache, which stores key and value tensors for all previous tokens, expands proportionally with context length, which directly impacts request latencies, throughput, and resource consumption. Prefix caching is a promising approach to mitigate these challenges by storing previously computed KV-caches and retrieving them efficiently when a prompt shares an exact matching prefix with a cached prompt. To serve a prefix caching at scale, we can look beyond high-bandwidth memory (HBM), towards a dedicated capacity tier—a memory tier characterized by higher capacity but potentially much lower bandwidth.\\n\\nWe analyse the benefits and hardware requirements of a performant prefix cache, grounded in empirical observations across different workloads, including internal M365 applications. We identify that prefix caching can successfully reduce redundant computation to improve prefill throughput per GPU, while operating at realizable DRAM capacity with minimal overhead to commodity communication links. Once the KV-cache is offloaded to a capacity tier, further optimizations such as KV-cache distillation; also become possible off the inference path, reducing the bandwidth, storage, and computation needs of the KV-cache further.\\n\\nPrefix sharing can, in theory, also benefit decode operations, though the benefits are less well-understood than for prefill. We evaluate one such method, cascade inference, for workloads with high levels of prefix sharing, such as post-training with reinforcement learning. Together, prefix caching, judicious use of memory tiers, and post-offload optimizations can constitute a holistic approach to addressing the context accumulation challenge in large language model serving.\",[1336,1337,1338,1339,1343],{\"_31\":197,\"_33\":198,\"_35\":199},{\"_31\":491,\"_41\":42,\"_33\":492,\"_35\":493},{\"_31\":209,\"_33\":210,\"_35\":211},{\"_31\":1340,\"_33\":1341,\"_35\":1342},\"smastorakis\",\"Spyros Mastorakis\",\"smastorakis@microsoft.com\",{\"_31\":1344,\"_33\":1345,\"_35\":1346},\"taisazawa\",\"Taketomo Isazawa\",\"taisazawa@microsoft.com\",[46],\"2025-10-30T14:13:55.224Z\",\"2025-10-31T23:21:50.924Z\",[],[],{\"_18\":1353,\"_20\":1354,\"_22\":1355,\"_24\":186,\"_26\":27,\"_28\":1356,\"_43\":1377,\"_48\":1379,\"_50\":1380,\"_52\":1381,\"_62\":1382,\"_64\":101,\"_66\":67,\"_68\":218},\"RRS25-PROJ-077\",\"Inference 2030: Circuit-Switched Networks for Efficient AI\",\"Clusters for AI are incredibly power-hungry. While GPUs are the biggest consumer, networking can account for something like 20% of power usage in AI training clusters today, and we expect this to increase by 2030 as demands for bandwidth and connectivity grow. \\n\\nWe’re exploring how optical circuit switches can help. These devices switch light rather than packets—this lets them use 5-10x less power than a packet switch, but at the cost of way less flexibility. This lack of flexibility has limited their use to other parts of the datacenter to date, but AI workloads have properties we can leverage to take advantage of their benefits. \\n\\nOur models indicate that with the right combination of approaches, we can replace the majority of switches in AI clusters with optical circuit switches, closely approximating the performance of packet-switched networks at a fraction of the power. We’ll explain this and show an interactive demo of inference running over a circuit-switched network.\",[1357,1361,1365,1367,1368,1372,1373],{\"_31\":1358,\"_33\":1359,\"_35\":1360},\"bearzani\",\"Behnaz Arzani\",\"bearzani@microsoft.com\",{\"_31\":1362,\"_33\":1363,\"_35\":1364},\"dports\",\"Dan Ports\",\"dports@microsoft.com\",{\"_31\":491,\"_33\":492,\"_35\":1366},\"jacnels@microsoft.com\",{\"_31\":491,\"_41\":42,\"_33\":492,\"_35\":493},{\"_31\":1369,\"_33\":1370,\"_35\":1371},\"ncheriere\",\"Nathanaël Cheriere\",\"ncheriere@microsoft.com\",{\"_31\":499,\"_33\":500,\"_35\":501},{\"_31\":1374,\"_33\":1375,\"_35\":1376},\"xingbowu\",\"Xingbo Wu\",\"xingbowu@microsoft.com\",[45,1378],\"Power usage\",\"2025-10-30T14:13:55.284Z\",\"2025-10-31T16:48:42.916Z\",[],[],{\"_18\":1384,\"_20\":1385,\"_22\":1386,\"_24\":186,\"_26\":27,\"_28\":1387,\"_43\":1478,\"_48\":1479,\"_50\":1480,\"_52\":1481,\"_62\":1482,\"_64\":101,\"_66\":67,\"_68\":218},\"RRS25-PROJ-078\",\"Inference 2030: Reimagining Next-generation AI Systems\",\"Microsoft Research sees a significant opportunity to reimagine AI infrastructure for inference and training over the next 5 years.  As the model ecosystem continues to evolve at a rapid pace and demand outstrips supply for GPUs/accelerators and the power required to run them, there is an opportunity to radically rethink hardware, network, and software design in the datacenter.  \\n\\nInference 2030 is a research initiative that focuses on high-risk, high-upside projects to meet these opportunities by partnering across Microsoft and exploiting recent innovations inside and outside Microsoft Research. As model sizes have grown, workloads have become more IO- and memory-bound, constraining end-to-end performance. We are exploring how we can remove network and memory bottlenecks using novel system designs and architectures, looking for opportunities across the systems stack all the way from the device level to the application level. \\n\\nOur objective is to deliver higher throughput and lower cost infrastructure that is agnostic to both changes in the rapidly advancing frontier language models and new, more powerful GPU compute architectures. This poster will provide an overview of the project and introduce other posters and demos from key workstreams.\",[1388,1389,1390,1394,1398,1399,1400,1404,1408,1412,1416,1417,1421,1422,1423,1424,1425,1426,1430,1434,1435,1436,1437,1441,1445,1449,1450,1451,1455,1456,1460,1463,1464,1468,1469,1473,1477],{\"_31\":189,\"_33\":190,\"_35\":191},{\"_31\":193,\"_33\":194,\"_35\":195},{\"_31\":1391,\"_33\":1392,\"_35\":1393},\"anchatzi\",\"Andromachi Chatzieleftheriou\",\"anchatzi@microsoft.com\",{\"_31\":1395,\"_33\":1396,\"_35\":1397},\"argome\",\"Ariel Gomez Diaz\",\"argome@microsoft.com\",{\"_31\":197,\"_33\":198,\"_35\":199},{\"_31\":1362,\"_33\":1363,\"_35\":1364},{\"_31\":1401,\"_33\":1402,\"_35\":1403},\"dasween\",\"David Sweeney\",\"dasween@microsoft.com\",{\"_31\":1405,\"_33\":1406,\"_35\":1407},\"enightingale\",\"Ed Nightingale\",\"enightingale@microsoft.com\",{\"_31\":1409,\"_33\":1410,\"_35\":1411},\"t-fabianotto\",\"Fabian Otto\",\"t-fabianotto@microsoft.com\",{\"_31\":1413,\"_33\":1414,\"_35\":1415},\"gokuma\",\"Gopi Kumar\",\"gokuma@microsoft.com\",{\"_31\":479,\"_33\":480,\"_35\":481},{\"_31\":1418,\"_33\":1419,\"_35\":1420},\"hughwi\",\"Hugh Williams\",\"hughwi@microsoft.com\",{\"_31\":487,\"_33\":488,\"_35\":489},{\"_31\":763,\"_33\":764,\"_35\":765},{\"_31\":491,\"_33\":492,\"_35\":1366},{\"_31\":491,\"_41\":42,\"_33\":492,\"_35\":493},{\"_31\":495,\"_33\":496,\"_35\":497},{\"_31\":1427,\"_33\":1428,\"_35\":1429},\"kaishi\",\"Kai Shi\",\"kaishi@microsoft.com\",{\"_31\":1431,\"_33\":1432,\"_35\":1433},\"kbenyahya\",\"Kaoutar Benyahya\",\"kbenyahya@microsoft.com\",{\"_31\":309,\"_33\":310,\"_35\":311},{\"_31\":775,\"_33\":776,\"_35\":777},{\"_31\":670,\"_33\":671,\"_35\":672},{\"_31\":1438,\"_33\":1439,\"_35\":1440},\"mmolinaro\",\"Marco Molinaro\",\"mmolinaro@microsoft.com\",{\"_31\":1442,\"_33\":1443,\"_35\":1444},\"mpantouvaki\",\"Marianna Pantouvaki\",\"mpantouvaki@microsoft.com\",{\"_31\":1446,\"_33\":1447,\"_35\":1448},\"meny\",\"Mengyang Yang\",\"meny@microsoft.com\",{\"_31\":1369,\"_33\":1370,\"_35\":1371},{\"_31\":499,\"_33\":500,\"_35\":501},{\"_31\":1452,\"_33\":1453,\"_35\":1454},\"rjblack\",\"Richard Black\",\"rjblack@microsoft.com\",{\"_31\":201,\"_33\":202,\"_35\":203},{\"_31\":1457,\"_33\":1458,\"_35\":1459},\"sadjadfouladi\",\"Sadjad Fouladi\",\"sadjadfouladi@microsoft.com\",{\"_31\":209,\"_33\":1461,\"_35\":1462},\"Sankara Narayanan M S\",\"sanaray@microsoft.com\",{\"_31\":504,\"_33\":505,\"_35\":506},{\"_31\":1465,\"_33\":1466,\"_35\":1467},\"ssiew\",\"Shawn Yohanes Siew\",\"ssiew@microsoft.com\",{\"_31\":439,\"_33\":440,\"_35\":441},{\"_31\":1470,\"_33\":1471,\"_35\":1472},\"vassilyl\",\"Vassily Lyutsarev\",\"vassilyl@microsoft.com\",{\"_31\":1474,\"_33\":1475,\"_35\":1476},\"weisliu\",\"Weishung Liu\",\"weisliu@microsoft.com\",{\"_31\":1374,\"_33\":1375,\"_35\":1376},[],\"2025-10-30T14:13:55.341Z\",\"2025-10-31T23:25:26.535Z\",[],[],{\"_18\":1484,\"_20\":1485,\"_22\":1486,\"_24\":297,\"_26\":27,\"_28\":1487,\"_43\":1508,\"_48\":1510,\"_50\":1511,\"_52\":1512,\"_62\":1513,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-046\",\"Inference Delivery for Large-scale Multi-modal AI Applications\",\"We propose a novel caching technique to enhance the efficiency of inference delivery in large-scale AI systems. Our approach leverages intermediate representations (IRs) generated by large language models, which are stored as reusable artifacts. These cached IRs can be adapted to generate responses for new user queries using smaller, more cost-effective models. This approach aims to reduce computational overhead and lower the cost of inference, while preserving response quality.\",[1488,1492,1496,1500,1504],{\"_31\":1489,\"_33\":1490,\"_35\":1491},\"ga\",\"Ganesh Ananthanarayanan\",\"ga@microsoft.com\",{\"_31\":1493,\"_33\":1494,\"_35\":1495},\"kevhsieh\",\"Kevin Hsieh\",\"kevhsieh@microsoft.com\",{\"_31\":1497,\"_33\":1498,\"_35\":1499},\"krchinta\",\"Krishna Chintalapudi\",\"krchinta@microsoft.com\",{\"_31\":1501,\"_33\":1502,\"_35\":1503,\"_41\":42},\"samani\",\"Sathiya Kumaran Mani\",\"samani@microsoft.com\",{\"_31\":1505,\"_33\":1506,\"_35\":1507},\"sujbanerjee\",\"Sujata Banerjee\",\"sujbanerjee@microsoft.com\",[1509,45],\"Inference\",\"2025-10-30T14:13:55.404Z\",\"2025-10-31T16:35:43.381Z\",[],[],{\"_18\":1515,\"_20\":1516,\"_22\":1517,\"_24\":456,\"_26\":27,\"_28\":1518,\"_43\":1524,\"_48\":1525,\"_50\":1526,\"_52\":1527,\"_62\":1528,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-036\",\"Intent Tracking in LLMs Under Noise and Under-Specification\",\"LLMs/LRMs often fail when key information is missing or when inputs are noisy. Prior work highlights two failure modes: users withholding context and noise overwhelming signal. We ask:\\n\\nRQ1: How do different models break down under increasing underspecification?\\n\\nRQ2: How do they falter as noise grows?\\n\\nOur goal is to systematically map model weaknesses across these stress conditions. To address this, we propose an inference time strategy that dynamically decides whether to ask a clarifying question, make an assumption, or take action—ensuring progress without overwhelming the user. Framed through decision theory, we treat dialogue as a tradeoff between information gain and user effort. Our hypothesis: an assistant that maintains beliefs about the user’s true goal and only intervenes when the expected payoff outweighs the cost will outperform today’s rigid heuristics.\",[1519,1520],{\"_31\":463,\"_33\":464,\"_35\":465},{\"_31\":1521,\"_33\":1522,\"_35\":1523,\"_41\":42},\"pekumar\",\"Peeyush Kumar\",\"pekumar@microsoft.com\",[467],\"2025-10-30T14:13:55.462Z\",\"2025-10-30T22:50:48.935Z\",[],[],{\"_18\":1530,\"_20\":1531,\"_22\":1532,\"_24\":297,\"_26\":1533,\"_28\":1534,\"_43\":1547,\"_48\":1549,\"_50\":1550,\"_52\":1551,\"_62\":1552,\"_64\":101,\"_66\":67,\"_68\":102},\"RRS25-PROJ-050\",\"Job Execution Infrastructure Playbook: How you can execute AI workloads better and faster on MSR's AI infrastructure\",\"This is a systematic framework to diagnose performance issues and optimize our deep learning training workloads, with the primary goal of maximizing the return on our significant GPU hardware investment. This data-driven methodology moves us beyond ad-hoc fixes by providing a structured, repeatable process to analyze our training jobs from three key perspectives: how work is scheduled by the CPU, how efficiently it executes on the GPU, and how it's parallelized across multiple machines. For each area, we first measure performance to precisely identify bottlenecks, and then use a clear analytical model to understand the root cause. This enables us to make deliberate, strategic trade-offs between core resources—computation speed, memory cost, and communication overhead.\",\"\u003ciframe src=\\\"https://microsoft.sharepoint.com/teams/MSRNVA01/_layouts/15/embed.aspx?UniqueId=438db3b1-5c3b-461e-b2cb-eb1322376b78\u0026embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D\u0026referrer=StreamWebApp\u0026referrerScenario=EmbedDialog.Create\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" allowfullscreen title=\\\"58416.mp4\\\"\u003e\u003c/iframe\u003e\",[1535,1539,1543],{\"_31\":1536,\"_33\":1537,\"_35\":1538},\"cesarmart\",\"Cesar Martinez Spessot\",\"cesarmart@microsoft.com\",{\"_31\":1540,\"_33\":1541,\"_35\":1542},\"v-krebseric\",\"Eric Krebs\",\"v-krebseric@microsoft.com\",{\"_31\":1544,\"_33\":1545,\"_35\":1546,\"_41\":42},\"lifli\",\"Lifeng Li\",\"lifli@microsoft.com\",[1548,45],\"AI workloads\",\"2025-10-30T14:13:55.518Z\",\"2025-11-01T01:56:47.603Z\",[],[],{\"_18\":1554,\"_20\":1555,\"_22\":1556,\"_24\":456,\"_26\":27,\"_28\":1557,\"_43\":1577,\"_48\":1578,\"_50\":1579,\"_52\":1580,\"_62\":1581,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-043\",\"Let’s Let’s Let’s Let’s… Understanding looping in reasoning models\",\"All reasoning models (e.g. O3, Deepseek R1) tend to often get stuck into infinite loops producing the same text  endlessly. In this project, we explore what causes this behavior and how can it be mitigated.\",[1558,1562,1566,1570,1571,1573],{\"_31\":1559,\"_33\":1560,\"_35\":1561},\"akshaykr\",\"Akshay Krishnamurthy\",\"akshaykr@microsoft.com\",{\"_31\":1563,\"_33\":1564,\"_35\":1565},\"dimitriosp\",\"Dimitris Papailiopoulos\",\"dimitriosp@microsoft.com\",{\"_31\":1567,\"_33\":1568,\"_35\":1569},\"shrivastavav\",\"Vaish Shrivastava\",\"shrivastavav@microsoft.com\",{\"_31\":987,\"_33\":988,\"_35\":989,\"_41\":42},{\"_31\":27,\"_35\":27,\"_33\":1572},\"Charis Pipis\",{\"_31\":1574,\"_33\":1575,\"_35\":1576},\"vkontonis\",\"Vasilis Kontonis\",\"vkontonis@microsoft.com\",[467],\"2025-10-30T14:13:55.579Z\",\"2025-11-03T21:34:56.213Z\",[],[],{\"_18\":1583,\"_20\":1584,\"_22\":1585,\"_24\":25,\"_26\":27,\"_28\":1586,\"_43\":1593,\"_48\":1594,\"_50\":1595,\"_52\":1596,\"_62\":1597,\"_64\":101,\"_66\":67,\"_68\":102},\"RRS25-PROJ-007\",\"Lexicon: A Proactive and Private Speech Interface to AI Devices\",\"With the rise of LLMs, speech is becoming a ubiquitous interface for interacting with AI-powered agents and devices. Lexicon addresses the need for proactive context capture—enabling AI agents to listen without wake words and build personalized memory—while prioritizing privacy and social acceptance.\\nUnlike reactive assistants like Siri or Alexa which respond to a wake word, or capture-everything model like Meta’s Ray-Ban glasses, Lexicon introduces a consent-aware, secure listening model. It operates in three stages:\\n\\n1. Voice Fingerprinting: Lexicon runs locally on the user’s device (e.g., smartphone or wearable), capturing and processing only the authorized user’s voice.\\n2. Contextual Memory Building: The agent uses first-person speech to build dynamic memory, enabling personalized task execution and decision-making.\\n3. Consent via Contact Tracing: Lexicon builds on BLE-based proximity tracing to detect other speakers and obtain consent for shared conversations and context.\\n\\nLexicon is designed to run on-device, ensuring energy efficiency, data sovereignty, and privacy by default. It redefines speech capture as a consensual and secure interaction, making proactive listening socially and ethically viable.\",[1587,1591,1592],{\"_31\":1588,\"_33\":1589,\"_35\":1590},\"lacox\",\"Landon Cox\",\"lacox@microsoft.com\",{\"_31\":1505,\"_33\":1506,\"_35\":1507},{\"_31\":547,\"_41\":42,\"_33\":546,\"_35\":548},[395,396,397],\"2025-10-30T14:13:55.640Z\",\"2025-10-30T22:39:27.553Z\",[],[],{\"_18\":1599,\"_20\":1600,\"_22\":1601,\"_24\":558,\"_26\":1602,\"_28\":1603,\"_43\":1624,\"_48\":1625,\"_50\":1626,\"_52\":1627,\"_62\":1628,\"_64\":101,\"_66\":67,\"_68\":102},\"RRS25-PROJ-094\",\"LiteBox: Rust-based Parametric Operating System for Secure Computing\",\"Collaboration between mutually distrusting parties is critical in today's AI and Cloud landscape.  Data owners, LLM owners, and cloud providers seek to collaborate without fully trusting each other.  Similarly, AI agents from different entities aim to work together without compromising trust.  Secure code execution technology is essential to facilitate these trustless collaborations---we need sandboxing.\\n \\nOur new sandboxing framework, LiteBox, introduces a parametric layered design, enabling broad applicability across diverse workloads.  LiteBox supports a range of popular feature-rich interfaces to the unmodified guest program (including the Linux ABI, and OP-TEE), while maintaining a highly minimized and defensible attack surface to any underlying host.  With this layering, we support safely running these guest programs on top of a number of platforms, including on Linux, Windows, LVBS, and for confidential computing.  Our implementation of LiteBox strikes a pragmatic balance between security, performance, and compatibility.  In short, LiteBox provides a secure foundation towards enabling safer multi-party collaboration.\",\"\u003ciframe src=\\\"https://microsoft.sharepoint.com/teams/MSRNVA01/_layouts/15/embed.aspx?UniqueId=82bd01f9-06a6-475e-b67a-e1b5d9cc38b4\u0026embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D\u0026referrer=StreamWebApp\u0026referrerScenario=EmbedDialog.Create\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" allowfullscreen title=\\\"58442.mp4\\\"\u003e\u003c/iframe\u003e\",[1604,1608,1612,1616,1620],{\"_31\":1605,\"_33\":1606,\"_35\":1607,\"_41\":42},\"jayb\",\"Jay Bosamiya\",\"jayb@microsoft.com\",{\"_31\":1609,\"_33\":1610,\"_35\":1611},\"sanghle\",\"Sangho Lee\",\"sanghle@microsoft.com\",{\"_31\":1613,\"_33\":1614,\"_35\":1615},\"wdcui\",\"Weidong Cui\",\"wdcui@microsoft.com\",{\"_31\":1617,\"_33\":1618,\"_35\":1619},\"weitengchen\",\"Weiteng Chen\",\"weitengchen@microsoft.com\",{\"_31\":1621,\"_33\":1622,\"_35\":1623},\"ziqiaozhou\",\"Ziqiao Zhou\",\"ziqiaozhou@microsoft.com\",[574,575],\"2025-10-30T14:13:55.702Z\",\"2025-11-03T23:06:13.563Z\",[],[],{\"_18\":1630,\"_20\":1631,\"_22\":1632,\"_24\":248,\"_26\":27,\"_28\":1633,\"_43\":1638,\"_48\":1639,\"_50\":1640,\"_52\":1641,\"_62\":1642,\"_64\":101,\"_66\":67,\"_68\":292},\"RRS25-PROJ-082\",\"Logitext: Formalizing Prompts for Production\",\"Programs increasingly contain natural-language (NL) prompts. Prompts enable breakthrough capabilities and require almost no learning curve for programmers. However, as these programs go to production, the imprecision of NL and the unpredictability of LLMs' statistical decoding cause reliability challenges.\\n\\nLogitext is a \\\"neurosymbolic\\\" hybrid of natural language (NL) and code that allows \\\"natural\\\" parts of intent to be expressed in NL, \\\"formal\\\" parts to be expressed as code (or formal logic), and the two to be finely meshed. Statistical decoding and logical solving jointly interpret this hybrid language. \\n\\nLogitext programs are not just more reliably correct, they also allow prompts to be checked like code. Logitext can automatically produce high-coverage unit tests for prompts, detect contradictions, perform property-based testing and enable compositional debugging. The resulting programs' behavior matches expectations more reliably than those based on traditional prompts.\",[1634,1635,1636,1637],{\"_31\":666,\"_33\":667,\"_35\":668},{\"_31\":674,\"_33\":675,\"_35\":676,\"_41\":42},{\"_31\":678,\"_33\":679,\"_35\":680,\"_41\":6},{\"_31\":686,\"_33\":687,\"_35\":688},[],\"2025-10-30T14:13:55.760Z\",\"2025-10-31T16:50:56.240Z\",[],[],{\"_18\":1644,\"_20\":1645,\"_22\":1646,\"_24\":456,\"_26\":27,\"_28\":1647,\"_43\":1657,\"_48\":1658,\"_50\":1659,\"_52\":1660,\"_62\":1661,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-038\",\"Lost in Transmission: When and Why LLMs Fail to Reason Globally\",\"Despite their many successes, transformer-based large language models (LLMs) continue to struggle with tasks that require complex reasoning over large parts of their input. We argue that these failures arise due to capacity limits on the accurate flow of information within LLMs. The framework we introduce offers principled explanations for key LLM failures and suggest directions for architectures and inference methods that mitigate bandwidth limits.\",[1648,1649,1653],{\"_31\":463,\"_33\":464,\"_35\":465},{\"_31\":1650,\"_33\":1651,\"_35\":1652},\"kitomlinson\",\"Kiran Tomlinson\",\"kitomlinson@microsoft.com\",{\"_31\":1654,\"_41\":42,\"_33\":1655,\"_35\":1656},\"toschnab\",\"Tobias Schnabel\",\"toschnab@microsoft.com\",[],\"2025-10-30T14:13:55.818Z\",\"2025-10-31T22:21:16.499Z\",[],[],{\"_18\":1663,\"_20\":1664,\"_22\":1665,\"_24\":297,\"_26\":27,\"_28\":1666,\"_43\":1683,\"_48\":49,\"_50\":1685,\"_52\":1686,\"_62\":1719,\"_64\":65,\"_66\":67,\"_68\":69},\"RRS25-PROJ-107\",\"M365 Research AIOps: AI Agents for Cloud Reliability \u0026 Dev Productivity Improvement\",\"Ensuring reliability and productivity at hyperscale is increasingly challenging as Cloud systems and AI agents grow in complexity. Traditional approaches to incident management and developer workflows often struggle to keep pace with scale, velocity, and operational noise. To address these challenges, we explore how AI agents can fundamentally enhance cloud reliability and developer productivity through three complementary directions: AI Agents for CloudOps, Improving Robustness of AI Agents, and Automating Code Migration at Scale.\\n\\nWe have deployed CloudOps agents across Microsoft’s E+D and Azure ecosystems to automate incident management from detection to mitigation. To strengthen reliability of AI agents, we developed a neuro-symbolic debugging framework that detects and explains agent failures, making them more predictable and trustworthy. In parallel, our self-learning code migration framework automates large-scale software transformations in a data-driven manner. Together, these efforts have reduced peak incident noise by 25%, shortened high-severity queues by 40%, lowered support costs by up to 80%, and adopted by over 50 teams across Microsoft. Our work has earned industry recognition and resulted in more than 20 publications and 10 patents.\",[1667,1671,1675,1679],{\"_31\":1668,\"_33\":1669,\"_35\":1670},\"minghuama\",\"Minghua Ma\",\"minghuama@microsoft.com\",{\"_31\":1672,\"_33\":1673,\"_35\":1674},\"xuchaozhang\",\"Xuchao Zhang\",\"xuchaozhang@microsoft.com\",{\"_31\":1676,\"_33\":1677,\"_35\":1678},\"chetanb\",\"Chetan Bansal\",\"chetanb@microsoft.com\",{\"_31\":1680,\"_41\":42,\"_33\":1681,\"_35\":1682},\"rujiawang\",\"Rujia Wang\",\"rujiawang@microsoft.com\",[1684],\"AIOps\",\"2025-10-31T23:42:31.943Z\",[1687,1690,1694,1697,1700,1703,1707,1710,1713,1716],{\"_55\":268,\"_57\":1688,\"_20\":1689},\"https://aka.ms/aiops-reliability\",\"Deep Dive Overview\",{\"_55\":1691,\"_57\":1692,\"_20\":1693},\"Documentation\",\"https://aka.ms/aiops-strategy\",\"AI Ops Strategy\",{\"_55\":1691,\"_57\":1695,\"_20\":1696},\"https://aka.ms/BeyondUptime \",\"Whitepaper\",{\"_55\":60,\"_57\":1698,\"_20\":1699},\"https://aka.ms/triangle-code\",\"Triangle code repo\",{\"_55\":275,\"_57\":1701,\"_20\":1702},\"https://aka.ms/triangle-blogpost\",\"Triangle blog post\",{\"_55\":1704,\"_57\":1705,\"_20\":1706},\"Live\",\"https://aka.ms/flash-doc\",\"Flash demo \u0026 documentation\",{\"_55\":1704,\"_57\":1708,\"_20\":1709},\"https://aka.ms/flash-playground-v2\",\"Flash Playground\",{\"_55\":60,\"_57\":1711,\"_20\":1712},\"https://aka.ms/TSGen-code\",\"TSGen Code Repo\",{\"_55\":1704,\"_57\":1714,\"_20\":1715},\"https://aka.ms/TSGen-demo\",\"TSGen Demo\",{\"_55\":56,\"_57\":1717,\"_20\":1718},\"https://aka.ms/agent-verification\",\"Improving Robustness of AI Agents\",[],{\"_18\":1721,\"_20\":1722,\"_22\":1723,\"_24\":25,\"_26\":27,\"_28\":1724,\"_43\":1733,\"_48\":49,\"_50\":1734,\"_52\":1735,\"_62\":1736,\"_64\":101,\"_66\":149,\"_68\":1737},\"RRS25-PROJ-108\",\"MSR Accelerator booth\",\"The MSRX booth will provide examples of how the MSR Accelerator partners with research teams to help breakthrough ideas into real world impact. By showcasing a small set of focused pilot projects such as rapid research prototyping tools or early customer aligned innovations, we will demonstrate how MSRX connects researchers, technology, and partners to mature promising work. We would like to leverage the MSR Research Showcase as a unique opportunity for researchers across Redmond to engage directly with us, discover incubation pathways, and explore how MSRX can help their ideas move faster toward impact.\",[1725,1729],{\"_31\":1726,\"_33\":1727,\"_35\":1728,\"_41\":42},\"xinma\",\"Xin Ma\",\"xinma@microsoft.com\",{\"_33\":1730,\"_31\":1731,\"_35\":1732,\"_41\":6},\"Shannon Monroe\",\"smonroe\",\"smonroe@microsoft.com\",[],\"2025-11-06T18:35:23.263Z\",[],[],\"3501\",{\"_18\":1739,\"_20\":1740,\"_22\":1741,\"_24\":297,\"_26\":27,\"_28\":1742,\"_43\":1751,\"_48\":49,\"_50\":1752,\"_52\":1753,\"_62\":1757,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-104\",\"MSR Hub\",\"MSR Hub is a secure and scalable hosting platform designed to streamline the project lifecycle for Microsoft Research (MSR) teams. The primary goal of MSR Hub is to enhance the digital presence of MSR projects by providing a centralized and secure environment for hosting, showcasing, and scaling research innovations. By removing infrastructure barriers and embedding security and operational best practices, MSR Hub accelerates the path from research to real-world impact, and facilitates internal collaboration.\",[1743,1747],{\"_31\":1744,\"_33\":1745,\"_35\":1746,\"_41\":42},\"hakhanpo\",\"Hamed Khanpour\",\"hakhanpo@microsoft.com\",{\"_31\":1748,\"_33\":1749,\"_35\":1750},\"lenin\",\"Lenin Ravindranath Sivalingam\",\"lenin@microsoft.com\",[],\"2025-10-31T16:57:21.233Z\",[1754],{\"_55\":285,\"_57\":1755,\"_20\":1756},\"https://aka.ms/msrhub\",\"Visit MSR Hub\",[],{\"_18\":1759,\"_20\":1760,\"_22\":1761,\"_24\":25,\"_26\":27,\"_28\":1762,\"_43\":1776,\"_48\":1777,\"_50\":1778,\"_52\":1779,\"_62\":1780,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-009\",\"MSR’s Innovation Hub: Hardware Lab and Technology Consulting\",\"Multi-disciplinary team of designers, engineers, and makers who bridge the gap between research ideas and their physical or electronic implementations.\",[1763,1767,1768,1772],{\"_31\":1764,\"_33\":1765,\"_35\":1766},\"chriod\",\"Christopher O'Dowd\",\"chriod@microsoft.com\",{\"_31\":534,\"_33\":535,\"_35\":536},{\"_31\":1769,\"_33\":1770,\"_35\":1771,\"_41\":42},\"mikeshep\",\"Mike Shepperd\",\"mikeshep@microsoft.com\",{\"_31\":1773,\"_33\":1774,\"_35\":1775},\"telascal\",\"Teresa LaScala\",\"telascal@microsoft.com\",[395,396,397],\"2025-10-30T14:13:56.099Z\",\"2025-10-30T22:40:05.446Z\",[],[],{\"_18\":1782,\"_20\":1783,\"_22\":1784,\"_24\":25,\"_26\":1785,\"_28\":1786,\"_43\":1873,\"_48\":1874,\"_50\":1875,\"_52\":1876,\"_62\":1877,\"_64\":101,\"_66\":67,\"_68\":102},\"RRS25-PROJ-002\",\"Magentic Marketplaces: An Environment for Studying Agentic Markets\",\"In this project we deep dive into \\\"agentic marketplaces\\\" where customers and businesses have I agent that represent them interests can and automate buying and selling of goods on their behalf. We'll present theory and results to understand what it would take to create a healthy and resilient agentic marketplace. \",\"\u003ciframe src=\\\"https://microsoft.sharepoint.com/teams/MSRNVA01/_layouts/15/embed.aspx?UniqueId=bd30043f-d02e-45f4-ab3b-bb9021edacc0\u0026embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D\u0026referrer=StreamWebApp\u0026referrerScenario=EmbedDialog.Create\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" allowfullscreen title=\\\"58408.MOV\\\"\u003e\u003c/iframe\u003e\",[1787,1791,1795,1799,1803,1807,1811,1815,1819,1823,1827,1828,1832,1833,1837,1841,1845,1849,1853,1857,1861,1865,1869],{\"_31\":1788,\"_33\":1789,\"_35\":1790},\"adamfo\",\"Adam Fourney\",\"adamfo@microsoft.com\",{\"_31\":1792,\"_33\":1793,\"_35\":1794},\"slivkins\",\"Alex Slivkins\",\"slivkins@microsoft.com\",{\"_31\":1796,\"_33\":1797,\"_35\":1798},\"aswearngin\",\"Amanda Swearngin\",\"aswearngin@microsoft.com\",{\"_31\":1800,\"_33\":1801,\"_35\":1802},\"brlucier\",\"Brendan Lucier\",\"brlucier@microsoft.com\",{\"_31\":1804,\"_33\":1805,\"_35\":1806},\"chsingh\",\"Chinmay Singh\",\"chsingh@microsoft.com\",{\"_31\":1808,\"_33\":1809,\"_35\":1810},\"dgg\",\"Dan Goldstein\",\"dgg@microsoft.com\",{\"_31\":1812,\"_33\":1813,\"_35\":1814},\"davidmr\",\"David Rothschild\",\"davidmr@microsoft.com\",{\"_31\":1816,\"_33\":1817,\"_35\":1818},\"eckamar\",\"Ece Kamar\",\"eckamar@microsoft.com\",{\"_31\":1820,\"_33\":1821,\"_35\":1822},\"horvitz\",\"Eric Horvitz\",\"horvitz@microsoft.com\",{\"_31\":1824,\"_33\":1825,\"_35\":1826,\"_41\":42},\"gaganbansal\",\"Gagan Bansal\",\"gaganbansal@microsoft.com\",{\"_31\":371,\"_33\":372,\"_35\":373},{\"_31\":1829,\"_33\":1830,\"_35\":1831},\"jmh\",\"Jake Hofman\",\"jmh@microsoft.com\",{\"_31\":771,\"_33\":772,\"_35\":773},{\"_31\":1834,\"_33\":1835,\"_35\":1836},\"mobius\",\"Markus Mobius\",\"mobius@microsoft.com\",{\"_31\":1838,\"_33\":1839,\"_35\":1840},\"mayamurad\",\"Maya Murad\",\"mayamurad@microsoft.com\",{\"_31\":1842,\"_33\":1843,\"_35\":1844},\"nicimm\",\"Nicole Immorlica\",\"nicimm@microsoft.com\",{\"_31\":1846,\"_33\":1847,\"_35\":1848},\"samershi\",\"Saleema Amershi (SHE/HER)\",\"samershi@microsoft.com\",{\"_31\":1850,\"_33\":1851,\"_35\":1852},\"sojaffe\",\"Sonia Jaffe\",\"sojaffe@microsoft.com\",{\"_31\":1854,\"_33\":1855,\"_35\":1856},\"v-subbaraok\",\"Subbarao Kambhampati\",\"v-subbaraok@microsoft.com\",{\"_31\":1858,\"_33\":1859,\"_35\":1860},\"tylerpayne\",\"Tyler Payne\",\"tylerpayne@microsoft.com\",{\"_31\":1862,\"_33\":1863,\"_35\":1864},\"wenyuehua\",\"Wenyue Hua\",\"wenyuehua@microsoft.com\",{\"_31\":1866,\"_33\":1867,\"_35\":1868},\"willepperson\",\"Will Epperson\",\"willepperson@microsoft.com\",{\"_31\":1870,\"_33\":1871,\"_35\":1872},\"zacharyhuang\",\"Zachary Huang\",\"zacharyhuang@microsoft.com\",[96],\"2025-10-30T14:13:55.872Z\",\"2025-10-31T15:16:21.980Z\",[],[],{\"_18\":1879,\"_20\":1880,\"_22\":1881,\"_24\":25,\"_26\":27,\"_28\":1882,\"_43\":1907,\"_48\":1908,\"_50\":1909,\"_52\":1910,\"_62\":1911,\"_64\":101,\"_66\":67,\"_68\":102},\"RRS25-PROJ-008\",\"Magentic-UI: Towards Human-in-the-loop Agentic Systems\",\"Magentic-UI is an open-source web interface for developing and studying human-agent interaction built with a flexible multi-agent architecture that supports web browsing, code execution, and file manipulation, and can be extended with diverse tools via MCP.\",[1883,1884,1887,1888,1892,1896,1897,1898,1899,1900,1901,1902,1903],{\"_31\":1788,\"_33\":1789,\"_35\":1790},{\"_31\":1885,\"_33\":1677,\"_35\":1886},\"chetan\",\"chetan@microsoft.com\",{\"_31\":1816,\"_33\":1817,\"_35\":1818},{\"_31\":1889,\"_33\":1890,\"_35\":1891},\"ekzhu\",\"Eric Zhu\",\"ekzhu@microsoft.com\",{\"_31\":1893,\"_33\":1894,\"_35\":1895},\"fniedtner\",\"Friederike Niedtner\",\"fniedtner@microsoft.com\",{\"_31\":1824,\"_33\":1825,\"_35\":1826},{\"_31\":371,\"_33\":372,\"_35\":373,\"_41\":42},{\"_31\":970,\"_33\":971,\"_35\":972},{\"_31\":1838,\"_33\":1839,\"_35\":1840},{\"_31\":88,\"_33\":89,\"_35\":90},{\"_31\":1846,\"_33\":1847,\"_35\":1848},{\"_31\":1858,\"_33\":1859,\"_35\":1860},{\"_31\":1904,\"_33\":1905,\"_35\":1906},\"victordibia\",\"Victor Dibia\",\"victordibia@microsoft.com\",[395,396,397],\"2025-10-30T14:13:55.930Z\",\"2025-10-31T22:46:57.974Z\",[],[],{\"_18\":1913,\"_20\":1914,\"_22\":1915,\"_24\":297,\"_26\":27,\"_28\":1916,\"_43\":1938,\"_48\":1940,\"_50\":1941,\"_52\":1942,\"_62\":1943,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-052\",\"Managing Serverless Resource Pools\",\"Serverless computing offers scalability and simplified application deployment for developers. However, meeting service-level objectives for bursty workloads requires large pools of warm containers on standby. The burden of these idle resources significantly magnifies the cost of providing serverless. In this work, we propose runtime oversubscription to reduce the number of idle containers while meeting the same service-level objectives. Specifically, we take pools of containers reserved for different runtimes and merge them, creating smaller pools of shared containers able to serve multiple types of requests. We examine how to choose which runtimes should be grouped together while also mitigating the tradeoff of longer creation time for shared containers. Experiments with Azure Functions traces demonstrate runtime oversubscription is able to reduce the total number of containers across all pools by up to 40%.\",[1917,1921,1922,1926,1930,1934],{\"_31\":1918,\"_33\":1919,\"_35\":1920,\"_41\":42},\"rdasilva\",\"Rafael Mendes da Silva\",\"rdasilva@microsoft.com\",{\"_31\":205,\"_33\":206,\"_35\":207,\"_41\":42},{\"_33\":1923,\"_31\":1924,\"_35\":1925,\"_41\":6},\"Paul Batum\",\"pbatum\",\"pbatum@microsoft.com\",{\"_33\":1927,\"_31\":1928,\"_35\":1929,\"_41\":6},\"Yan Chen\",\"yach\",\"yach@microsoft.com\",{\"_33\":1931,\"_31\":1932,\"_35\":1933,\"_41\":6},\"Hamid Henry Safi\",\"hamids\",\"hamids@microsoft.com\",{\"_33\":1935,\"_31\":1936,\"_35\":1937,\"_41\":6},\"Seth Fine\",\"sethfine\",\"sethfine@microsoft.com\",[1939],\"Serverless computing\",\"2025-10-30T14:13:55.985Z\",\"2025-11-06T18:09:48.023Z\",[],[],{\"_18\":1945,\"_20\":1946,\"_22\":1947,\"_24\":558,\"_26\":27,\"_28\":1948,\"_43\":1967,\"_48\":1968,\"_50\":1969,\"_52\":1970,\"_62\":1971,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-095\",\"Microsoft Crypto Board: 20+ Years of Influence, Standards, and Impact\",\"Microsoft Crypto Board is the company’s authority on cryptography usage and standards. Co-founded by MSR, the Board reviews complex cryptography challenges, sets standards, and provides ongoing consultation to product teams. Since 2004, it has proactively identified security issues before products ship, saving millions in remediation costs and protecting Microsoft’s reputation. By connecting cryptographers and engineers, the Board drives best cryptographic practices, compliance, and cross-company influence for MSR which not only helps engineering teams produce more secure products and services but also brings important unsolved problems to the attention of MSR.\",[1949,1950,1954,1955,1959,1963],{\"_31\":562,\"_33\":563,\"_35\":564},{\"_31\":1951,\"_33\":1952,\"_35\":1953},\"danshu\",\"Dan Shumow\",\"danshu@microsoft.com\",{\"_31\":566,\"_33\":567,\"_35\":568},{\"_31\":1956,\"_33\":1957,\"_35\":1958},\"benaloh\",\"Josh Benaloh\",\"benaloh@microsoft.com\",{\"_31\":1960,\"_33\":1961,\"_35\":1962,\"_41\":42},\"Keaster\",\"Karen Easterbrook\",\"keaster@microsoft.com\",{\"_31\":1964,\"_33\":1965,\"_35\":1966},\"mnaehrig\",\"Michael Naehrig\",\"mnaehrig@microsoft.com\",[574,575],\"2025-10-30T14:13:56.043Z\",\"2025-10-31T16:54:53.626Z\",[],[],{\"_18\":1973,\"_20\":1974,\"_22\":1975,\"_24\":456,\"_26\":27,\"_28\":1976,\"_43\":1981,\"_48\":1982,\"_50\":1983,\"_52\":1984,\"_62\":1985,\"_64\":101,\"_66\":67,\"_68\":102},\"RRS25-PROJ-068\",\"Multiverse Mechanica: A Testbed for Learning Video Game Mechanics via Counterfactual\",\"Generative AI for games can create stunning visuals—but too often it breaks the rules of play. Characters pass through walls, physics fail, and objects don’t persist. We bridge this gap with causal AI abstractions that pinpoint how to learn game rules. Our benchmark encodes these rules as causal structures, making it possible to train and evaluate models on whether they truly understand how a game is played—not just how it looks.\",[1977],{\"_31\":1978,\"_33\":1979,\"_35\":1980,\"_41\":42},\"robertness\",\"Robert Ness\",\"robertness@microsoft.com\",[467],\"2025-10-30T14:13:56.156Z\",\"2025-11-03T22:03:15.887Z\",[],[],{\"_18\":1987,\"_20\":1988,\"_22\":1989,\"_24\":297,\"_26\":27,\"_28\":1990,\"_43\":2011,\"_48\":2013,\"_50\":2014,\"_52\":2015,\"_62\":2016,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-051\",\"Nanvix: A Split OS Design for High-Density Serverless Deployments\",\"Nanvix is a novel split-operating system architecture designed to address the scalability, performance, and isolation challenges of modern serverless cloud platforms. Traditional serverless deployments rely on virtual machines (VMs) to isolate functions, but suffer from significant cold-start overheads and limited density due to heavyweight VM provisioning and memory footprints. Nanvix introduces a split-VM model, separating the system VM (handling OS, network, and I/O for each tenant) from lightweight user VMs (one per function instance), each running a purpose-built Nanvix kernel. Nanvix runs on top of Hyperlight, a lightweight virtual machine monitor (VMM) optimized for high-density workloads.\\n\\nThis architecture amortizes expensive components across functions of the same tenant, dramatically reducing cold-start times and increasing the number of function instances that can be packed per server. Nanvix achieves significant improvements when compared to state-of-the-art solutions such as AWS Firecracker , Unikraft, Google gVisor, and Cloud-Hypervisor. For example, Nanvix demonstrates cold-start overhead reductions of 10x to 100x and can provision up to 50x more VMs per server than conventional approaches, while maintaining strong isolation and compatibility with unmodified application code (Python, JavaScript, WebAssembly, Rust, and C/C++).\\n\\nNanvix also exposes runtime configuration knobs for fine-grained performance tuning, enabling dynamic resource orchestration and co-design opportunities between the OS, virtual machine monitor (VMM), and control plane. The project demonstrates that split-OS designs can deliver high-density, low-latency cloud-native deployments without sacrificing security or compatibility, paving the way for more efficient cloud infrastructure.\",[1991,1995,1999,2003,2007],{\"_31\":1992,\"_33\":1993,\"_35\":1994},\"dchiarlone\",\"Danilo Chiarlone\",\"dchiarlone@microsoft.com\",{\"_31\":1996,\"_33\":1997,\"_35\":1998,\"_41\":42},\"ppenna\",\"Pedro Henrique Penna\",\"ppenna@microsoft.com\",{\"_31\":2000,\"_33\":2001,\"_35\":2002},\"esaurez\",\"Enrique Saurez\",\"esaurez@microsoft.com\",{\"_31\":2004,\"_33\":2005,\"_35\":2006},\"inigog\",\"Íñigo Goiri\",\"inigog@microsoft.com\",{\"_31\":2008,\"_33\":2009,\"_35\":2010},\"rofons\",\"Rodrigo Fonseca\",\"rofons@microsoft.com\",[1939,2012],\"operating systems\",\"2025-10-30T14:13:56.213Z\",\"2025-10-31T23:08:16.042Z\",[],[],{\"_18\":2018,\"_20\":2019,\"_22\":2020,\"_24\":428,\"_26\":27,\"_28\":2021,\"_43\":2032,\"_48\":2033,\"_50\":2034,\"_52\":2035,\"_62\":2039,\"_64\":101,\"_66\":149,\"_68\":451},\"RRS25-PROJ-061\",\"New Memory-Optimized Storage Engines for Vector Workloads and Beyond\",\"MSR has developed a new storage engine based on our recently published work on the Bf-Tree range index data structure. This storage engine is optimized for memory efficiency towards serving new AI driven workloads such as vector databases, and is applicable to traditional database engines as well. It can serve as either a cache or the point of truth. The new use cases we target demand extremely high throughput and low latency, combined with high memory efficiency (hit rates), so that they can effectively serve both scale-up and scale-out cloud scenarios. In this poster, we will describe the design of this new storage engine and present results on its performance and caching efficiency.\",[2022,2026,2027,2028],{\"_31\":2023,\"_33\":2024,\"_35\":2025,\"_41\":42},\"badrishc\",\"Badrish Chandramouli\",\"badrishc@microsoft.com\",{\"_31\":1318,\"_33\":1319,\"_35\":1320},{\"_31\":1322,\"_33\":1323,\"_35\":1324},{\"_31\":2029,\"_33\":2030,\"_35\":2031},\"shayi\",\"Yi Shan\",\"shayi@microsoft.com\",[428],\"2025-10-30T14:13:56.272Z\",\"2025-11-01T00:31:15.003Z\",[2036],{\"_55\":60,\"_57\":2037,\"_20\":2038},\"https://aka.ms/ferricdb\",\"Paper and Rust code\",[],{\"_18\":2041,\"_20\":2042,\"_22\":2043,\"_24\":558,\"_26\":27,\"_28\":2044,\"_43\":2050,\"_48\":2051,\"_50\":2052,\"_52\":2053,\"_62\":2054,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-096\",\"NovaRollup: Digital Asset Transactions with Scale and Privacy\",\"The digital assets market is rapidly expanding, with financial institutions, technology leaders, and cross-industry market leaders deploying blockchain-based solutions for tokenizing real-world assets. Existing solutions like public blockchains (e.g., Ethereum) and permissioned blockchains (e.g., Google's) face critical limitations in scalability and privacy. We propose NovaRollup that addresses these limitations with the use of Nova zero-knowledge proof system.\",[2045,2049],{\"_31\":2046,\"_33\":2047,\"_35\":2048,\"_41\":42},\"srinath\",\"Srinath Setty\",\"srinath@microsoft.com\",{\"_31\":1613,\"_33\":1614,\"_35\":1615},[574,575],\"2025-10-30T14:13:56.332Z\",\"2025-10-31T16:55:08.096Z\",[],[],{\"_18\":2056,\"_20\":2057,\"_22\":2058,\"_24\":297,\"_26\":27,\"_28\":2059,\"_43\":2072,\"_48\":49,\"_50\":2074,\"_52\":2075,\"_62\":2078,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-106\",\"Operating at the Knee: Using Monte Carlo and Analytical Models to Optimize Efficiency\",\"Microsoft Copilot operates across a wide range of deployments and model families, each exhibiting distinct traffic patterns. We present a characterization of current serving dynamics, highlighting variability in context lengths, generated tokens, cache hit rates, and batch sizes under production schedulers. Building on this, we introduce GAUSS, a Monte Carlo simulation framework that integrates trace-derived arrival processes with empirically measured prefill and decode behavior. This approach enables replay of realistic request mixes to explore efficiency trade-offs. Validated against production telemetry, the simulator maps the throughput–latency Pareto frontier and identifies the knee, an optimal operating region where incremental throughput gains incur disproportionate latency costs.\",[2060,2064,2068],{\"_31\":2061,\"_33\":2062,\"_35\":2063},\"srbharadwaj\",\"Srikant Bharadwaj\",\"srbharadwaj@microsoft.com\",{\"_31\":2065,\"_33\":2066,\"_35\":2067},\"ankurmallick\",\"Ankur Mallick\",\"ankurmallick@microsoft.com\",{\"_31\":2069,\"_33\":2070,\"_35\":2071},\"reneestamant\",\"Renee St Amant\",\"reneestamant@microsoft.com\",[2073],\"Analytics\",\"2025-10-31T23:41:47.464Z\",[2076],{\"_55\":268,\"_57\":2077,\"_20\":27},\"https://aka.ms/efficient-ai-primer\",[],{\"_18\":2080,\"_20\":2081,\"_22\":2082,\"_24\":186,\"_26\":2083,\"_28\":2084,\"_43\":2094,\"_48\":2095,\"_50\":2096,\"_52\":2097,\"_62\":2098,\"_64\":101,\"_66\":67,\"_68\":218},\"RRS25-PROJ-079\",\"OptiMind: Teaching LLMs to Think Like Optimization Experts\",\"Optimization formulation—translating a user’s natural language description into valid programming code for optimization solvers—is challenging and requires operations research expertise, yet it is fundamental to decision making across many business and public sectors. Automating this process with large language models (LLMs) can substantially improve efficiency in domains such as supply chain and logistics while reducing operational costs. In this project, we post-train LLMs with supervised fine-tuning and reinforcement learning to improve performance on the optimization formulation task. Because high-quality training data is critical, we identify a major limitation of existing open-source datasets: as they are synthetically generated by LLMs or curated without careful human supervision, these datasets are typically error-prone with error rates over 30-50%. To address this, we develop an automatic dataset cleaning procedure by applying careful error analyses for each optimization category, inspired by our manual cleaning of a small test set. We also construct high-quality training and test datasets extracted from real operations research papers on ArXiv. Training on these datasets yields significant improvements for open-source language models such as Qwen, and we are further exploring training the state-of-the-art GPT-oss model to enhance performance.\",\"\u003ciframe src=\\\"https://microsoft.sharepoint.com/teams/MSRNVA01/_layouts/15/embed.aspx?UniqueId=19aae94a-b701-4f6e-bfd4-266f43743a17\u0026embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D\u0026referrer=StreamWebApp\u0026referrerScenario=EmbedDialog.Create\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" allowfullscreen title=\\\"58419.mp4\\\"\u003e\u003c/iframe\u003e\",[2085,2086,2087,2088,2089,2090],{\"_31\":759,\"_33\":760,\"_35\":761},{\"_31\":763,\"_33\":764,\"_35\":765},{\"_31\":662,\"_33\":663,\"_35\":664},{\"_31\":775,\"_33\":776,\"_35\":777},{\"_31\":1438,\"_33\":1439,\"_35\":1440},{\"_31\":2091,\"_33\":2092,\"_35\":2093,\"_41\":42},\"siruili\",\"Sirui Li\",\"siruili@microsoft.com\",[45],\"2025-10-30T14:13:56.390Z\",\"2025-10-31T23:27:59.806Z\",[],[],{\"_18\":2100,\"_20\":2101,\"_22\":2102,\"_24\":456,\"_26\":27,\"_28\":2103,\"_43\":2126,\"_48\":2127,\"_50\":2128,\"_52\":2129,\"_62\":2130,\"_64\":101,\"_66\":67,\"_68\":102},\"RRS25-PROJ-040\",\"Phi 4 Vision 15B\",\"Building the next generation small, open-weight multimodal models with a focus on Math and Computer-Use-Agents.\",[2104,2108,2109,2110,2114,2115,2116,2120,2121,2125],{\"_31\":2105,\"_33\":2106,\"_35\":2107},\"mharrison\",\"Michael Harrison\",\"mharrison@microsoft.com\",{\"_31\":966,\"_33\":967,\"_35\":968},{\"_31\":80,\"_33\":81,\"_35\":82},{\"_31\":2111,\"_33\":2112,\"_35\":2113},\"jyotianeja\",\"Jyoti Aneja\",\"jyotianeja@microsoft.com\",{\"_31\":979,\"_33\":980,\"_35\":981,\"_41\":42},{\"_31\":817,\"_33\":818,\"_35\":819},{\"_31\":2117,\"_33\":2118,\"_35\":2119},\"raward\",\"Rachel Ward (CELA)\",\"raward@microsoft.com\",{\"_31\":379,\"_33\":380,\"_35\":381},{\"_31\":2122,\"_33\":2123,\"_35\":2124},\"v-tylabonte\",\"Tyler LaBonte (POPULUS GROUP LLC)\",\"v-tylabonte@microsoft.com\",{\"_31\":383,\"_33\":384,\"_35\":385},[],\"2025-10-30T14:13:56.449Z\",\"2025-10-31T23:05:57.208Z\",[],[],{\"_18\":2132,\"_20\":2133,\"_22\":2134,\"_24\":558,\"_26\":2135,\"_28\":2136,\"_43\":2149,\"_48\":2150,\"_50\":2151,\"_52\":2152,\"_62\":2153,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-097\",\"Preventing MitM Attacks in End-to-End Encrypted Calls\",\"End-to-end encrypted communication requires public keys to be distributed in a reliable manner. If two or more people want to set up a protected channel between themselves, each of them needs to be confident that they are using the correct public keys for the other participants. Failure to verify this leads to a total break of the system, as a malicious party can potentially perform a meddler-in-the-middle (MitM) attack. This is a realistic threat. For example, there are known cases where existing public-key directories have been attacked to replace the public keys of well-known journalists.\\n\\nWe are taking a two-pronged approach here. We have been investigating the approach that the industry (including Teams) currently uses to guarantee the security of end-to-end encrypted calls, which relies on users manually comparing long numeric strings. We have designed a new variant of the protocol that Teams has been using, which provides much stronger security without extending the length of the security codes. Our Teams collaborators are currently in the process of implementing this protocol.\\n\\nHowever, this approach is burdensome for users and does not scale to larger meetings; it is also vulnerable to deep fakes. We have a long running research project developing a transparent cloud-hosted “phone book” for user public keys—this idea is known as key transparency. This approach replaces the burdensome manual digital fingerprint checking with an asynchronous process that runs entirely into the background. We have been working to design and implement all the building blocks necessary to build this into Teams.\",\"\u003ciframe src=\\\"https://microsoft.sharepoint.com/teams/MSRNVA01/_layouts/15/embed.aspx?UniqueId=2f8d2a50-e7c0-4b1f-b323-ba9d9e9c5429\u0026embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D\u0026referrer=StreamWebApp\u0026referrerScenario=EmbedDialog.Create\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" allowfullscreen title=\\\"58429.mp4\\\"\u003e\u003c/iframe\u003e\",[2137,2141,2145],{\"_31\":2138,\"_33\":2139,\"_35\":2140,\"_41\":42},\"kilai\",\"Kim Laine\",\"kilai@microsoft.com\",{\"_31\":2142,\"_33\":2143,\"_35\":2144},\"melissac\",\"Melissa Chase\",\"melissac@microsoft.com\",{\"_31\":2146,\"_33\":2147,\"_35\":2148},\"racruzmo\",\"Radames Cruz Moreno\",\"racruzmo@microsoft.com\",[574,575],\"2025-10-30T14:13:56.507Z\",\"2025-10-31T23:34:59.815Z\",[],[],{\"_18\":2155,\"_20\":2156,\"_22\":2157,\"_24\":837,\"_26\":27,\"_28\":2158,\"_43\":2162,\"_48\":2163,\"_50\":2164,\"_52\":2165,\"_62\":2166,\"_64\":101,\"_66\":149,\"_68\":150},\"RRS25-PROJ-066\",\"Project Haven: Empowering People with Chronic Illnesses to Connect and Collaborate\",\"Chronic illness impacts more than half of adults in the U.S., and the number of workers living with chronic illness will continue to grow as people live and work longer. This project explores new AI-powered technologies to create inclusive digital environments where people with chronic illness can connect, contribute, and collaborate without compromising their well-being. We partner directly with individuals with chronic illness to identify communication and collaboration challenges, and to develop novel solutions that address their specific needs.\",[2159,2160,2161],{\"_31\":913,\"_33\":914,\"_35\":915},{\"_31\":848,\"_33\":849,\"_35\":850},{\"_31\":864,\"_33\":865,\"_35\":866,\"_41\":42},[837],\"2025-10-30T14:13:56.563Z\",\"2025-10-31T16:43:59.714Z\",[],[],{\"_18\":2168,\"_20\":2169,\"_22\":2170,\"_24\":558,\"_26\":27,\"_28\":2171,\"_43\":2204,\"_48\":2205,\"_50\":2206,\"_52\":2207,\"_62\":2208,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-098\",\"Project Ire: Autonomous Reverse Engineering of Binaries\",\"Project Ire is an LLM-powered autonomous malware classifier. The agentic system fully reverse engineers software binaries and determines whether it is malicious or benign, without human assistance.\",[2172,2176,2180,2184,2188,2192,2196,2200],{\"_31\":2173,\"_33\":2174,\"_35\":2175},\"bobfleck\",\"Bob Fleck\",\"bobfleck@microsoft.com\",{\"_31\":2177,\"_33\":2178,\"_35\":2179},\"bcaswell\",\"Brian Caswell\",\"bcaswell@microsoft.com\",{\"_31\":2181,\"_33\":2182,\"_35\":2183},\"cduplantis\",\"Cory Duplantis\",\"cduplantis@microsoft.com\",{\"_31\":2185,\"_33\":2186,\"_35\":2187},\"dustinfraze\",\"Dustin Fraze\",\"dustinfraze@microsoft.com\",{\"_31\":2189,\"_33\":2190,\"_35\":2191},\"jeswinter\",\"Jessica Winter\",\"jeswinter@microsoft.com\",{\"_31\":2193,\"_33\":2194,\"_35\":2195},\"katysmith\",\"Katy Smith\",\"katysmith@microsoft.com\",{\"_31\":2197,\"_33\":2198,\"_35\":2199},\"walkerm\",\"Mike Walker (NSV)\",\"walkerm@microsoft.com\",{\"_31\":2201,\"_33\":2202,\"_35\":2203,\"_41\":42},\"smithsarah\",\"Sarah Smith\",\"smithsarah@microsoft.com\",[574,575],\"2025-10-30T14:13:56.625Z\",\"2025-10-31T16:55:42.918Z\",[],[],{\"_18\":2210,\"_20\":2211,\"_22\":2212,\"_24\":25,\"_26\":27,\"_28\":2213,\"_43\":2245,\"_48\":2247,\"_50\":2248,\"_52\":2249,\"_62\":2250,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-010\",\"Project Xavier – Platform for Physical AI Agents\",\"We will present Project Xavier, a novel edge-centric platform for physical AI, enabling seamless integration of AI models with sensors, wearables, and robotic systems across home or industrial environments. It is designed to support low-latency, privacy-preserving, and cost-efficient computation. It seeks to address key challenges in distributed automation, through a unified infrastructure that spans device, edge, and cloud. The first version of Project Xavier is available for internal use within Microsoft. It comes pre-integrated with several wearables, robots, and AI models. It can also readily run on top of MSR’s fully programmable 5G network. It offers simple programming abstraction that allows developers to quickly prototype and deploy their ideas with a few hundred lines of Python code. We will show a few demos to illustrate its capabilities and propose a few areas for potential collaboration.\",[2214,2218,2222,2223,2224,2225,2229,2233,2237,2241],{\"_31\":2215,\"_33\":2216,\"_35\":2217},\"bozidar\",\"Bozidar Radunovic\",\"bozidar@microsoft.com\",{\"_31\":2219,\"_33\":2220,\"_35\":2221},\"connorsettle\",\"Connor Settle\",\"connorsettle@microsoft.com\",{\"_31\":1489,\"_33\":1490,\"_35\":1491,\"_41\":42},{\"_31\":1588,\"_33\":1589,\"_35\":1590},{\"_31\":947,\"_33\":948,\"_35\":949},{\"_31\":2226,\"_33\":2227,\"_35\":2228},\"mabalkwi\",\"Matthew Balkwill\",\"mabalkwi@microsoft.com\",{\"_31\":2230,\"_33\":2231,\"_35\":2232},\"sanjeevm\",\"Sanjeev Mehrotra\",\"sanjeevm@microsoft.com\",{\"_31\":2234,\"_33\":2235,\"_35\":2236},\"bahl\",\"Victor Bahl\",\"bahl@microsoft.com\",{\"_31\":2238,\"_33\":2239,\"_35\":2240},\"ygz\",\"Yongguang Zhang\",\"ygz@microsoft.com\",{\"_33\":2242,\"_31\":2243,\"_35\":2244,\"_41\":6},\"Xenofon Foukas\",\"xefouk\",\"xefouk@microsoft.com\",[2246],\"Physical AI\",\"2025-10-30T14:13:56.684Z\",\"2025-11-03T21:14:06.359Z\",[],[],{\"_18\":2252,\"_20\":2253,\"_22\":2254,\"_24\":248,\"_26\":27,\"_28\":2255,\"_43\":2267,\"_48\":2268,\"_50\":2269,\"_52\":2270,\"_62\":2271,\"_64\":101,\"_66\":67,\"_68\":292},\"RRS25-PROJ-080\",\"Proofs à la Carte: Verified Code with Pulse\",\"Across the company and the industry, large codebases continue to be written in memory-unsafe languages.  Even code in memory-safe languages is susceptible to security-critical bugs such as buffer reuse or malleability issues.  Pulse is our answer to secure this critical attack surface: a modern, concurrent separation logic that enables scalable and modular proofs of memory safety and optionally functional correctness.\\n\\nOn top of Pulse, we are building tools that bring verification in a production-ready package: \\n\\n•\\tEverParse is a toolchain to automatically generate provably memory-safe and secure binary parsers and serializers, and is replacing hand-written unsafe parsers in CoreOS, Azure CCF, SQL, etc.\\n•\\tKuiper is a library for writing generic, memory-safe and data race-free GPU kernels without sacrificing performance, natively supporting low-level atomics and barriers.  \\n•\\tC2Pulse is an annotation framework that brings memory-safety to existing C code, without requiring costly and risky rewrites in a different language.\\n\\nWe have ongoing engagements with several teams in CoreOS, SQL, \u0026 Azure Storage.\",[2256,2257,2258,2262,2263],{\"_31\":700,\"_33\":699,\"_35\":701},{\"_31\":658,\"_33\":659,\"_35\":660,\"_41\":42},{\"_31\":2259,\"_33\":2260,\"_35\":2261},\"guimartinez\",\"Guido Martinez\",\"guimartinez@microsoft.com\",{\"_31\":682,\"_33\":683,\"_35\":684},{\"_31\":2264,\"_33\":2265,\"_35\":2266},\"taramana\",\"Tahina Ramananandro\",\"taramana@microsoft.com\",[],\"2025-10-30T14:13:56.741Z\",\"2025-10-31T16:50:21.735Z\",[],[],{\"_18\":2273,\"_20\":2274,\"_22\":2275,\"_24\":25,\"_26\":27,\"_28\":2276,\"_43\":2287,\"_48\":2288,\"_50\":2289,\"_52\":2290,\"_62\":2291,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-011\",\"Prospection Guided Memory Retrieval for Agent Personalization\",\"Personalization of agents requires agents to continuously learn, remember and anticipate user needs. Consequently, given a query, the agent must use long term memory storage and retrieval to retrieve the relevant and important memories. The key challenge is to determine which memories are relevant. Recent techniques rely on RAGs and Graphs to store and retrieve memories. These \\\"static\\\" approaches cannot adapt and tailor retrieval on a per query basis. We introduce novel approach -  Prospection Guided Retrieval - a neuroscience inspired retrieval technique that retrieves memories by simulating possible futures and iteratively refining them based on the newly retrieved memories. This is similar to the manner in which human brain's pre-frontal cortex simulates possible futures and uses them to retrieve memories stored in the hippocampus.\",[2277,2278,2282,2286],{\"_31\":1497,\"_33\":1498,\"_35\":1499,\"_41\":42},{\"_31\":2279,\"_33\":2280,\"_35\":2281},\"niruc\",\"Nirupama Chandrasekaran\",\"niruc@microsoft.com\",{\"_31\":2283,\"_33\":2284,\"_35\":2285},\"ryenw\",\"Ryen White\",\"ryenw@microsoft.com\",{\"_31\":170,\"_33\":171,\"_35\":172},[395,396,397],\"2025-10-30T14:13:56.799Z\",\"2025-10-30T22:40:48.109Z\",[],[],{\"_18\":2293,\"_20\":2294,\"_22\":2295,\"_24\":297,\"_26\":27,\"_28\":2296,\"_43\":2306,\"_48\":2307,\"_50\":2308,\"_52\":2309,\"_62\":2310,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-053\",\"Prospector: Identifying System Log Anomalies with AI\",\"System logs are everywhere! They offer rich insights into the health of critical systems in Azure and other Microsoft services, often revealing early warning signs of failures—if operators know what to look for. Today, operators must manually design parsing and alerting rules, an unscalable process. Azure’s network infrastructure alone produces over 100 billion logs per day, demanding automated solutions that scale, minimize tuning, reduce false positives, and remain interpretable.\\n\\nWe built Prospector, a fully unsupervised, cloud-scale anomaly detection system for system logs. Prospector automatically learns high-confidence alerting rules from historical data. To extract semantic signals from log text, we leverage Large Language Models (LLMs), using in-context learning to interpret logs and reduce false positives. Our scalable neuro-symbolic pipeline combines LLMs with statistical analysis to detect anomalies effectively.\",[2297,2298,2302],{\"_31\":1358,\"_33\":1359,\"_35\":1360},{\"_31\":2299,\"_33\":2300,\"_35\":2301,\"_41\":42},\"rybecket\",\"Ryan Beckett\",\"rybecket@microsoft.com\",{\"_31\":2303,\"_33\":2304,\"_35\":2305},\"sivakakarla\",\"Siva Kakarla\",\"sivakakarla@microsoft.com\",[],\"2025-10-30T14:13:56.854Z\",\"2025-10-31T16:37:31.161Z\",[],[],{\"_18\":2312,\"_20\":2313,\"_22\":2314,\"_24\":25,\"_26\":27,\"_28\":2315,\"_43\":2320,\"_48\":2321,\"_50\":2322,\"_52\":2323,\"_62\":2324,\"_64\":2325,\"_66\":27,\"_68\":27},\"RRS25-PROJ-012\",\"ReDo agentic build and orchestration  system\",\"Developers need a way to know objectively if an agentic approach is the right approach for their problem and if they built the right solution.\\n\\nResearchers need a resilient orchestration system that is designed for the complexities of research  questions and doesn't require a lot of up front cost to explore. Agents should help the process of figuring out the shape of a problem.\\n\\nReDo goes after these undeserved areas  of agentic development. To help health futures and other researchers apply agentic approaches as a tool in their work.\",[2316],{\"_31\":2317,\"_33\":2318,\"_35\":2319,\"_41\":42},\"katieclaveau\",\"Katie Claveau\",\"katieclaveau@microsoft.com\",[395,396,397],\"2025-10-30T14:13:57.029Z\",\"2025-10-30T22:41:07.753Z\",[],[],\"Virtual only\",{\"_18\":2327,\"_20\":2328,\"_22\":2329,\"_24\":456,\"_26\":2330,\"_28\":2331,\"_43\":2352,\"_48\":2353,\"_50\":2354,\"_52\":2355,\"_62\":2356,\"_64\":101,\"_66\":67,\"_68\":102},\"RRS25-PROJ-041\",\"Real-Time Text-Conditioned World Models for Interactive Prototyping\",\"Recent advances in world models have enabled the generation of gameplay sequences that respond to user input, opening up exciting possibilities for creative applications such as rapid prototyping of game ideas. Yet, these models often fall short of real-time interactivity and struggle to produce novel content beyond their training environments.\\nIn this work, we take early steps toward unlocking the full creative potential of world models, making them faster, more flexible, and more controllable. Building on our previous work, WHAM, we introduce a new modelling approach that replaces next-token prediction with discrete diffusion, enabling significant speed-ups with minimal loss in output quality.\\nWe explore how new game behaviours can be learned and triggered at inference time in a controlled manner. To this end, we introduce text to control the game environment generated by the model, and curate the BodySwap dataset which simulates a character swapping mechanism, allowing to change the playable character on the fly. \\nThis proof-of-concept highlights the potential of world models as powerful tools for interactive prototyping and user content generation, made possible through intentional data curation and efficient fine-tuning. Our work lays the foundation for real-time, user-driven experimentation in game design and beyond.\",\"\u003ciframe src=\\\"https://microsoft.sharepoint.com/teams/MSRNVA01/_layouts/15/embed.aspx?UniqueId=cbfcce51-d126-482f-acce-8d5cf298f400\u0026embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D\u0026referrer=StreamWebApp\u0026referrerScenario=EmbedDialog.Create\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" allowfullscreen title=\\\"58444.mp4\\\"\u003e\u003c/iframe\u003e\",[2332,2336,2340,2344,2348],{\"_31\":2333,\"_33\":2334,\"_35\":2335},\"t-eaiello\",\"Emanuele Aiello\",\"t-eaiello@microsoft.com\",{\"_31\":2337,\"_33\":2338,\"_35\":2339},\"t-jewhite\",\"Jennifer White\",\"t-jewhite@microsoft.com\",{\"_31\":2341,\"_33\":2342,\"_35\":2343},\"rageorg\",\"Raluca Stevenson\",\"rageorg@microsoft.com\",{\"_31\":2345,\"_33\":2346,\"_35\":2347},\"saliakbarian\",\"Sadegh Aliakbarian\",\"saliakbarian@microsoft.com\",{\"_31\":2349,\"_33\":2350,\"_35\":2351,\"_41\":42},\"sarahparisot\",\"Sarah Parisot\",\"sarahparisot@microsoft.com\",[467],\"2025-10-30T14:13:56.913Z\",\"2025-11-04T23:32:55.223Z\",[],[],{\"_18\":2358,\"_20\":2359,\"_22\":2360,\"_24\":107,\"_26\":27,\"_28\":2361,\"_43\":2418,\"_48\":2420,\"_50\":2421,\"_52\":2422,\"_62\":2423,\"_64\":101,\"_66\":149,\"_68\":243},\"RRS25-PROJ-028\",\"Real-World Evidence\",\"Our research advances multimodal GenAI for precision health to create high-fidelity virtual patients from unstructured, multimodal, longitudinal patient journeys and distill personalized, population-scale insights for optimizing care delivery and accelerating biomedical discovery.\",[2362,2366,2370,2374,2378,2382,2386,2390,2394,2398,2402,2406,2410,2414],{\"_31\":2363,\"_33\":2364,\"_35\":2365},\"clwon\",\"Cliff Wong\",\"clwon@microsoft.com\",{\"_31\":2367,\"_33\":2368,\"_35\":2369},\"qianchuliu\",\"Flora Liu\",\"qianchuliu@microsoft.com\",{\"_31\":2371,\"_33\":2372,\"_35\":2373},\"guanghuiqin\",\"Guanghui Qin\",\"guanghuiqin@microsoft.com\",{\"_31\":2375,\"_41\":42,\"_33\":2376,\"_35\":2377},\"hoifung\",\"Hoifung Poon\",\"hoifung@microsoft.com\",{\"_31\":2379,\"_35\":2380,\"_33\":2381},\"jabbaga\",\"jabbaga@microsoft.com\",\"Jass Bagga\",{\"_31\":2383,\"_33\":2384,\"_35\":2385},\"jevalanarasu\",\"Jeya Maria Jose Valanarasu\",\"jevalanarasu@microsoft.com\",{\"_31\":2387,\"_33\":2388,\"_35\":2389},\"juanza\",\"Juanma Zambrano Chaves\",\"juanza@microsoft.com\",{\"_31\":2391,\"_33\":2392,\"_35\":2393},\"naotous\",\"Naoto Usuyama\",\"naotous@microsoft.com\",{\"_31\":2395,\"_33\":2396,\"_35\":2397},\"sammarti\",\"Samuel De Freitas Martins\",\"sammarti@microsoft.com\",{\"_31\":2399,\"_33\":2400,\"_35\":2401},\"shezhan\",\"Sheng Zhang\",\"shezhan@microsoft.com\",{\"_31\":2403,\"_33\":2404,\"_35\":2405},\"tristan\",\"Tristan Naumann\",\"tristan@microsoft.com\",{\"_31\":2407,\"_33\":2408,\"_35\":2409},\"zelalemgero\",\"Zelalem Gero\",\"zelalemgero@microsoft.com\",{\"_33\":2411,\"_31\":2412,\"_35\":2413,\"_41\":6},\"Peniel Argaw\",\"penielargaw\",\"penielargaw@microsoft.com\",{\"_33\":2415,\"_31\":2416,\"_35\":2417,\"_41\":6},\"Jason Entenmann\",\"jentenmann\",\"jentenmann@microsoft.com\",[238,2419],\"Generative AI\",\"2025-10-30T14:13:56.969Z\",\"2025-11-03T16:27:19.400Z\",[],[],{\"_18\":2425,\"_20\":2426,\"_22\":2427,\"_24\":297,\"_26\":2428,\"_28\":2429,\"_43\":2436,\"_48\":2438,\"_50\":2439,\"_52\":2440,\"_62\":2441,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-054\",\"Robusta: Explanation-Guided Heuristic Design with LLMs\",\"Operators use heuristics in many production systems because they are faster and require less resources than their optimal counterparts. Recently, Google's AlphaEvolve solution showed we can use LLMs to design heuristics that perform better in practice --- Google claims these heuristics are deployed in their production pipeline and have improved performance. We posit that we can generate more robust and performant heuristics if we augment approaches such as AlphaEvolve with tools that explain why heuristics underperform and suggestions about how to fix them. We find even simple ideas that (1) expose the LLM to instances where the heuristic underperforms; (2) explain why they occur; and (3) specialize design to regions in the input space, can produce more robust algorithms compared to existing techniques — the heuristics we produce have a ∼ 28× better\\nworst-case performance compared to AlphaEvolve, improve average performance, and maintain the runtime.\",\"\u003ciframe src=\\\"https://microsoft.sharepoint.com/teams/MSRNVA01/_layouts/15/embed.aspx?UniqueId=0bab1ef8-2393-4f41-b6af-1a35c7c0a668\u0026embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D\u0026referrer=StreamWebApp\u0026referrerScenario=EmbedDialog.Create\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" allowfullscreen title=\\\"58417.mp4\\\"\u003e\u003c/iframe\u003e\",[2430,2431,2435],{\"_31\":1358,\"_33\":1359,\"_35\":1360,\"_41\":42},{\"_31\":2432,\"_33\":2433,\"_35\":2434},\"namyarpooria\",\"Pooria Namyar\",\"namyarpooria@microsoft.com\",{\"_31\":2303,\"_33\":2304,\"_35\":2305},[2437],\"Heuristics\",\"2025-10-30T14:13:57.086Z\",\"2025-10-31T16:48:39.065Z\",[],[],{\"_18\":2443,\"_20\":2444,\"_22\":2445,\"_24\":25,\"_26\":27,\"_28\":2446,\"_43\":2458,\"_48\":2459,\"_50\":2460,\"_52\":2461,\"_62\":2462,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-013\",\"Safety Risk Analysis of Computer Use Agents (CUA)\",\"This project evaluates safety risks in computer-use agents, evaluating whether systems such as OpenAI Operator/Computer-Use-Preview, Claude CUA, and GPT-5 behave safely during multi-step tasks—for example, refusing harmful or unethical requests and avoiding hallucinated UI actions. Our study surfaces three recurring goal-directedness failures: lack of contextual reasoning, costly assumptions and decisions, and the pursuit of contradictory or infeasible goals. To probe these issues systematically, we designed targeted benchmarks and ran experiments across frontier models and agent, capturing action traces, rationales, and the effects of safety interventions. The datasets and paper including detailed observations from our agent runs will be also released.\",[2447,2451,2455,2456,2457],{\"_31\":2448,\"_33\":2449,\"_35\":2450},\"keeganhines\",\"Keegan Hines\",\"keeganhines@microsoft.com\",{\"_31\":2452,\"_33\":2453,\"_35\":2454},\"romanlutz\",\"Roman Lutz\",\"romanlutz@microsoft.com\",{\"_31\":379,\"_33\":380,\"_35\":381},{\"_31\":383,\"_33\":384,\"_35\":385,\"_41\":42},{\"_31\":992,\"_33\":993,\"_35\":994},[395,396,397],\"2025-10-30T14:13:57.144Z\",\"2025-10-30T22:41:25.660Z\",[],[],{\"_18\":2464,\"_20\":2465,\"_22\":2466,\"_24\":456,\"_26\":2467,\"_28\":2468,\"_43\":2481,\"_48\":2482,\"_50\":2483,\"_52\":2484,\"_62\":2485,\"_64\":101,\"_66\":67,\"_68\":102},\"RRS25-PROJ-042\",\"Sci-Phi: A Large Language Model Spatial Audio Descriptor\",\"Spatial audio records sound sources and their directions, allowing humans and machines to hear not just what happens, but where. The demo combines two recent research projects:\\n1) a codec that converts a four-channel microphone signal to discrete tokens, and\\n2) a multimodal small language model that understands and reasons over spatial audio tokens.\\nThe demo demonstrates how machines can not only recognize what is being heard, but also infer and reason over where sounds occur in a 3D environment.\",\"\u003ciframe src=\\\"https://microsoft.sharepoint.com/teams/MSRNVA01/_layouts/15/embed.aspx?UniqueId=d6f2378c-33b0-47d0-ae15-5c52483be568\u0026embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D\u0026referrer=StreamWebApp\u0026referrerScenario=EmbedDialog.Create\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" allowfullscreen title=\\\"58412.mp4\\\"\u003e\u003c/iframe\u003e\",[2469,2473,2477],{\"_31\":2470,\"_33\":2471,\"_35\":2472,\"_41\":42},\"diemmano\",\"Dimitra Emmanouilidou\",\"diemmano@microsoft.com\",{\"_31\":2474,\"_33\":2475,\"_35\":2476},\"hagamper\",\"Hannes Gamper\",\"hagamper@microsoft.com\",{\"_31\":2478,\"_33\":2479,\"_35\":2480},\"sebraun\",\"Sebastian Braun\",\"sebraun@microsoft.com\",[467],\"2025-10-30T14:13:57.200Z\",\"2025-10-31T16:25:17.599Z\",[],[],{\"_18\":2487,\"_20\":2488,\"_22\":2489,\"_24\":558,\"_26\":2490,\"_28\":2491,\"_43\":2494,\"_48\":2495,\"_50\":2496,\"_52\":2497,\"_62\":2498,\"_64\":101,\"_66\":67,\"_68\":102},\"RRS25-PROJ-099\",\"SeGuRu: Safe GPU Programming in Rust\",\"With the rise of AI, GPUs are now widely deployed in both public clouds and personal laptops for general-purpose computing (GPGPU), accelerating not only AI workloads but also systems such as databases, cryptography, and zero-knowledge proofs. However, as lessons from CPU concurrent programming show, programming massively parallel hardware is prone to numerous bugs. On GPUs, this challenge is amplified due to their specialized memory architecture.  Developers apply more aggressive optimization (e.g., coalesced memory access and avoiding synchronization) for performance, extending system build times or leading to catastrophic failures after the deployment.\\nWe present SeGuRu, a framework for safe GPU programming in Rust. Unlike the unsafe programming models of CUDA C/C++, SeGuRu enables GPU programming in Rust with lightweight annotations and provides both static and dynamic guarantees for CPU–GPU memory safety through an extended Rust compiler and a trusted GPU core library. To prevent data races, SeGuRu leverages a core idea of chunking before mutation. Built on Rust’s memory model, it extends Rust’s existing static checker to the GPU context to reject unsafe memory usage at compile time. Furthermore, for memory errors that are difficult to statically verify—such as out-of-bounds accesses—SeGuRu follows the crash-for-safety rule, performing optimized runtime checks to balance safety, performance, and usability. With seamless integration of CPU and GPU programming in Rust, SeGuRu makes safe heterogeneous GPGPU programming practical and efficient.\",\"\u003ciframe src=\\\"https://microsoft.sharepoint.com/teams/MSRNVA01/_layouts/15/embed.aspx?UniqueId=70011d14-ad6f-446b-9cad-217ece9b0959\u0026embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D\u0026referrer=StreamWebApp\u0026referrerScenario=EmbedDialog.Create\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" allowfullscreen title=\\\"58430.mp4\\\"\u003e\u003c/iframe\u003e\",[2492,2493],{\"_31\":1609,\"_33\":1610,\"_35\":1611},{\"_31\":1621,\"_33\":1622,\"_35\":1623,\"_41\":42},[574,575],\"2025-10-30T14:13:57.259Z\",\"2025-10-31T16:56:00.315Z\",[],[],{\"_18\":2500,\"_20\":2501,\"_22\":2502,\"_24\":837,\"_26\":27,\"_28\":2503,\"_43\":2515,\"_48\":2516,\"_50\":2517,\"_52\":2518,\"_62\":2519,\"_64\":101,\"_66\":149,\"_68\":150},\"RRS25-PROJ-014\",\"SigmaBench: Towards Ecologically Valid Benchmarks for Physically Situated Collaboration\",\"We report initial work towards constructing ecologically valid benchmarks to assess the capabilities of large multimodal models for engaging in situated collaboration with humans in physical tasks. We leverage an interactive system-driven approach to benchmarking, where questions and challenges are generated by users in context, during their interactions with an end-to-end situated AI system called Sigma (https://aka.ms/psi-sigma), which is designed to guide users through physical tasks step-by-step. We define and explore several challenges with this open-source system and an initial dataset spanning 15 hours across 8 tasks, including step completion detection, confusion detection, situated question answering, preventing mistakes, and so on.\",[2504,2505,2509,2510,2511],{\"_31\":913,\"_33\":914,\"_35\":915},{\"_31\":2506,\"_33\":2507,\"_35\":2508},\"dbohus\",\"Dan Bohus\",\"dbohus@microsoft.com\",{\"_31\":1820,\"_33\":1821,\"_35\":1822},{\"_31\":1047,\"_33\":1048,\"_35\":1049},{\"_31\":2512,\"_33\":2513,\"_35\":2514,\"_41\":42},\"sandrist\",\"Sean Andrist\",\"sandrist@microsoft.com\",[837],\"2025-10-30T14:13:57.316Z\",\"2025-10-31T22:54:56.106Z\",[],[],{\"_18\":2521,\"_20\":2522,\"_22\":2523,\"_24\":456,\"_26\":27,\"_28\":2524,\"_43\":2530,\"_48\":2531,\"_50\":2532,\"_52\":2533,\"_62\":2534,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-037\",\"Simulating Realistic Multi-Turn User-LLM Conversations\",\"In real life, people don’t speak in perfect prompts. So, we simulate multi-turn conversations — less lab-like, more like real use — and we find that LLMs get lost in conversation! Specifically, we transformed existing datasets with complex instructions (like HumanEval) into a list of sharded instructions. We then use sharded instructions to simulate multi-turn underspecified conversations. On the same tasks, the 15 LLMs we tested perform much worse on multi-turn conversations compared to single-turn (ie. fully specified instructions) conversations. Average performance drops by 39% (!!) across all models (GPT, Claude, Gemini, etc.) and tasks. In multi-turn conversations, we find that LLMs tend to: (1) generate overly verbose responses, leading them to (2) propose final solutions prematurely, (3) make assumptions about underspecified details, and (4) over rely on previous (incorrect) answers.\",[2525,2526],{\"_31\":463,\"_33\":464,\"_35\":465},{\"_31\":2527,\"_33\":2528,\"_35\":2529,\"_41\":42},\"plaban\",\"Philippe Laban\",\"plaban@microsoft.com\",[],\"2025-10-30T14:13:57.376Z\",\"2025-10-31T16:07:46.750Z\",[],[],{\"_18\":2536,\"_20\":2537,\"_22\":2538,\"_24\":25,\"_26\":2539,\"_28\":2540,\"_43\":2562,\"_48\":2565,\"_50\":2566,\"_52\":2567,\"_62\":2568,\"_64\":101,\"_66\":67,\"_68\":102},\"RRS25-PROJ-015\",\"SmartReplay \",\"Like in any software, video game testing is critical to ensuring high quality titles. However, gameplay testing is hard and costly, since games are arbitrarily complex worlds that have to be played in real time, and standard scripting-based automation can be very time consuming and not always possible due to stochastic game elements. In the SmartReplay project, we are developing insights and technology for agents capable of learning to solve complex tasks in rich stochastic environments from few demonstrations. We are focused on retail requirements, so the technology can be more easily adopted in different scenarios, from certification to game development to hardware testing, etc. Our agents learn from video input only, operate the full Xbox controller in real-time. Moreover, our approach is game agnostic and can be applied to any game!\",\"\u003ciframe src=\\\"https://microsoft.sharepoint.com/teams/MSRNVA01/_layouts/15/embed.aspx?UniqueId=1ba02a79-d0a2-48b2-ac7d-5f0903258eaa\u0026embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D\u0026referrer=StreamWebApp\u0026referrerScenario=EmbedDialog.Create\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" allowfullscreen title=\\\"58409.mp4\\\"\u003e\u003c/iframe\u003e\",[2541,2542,2546,2550,2554,2558],{\"_31\":526,\"_33\":527,\"_35\":528},{\"_31\":2543,\"_33\":2544,\"_35\":2545},\"kahofman\",\"Katja Hofmann\",\"kahofman@microsoft.com\",{\"_31\":2547,\"_33\":2548,\"_35\":2549},\"t-luschaefer\",\"Lukas Schaefer\",\"t-luschaefer@microsoft.com\",{\"_31\":2551,\"_33\":2552,\"_35\":2553},\"pallavic\",\"Pallavi Choudhury\",\"pallavic@microsoft.com\",{\"_31\":2555,\"_33\":2556,\"_35\":2557,\"_41\":42},\"sergiov\",\"Sergio Valcarcel Macua\",\"sergiov@microsoft.com\",{\"_31\":2559,\"_33\":2560,\"_35\":2561},\"tony\",\"Tony Carbary\",\"tony@microsoft.com\",[2563,2564,795],\"Gaming\",\"Testing\",\"2025-10-30T14:13:57.434Z\",\"2025-11-01T02:43:03.041Z\",[],[],{\"_18\":2570,\"_20\":2571,\"_22\":2572,\"_24\":25,\"_26\":27,\"_28\":2573,\"_43\":2582,\"_48\":2583,\"_50\":2584,\"_52\":2585,\"_62\":2586,\"_64\":101,\"_66\":67,\"_68\":102},\"RRS25-PROJ-016\",\"Sol - Agentic Writing App for 1% Thinkers\",\"Sol is a writing app for the 1% thinkers of today. Researchers, PMs, Strategists, Journalists, and Deep Thinkers. It uses agents that can both curated and customized that can analyze your writing and help you build the edge in your thinking. It goes far beyond anything currently available in the market. From Grammarly (which heavily focuses on grammar), to Word/Notion (which provide enterprise knowledge). It understand the hypothesis you have, builds intelligence in your domain, accesses the worlds knowledge, and pushes your ideas into new trajectories. It builds corpus-level intelligence by continuously analyzing your body of work and helps you write the next big idea.\",[2574,2578],{\"_31\":2575,\"_33\":2576,\"_35\":2577},\"gooley\",\"Christopher Gooley\",\"gooley@microsoft.com\",{\"_31\":2579,\"_33\":2580,\"_35\":2581,\"_41\":42},\"suffsyed\",\"Suff Syed\",\"suffsyed@microsoft.com\",[395,396,397],\"2025-10-30T14:13:57.492Z\",\"2025-11-03T21:16:42.831Z\",[],[],{\"_18\":2588,\"_20\":2589,\"_22\":2590,\"_24\":186,\"_26\":27,\"_28\":2591,\"_43\":2599,\"_48\":2601,\"_50\":2602,\"_52\":2603,\"_62\":2604,\"_64\":101,\"_66\":67,\"_68\":218},\"RRS25-PROJ-081\",\"SplitRL: Disaggregation for Scalable RL Post-training\",\"Post-training models using reinforcement learning is becoming the norm for AI models as we saturate the data for model pre-training and want to specialize models according to our own use cases, such as code-reasoning. Post-training with reinforcement learning involves generating data using a certain policy or model weights and then using human feedback or automated tools to assign rewards to the responses. Based on the rewards, the model is trained, and the policy is updated with new weights. The process continues iteratively until a desired accuracy is achieved.\\n \\nRL post-training thus involves a complex flow combining batched model inference, reward calculation, model training, and finally, a global model update. In practice, each of these steps happens sequentially and is distributed on the same set of resources. However, these steps have different characteristics - model inference is GPU memory-bound, reward calculation is CPU-heavy, model training is GPU compute-bound, and model update is network-heavy. The diverse workload characteristic of RL post-training naturally lends itself to resource disaggregation. We build a framework, called SplitRL, to orchestrate and optimize the execution of each component independently. We formulate a dynamic programming problem to inform the placement of each component and pipeline multiple batches in the system to allow overlapping component execution on disjoint batches. SplitRL is built on top of the popular post-training framework Verl and provides around 1.4x speedup over Verl for post-training internal models for program intelligence.\",[2592,2593,2597,2598],{\"_31\":189,\"_33\":190,\"_35\":191,\"_41\":42},{\"_31\":2594,\"_33\":2595,\"_35\":2596},\"abonde\",\"Anand Bonde\",\"abonde@microsoft.com\",{\"_31\":775,\"_33\":776,\"_35\":777},{\"_31\":1438,\"_33\":1439,\"_35\":1440},[2600],\"Model training\",\"2025-10-30T14:13:57.554Z\",\"2025-10-31T16:50:39.157Z\",[],[],{\"_18\":2606,\"_20\":2607,\"_22\":2608,\"_24\":837,\"_26\":27,\"_28\":2609,\"_43\":2613,\"_48\":2614,\"_50\":2615,\"_52\":2616,\"_62\":2617,\"_64\":101,\"_66\":149,\"_68\":2618},\"RRS25-PROJ-067\",\"Storycaster: Immersive Room-Based Storytelling using Generative AI\",\"Storycaster transforms the physical world into a responsive storytelling environment. It uses generative AI techniques to change the appearance and sound of the room around you. Unlike headset-based VR, Storycaster preserves spatial awareness, using live camera feeds to augment the walls with cylindrical projections, creating worlds that blend with the physical surroundings. A narrator agent co-creates stories that evolve in response to voice commands, with each scene enhanced by generated ambient audio, dialogue, and imagery.\",[2610,2611,2612],{\"_31\":1035,\"_33\":1036,\"_35\":1037,\"_41\":42},{\"_31\":913,\"_33\":914,\"_35\":915},{\"_31\":530,\"_33\":531,\"_35\":532},[837],\"2025-10-30T14:13:57.612Z\",\"2025-10-31T16:44:15.766Z\",[],[],\"3315\",{\"_18\":2620,\"_20\":2621,\"_22\":2622,\"_24\":107,\"_26\":27,\"_28\":2623,\"_43\":2633,\"_48\":2636,\"_50\":2637,\"_52\":2638,\"_62\":2639,\"_64\":101,\"_66\":149,\"_68\":150},\"RRS25-PROJ-029\",\"Study of Domain Expertise, Task Complexity, and User Satisfaction among Copilot Users\",\"We analyzed logs from real Copilot user conversations over a period of six months. Our study focused on usage patterns among occasional, moderate, and heavy users, focusing on dimensions such as domain, task complexity, user intent, and expertise. Our findings empirically demonstrate that expert users tend to engage Copilot for more complex tasks and report higher satisfaction with the responses received.\",[2624,2625,2629],{\"_31\":2279,\"_33\":2280,\"_35\":2281,\"_41\":42},{\"_31\":2626,\"_33\":2627,\"_35\":2628},\"counts\",\"Scott Counts\",\"counts@microsoft.com\",{\"_31\":2630,\"_33\":2631,\"_35\":2632},\"suri\",\"Siddharth Suri\",\"suri@microsoft.com\",[2634,2635],\"Work\",\"Task\",\"2025-10-30T14:13:57.670Z\",\"2025-10-31T20:23:18.910Z\",[],[],{\"_18\":2641,\"_20\":2642,\"_22\":2643,\"_24\":25,\"_26\":2644,\"_28\":2645,\"_43\":2651,\"_48\":2652,\"_50\":2653,\"_52\":2654,\"_62\":2655,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-017\",\"SwitchCraft: Agentic AI Model Routing\",\"Customers want to use AI models on Azure to run agentic workloads but want to get the correct answer at the lowest cost. We have built an AI model router for agentic workloads that will select the best model for each incoming agentic tool call. Our model router is a very slim classifier that runs on minimal compute and adds \u003c50ms latency to the incoming request. It is trained on both academic and commercial benchmarks.\\n\\nWith the growth of 1P agentic workloads, we would love to partner with internal teams by applying our router to improve their workload's accuracy and cost.\",\"\u003ciframe src=\\\"https://microsoft.sharepoint.com/teams/MSRNVA01/_layouts/15/embed.aspx?UniqueId=c575eb58-b803-42e6-a02b-ad28be4183df\u0026embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D\u0026referrer=StreamWebApp\u0026referrerScenario=EmbedDialog.Create\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" allowfullscreen title=\\\"58440.mp4\\\"\u003e\u003c/iframe\u003e\",[2646,2647],{\"_31\":943,\"_33\":944,\"_35\":945},{\"_31\":2648,\"_33\":2649,\"_35\":2650,\"_41\":42},\"sagarwal\",\"Sharad Agarwal\",\"sagarwal@microsoft.com\",[],\"2025-10-30T14:13:57.728Z\",\"2025-11-04T02:49:24.359Z\",[],[],{\"_18\":2657,\"_20\":2658,\"_22\":2659,\"_24\":297,\"_26\":27,\"_28\":2660,\"_43\":2669,\"_48\":2670,\"_50\":2671,\"_52\":2672,\"_62\":2673,\"_64\":101,\"_66\":67,\"_68\":102},\"RRS25-PROJ-056\",\"TRAPI - The Research API Proxy\",\"TRAPI provides access to LLMs and other research resources and provides a foundation for managing secure, equitable access.\",[2661,2665],{\"_31\":2662,\"_33\":2663,\"_35\":2664},\"jkl\",\"Jamie Lee\",\"jkl@microsoft.com\",{\"_31\":2666,\"_33\":2667,\"_35\":2668,\"_41\":42},\"jordan\",\"Jordan Boland\",\"jordan@microsoft.com\",[],\"2025-10-30T14:13:58.019Z\",\"2025-10-31T23:09:10.969Z\",[],[],{\"_18\":2675,\"_20\":2676,\"_22\":2677,\"_24\":297,\"_26\":27,\"_28\":2678,\"_43\":2688,\"_48\":2690,\"_50\":2691,\"_52\":2692,\"_62\":2693,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-055\",\"Telemeta: A Copilot for Kusto Telemetry Integration\",\"Onboarding a cloud service to AIOps tools (e.g. automated root-causing) is time-consuming and tedious, requiring extensive effort to write templated integration queries for the tools to extract input data.  This project aims to automate the integration process, specifically for Kusto data sources, by automatically generating the service's integration queries using LLMs.  To do this requires automatically identifying and extracting service-specific semantics from Kusto tables, then using that as input to write semantically-correct queries.\",[2679,2683,2687],{\"_31\":2680,\"_33\":2681,\"_35\":2682,\"_41\":42},\"jonathanmace\",\"Jonathan Mace\",\"jonathanmace@microsoft.com\",{\"_31\":2684,\"_33\":2685,\"_35\":2686},\"petshr\",\"Peter Shrosbree\",\"petshr@microsoft.com\",{\"_31\":170,\"_33\":171,\"_35\":172},[2689],\"Telemetry\",\"2025-10-30T14:13:57.786Z\",\"2025-10-31T16:38:04.368Z\",[],[],{\"_18\":2695,\"_20\":2696,\"_22\":2697,\"_24\":428,\"_26\":2698,\"_28\":2699,\"_43\":2710,\"_48\":2711,\"_50\":2712,\"_52\":2713,\"_62\":2717,\"_64\":101,\"_66\":149,\"_68\":451},\"RRS25-PROJ-062\",\"Textonomy - Next-generation LLM-based Taxonomy Generation Library\",\"This flexible framework enables the generation of taxonomy labels for unstructured data at scale using large language models (LLMs). It is a data type agnostic method that creates clusters tailored to a user’s specific use case and supports hierarchical clustering approach. The system allows customization of iterations, label merging, batch size, and hierarchy depth, enabling adaptation to wide range of use cases, dataset sizes, model versions, and resource limitations.\",\"\u003ciframe src=\\\"https://microsoft.sharepoint.com/teams/MSRNVA01/_layouts/15/embed.aspx?UniqueId=51a2245d-94cd-45a3-b6a5-2b8d012f7c2c\u0026embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D\u0026referrer=StreamWebApp\u0026referrerScenario=EmbedDialog.Create\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" allowfullscreen title=\\\"58418.mp4\\\"\u003e\u003c/iframe\u003e\",[2700,2704,2708,2709],{\"_31\":2701,\"_33\":2702,\"_35\":2703},\"amhoak\",\"Amber Hoak\",\"amhoak@microsoft.com\",{\"_31\":2705,\"_33\":2706,\"_35\":2707},\"datittsw\",\"David Tittsworth\",\"datittsw@microsoft.com\",{\"_31\":1248,\"_33\":1249,\"_35\":1250,\"_41\":42},{\"_31\":1260,\"_33\":1261,\"_35\":1262},[428],\"2025-10-30T14:13:57.844Z\",\"2025-11-01T01:58:36.503Z\",[2714],{\"_55\":285,\"_57\":2715,\"_20\":2716},\"https://aka.ms/textonomy\",\"Textonomy project overview\",[],{\"_18\":2719,\"_20\":2720,\"_22\":2721,\"_24\":25,\"_26\":27,\"_28\":2722,\"_43\":2727,\"_48\":2728,\"_50\":2729,\"_52\":2730,\"_62\":2740,\"_64\":101,\"_66\":67,\"_68\":102},\"RRS25-PROJ-018\",\"Tool-space interference in the MCP era: Designing for agent compatibility at scale\",\"As agentic AI systems increasingly rely on the Model Context Protocol (MCP) to enable horizontal integration of tools and agents across providers, a new class of failure modes—tool-space interference—has emerged, where overlapping tool capabilities, ambiguous naming, divergent states, and bloated schemas undermine multi-agent effectiveness. To systematically characterize and benchmark this problem, we developed and released the MCP Interviewer: an open-source tool that catalogs, tests, and scores MCP servers for agent usability and interoperability. Surveying over 1,400 live servers, we uncovered widespread issues such as tool name collisions, excessive response sizes, deeply nested schemas, and inconsistent error reporting. Based these findings we propose protocol-level fixes, as well as recommendations for server, client, and marketplace developers.\",[2723,2724,2725,2726],{\"_31\":1788,\"_33\":1789,\"_35\":1790,\"_41\":42},{\"_31\":1838,\"_33\":1839,\"_35\":1840},{\"_31\":1846,\"_33\":1847,\"_35\":1848},{\"_31\":1858,\"_33\":1859,\"_35\":1860},[],\"2025-10-30T14:13:57.902Z\",\"2025-10-31T21:58:48.728Z\",[2731,2734,2737],{\"_55\":285,\"_57\":2732,\"_20\":2733},\"https://microsoft.sharepoint.com/teams/MSRNVA01/_layouts/15/stream.aspx?id=%2Fteams%2FMSRNVA01%2FVideos%2F58410%2Emov\u0026referrer=StreamWebApp%2EWeb\u0026referrerScenario=AddressBarCopied%2Eview%2E41ffa9d8%2D34f8%2D4d84%2Da610%2D027e80450fb9\",\"Whiteboard Wednesday Talk\",{\"_55\":60,\"_57\":2735,\"_20\":2736},\"https://github.com/microsoft/mcp-interviewer\",\"MCP Interviewer GitHub repo\",{\"_55\":275,\"_57\":2738,\"_20\":2739},\"https://aka.ms/tool-space-interference\",\"MSR Blog post\",[],{\"_18\":2742,\"_20\":2743,\"_22\":2744,\"_24\":558,\"_26\":2745,\"_28\":2746,\"_43\":2751,\"_48\":2752,\"_50\":2753,\"_52\":2754,\"_62\":2757,\"_64\":101,\"_66\":67,\"_68\":102},\"RRS25-PROJ-091\",\"Towards Secure Coding Agents with FlowGuard\",\"Artificial intelligence (AI) coding agents are autonomous software systems that can perform complex tasks like fixing bugs on behalf of a human operator. Coding agents are already capable and rapidly improving. Today’s best agents consistently resolve 70% of the issues on the SWE-Bench benchmark, compared to only 2% when the benchmark was introduced. But despite this promise, researchers have demonstrated numerous prompt-injection attacks that allow an attacker to lead an agent astray through adversarial inputs. For example, an attacker can post a malicious bug report that instructs an agent with access to private repositories to exfiltrate secret data.\\n\\nFlowGuard is an information flow control (IFC) system for preventing data exfiltration by coding agents and other AI. Unlike prior applications of IFC to AI agents, FlowGuard adopts Flume’s coarse-grained IFC labeling and propagation model, as well as a new spawn primitive that allows an agent to safely create sub-agents. We have implemented a FlowGuard prototype called GitGuard for protecting workflows on GitHub data and will demonstrate how it prevents prompt-injection attacks while also enabling complex coding tasks involving multiple public and private repositories. \",\"\u003ciframe src=\\\"https://microsoft-my.sharepoint.com/personal/lacox_microsoft_com/_layouts/15/embed.aspx?UniqueId=f65944c5-6e91-445d-9754-eabbec1a8b28\u0026embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D\u0026referrer=StreamWebApp\u0026referrerScenario=EmbedDialog.Create\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" allowfullscreen title=\\\"flowguard-demo.mp4\\\"\u003e\u003c/iframe\u003e\",[2747,2748,2749,2750],{\"_31\":1996,\"_33\":1997,\"_35\":1998},{\"_31\":1588,\"_33\":1589,\"_35\":1590,\"_41\":42},{\"_31\":2008,\"_33\":2009,\"_35\":2010},{\"_31\":2243,\"_33\":2242,\"_35\":2244},[],\"2025-10-30T14:13:57.960Z\",\"2025-10-31T23:33:30.705Z\",[2755],{\"_55\":268,\"_57\":2756,\"_20\":27},\"https://microsoft-my.sharepoint.com/personal/jeffrunn_microsoft_com1/Documents/../../../:p:/p/lacox/IQDd4WmpS8HIQZaq8fiUYDTjAaC3YPD65OdO9mPKSuqCqUg?e=kwwhdP\u0026xsdata=MDV8MDJ8di1icmVucG90dHNAbWljcm9zb2Z0LmNvbXwyMmY4OGU3ZWZlZjA0MDc0ZTE1ZjA4ZGUxNjMzODY5YXw3MmY5ODhiZjg2ZjE0MWFmOTFhYjJkN2NkMDExZGI0N3wxfDB8NjM4OTcyNjA3NzA4MTU5MzI5fFVua25vd258VFdGcGJHWnNiM2Q4ZXlKRmJYQjBlVTFoY0draU9uUnlkV1VzSWxZaU9pSXdMakF1TURBd01DSXNJbEFpT2lKWGFXNHpNaUlzSWtGT0lqb2lUV0ZwYkNJc0lsZFVJam95ZlE9PXwwfHx8\u0026sdata=Y0JmZW5jdytrWTJ1ZFZQd0k3ei84VEUvcWFJd1lRR3hSUjVYTVo5Y3NUVT0%3d\",[],{\"_18\":2759,\"_20\":2760,\"_22\":2761,\"_24\":558,\"_26\":27,\"_28\":2762,\"_43\":2766,\"_48\":2767,\"_50\":2768,\"_52\":2769,\"_62\":2770,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-100\",\"Undetectable but Removable Backdoors in Machine Learning Models: Or How to Offer Customer Trust in ML Platform Providers\",\"Recent theoretical results show that ML platform providers can put backdoors in ML models, and that it is computationally infeasible to detect them.  However, there are also theoretical results that show, given certain assumptions about the training data, these backdoors can be avoided by the customer (even without being able to detect them.)  Think about it like washing your hands: you don't know if there are harmful germs on your hands, but you wash them to be safe.\\n\\nThis project evaluates the theory of the threat and feasibility of solutions.  The theory needs to be refined to be more applicable to Microsoft's ML business, but it does provide a potential opportunity to offer our customers more trust.\",[2763,2764],{\"_31\":1951,\"_33\":1952,\"_35\":1953,\"_41\":42},{\"_31\":27,\"_35\":27,\"_33\":2765},\"Junaid Hasan\",[574,575],\"2025-10-30T14:13:58.077Z\",\"2025-11-03T19:23:33.266Z\",[],[],{\"_18\":2772,\"_20\":2773,\"_22\":2774,\"_24\":558,\"_26\":2775,\"_28\":2776,\"_43\":2793,\"_48\":2794,\"_50\":2795,\"_52\":2796,\"_62\":2797,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-101\",\"Unlocking the value of private data with differential privacy\",\"Highly valuable data—such as user interactions with Copilots, emails, and personal documents—is inherently private and cannot be freely accessed or shared. To address this challenge, Private Evolution (PE) has emerged as a leading algorithm for generating synthetic data with formal guarantees of differential privacy, all while avoiding direct training on sensitive content. However, PE has notable limitations: it performs well only on relatively short individual inputs and lacks the capacity to natively incorporate patterns or trends within private datasets into AI models. In this presentation, we introduce PE-SGD, a new algorithm that overcomes both constraints—enabling high-fidelity, scalable, privacy-preserving synthetic data generation and enhancement of AI models, all while still avoiding direct training on sensitive data.\",\"\u003ciframe src=\\\"https://microsoft.sharepoint.com/teams/MSRNVA01/_layouts/15/embed.aspx?UniqueId=d9b16039-7fa2-4252-9974-a4319fead7cc\u0026embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D\u0026referrer=StreamWebApp\u0026referrerScenario=EmbedDialog.Create\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" allowfullscreen title=\\\"58421.mp4\\\"\u003e\u003c/iframe\u003e\",[2777,2781,2785,2789],{\"_31\":2778,\"_33\":2779,\"_35\":2780},\"abackurs\",\"Arturs Backurs\",\"abackurs@microsoft.com\",{\"_31\":2782,\"_33\":2783,\"_35\":2784,\"_41\":42},\"yekhanin\",\"Sergey Yekhanin\",\"yekhanin@microsoft.com\",{\"_31\":2786,\"_33\":2787,\"_35\":2788},\"victorol\",\"Victor Reis\",\"victorol@microsoft.com\",{\"_31\":2790,\"_33\":2791,\"_35\":2792},\"zinanlin\",\"Zinan Lin (MSR)\",\"zinanlin@microsoft.com\",[],\"2025-10-30T14:13:58.133Z\",\"2025-10-31T23:36:40.169Z\",[],[],{\"_18\":2799,\"_20\":2800,\"_22\":2801,\"_24\":456,\"_26\":2802,\"_28\":2803,\"_43\":2809,\"_48\":2810,\"_50\":2811,\"_52\":2812,\"_62\":2816,\"_64\":101,\"_66\":67,\"_68\":102},\"RRS25-PROJ-044\",\"VeriTrail \u0026 Claimify\",\"Claimify extracts factual claims from language model outputs, and VeriTrail detects whether these claims are hallucinated.\",\"\u003ciframe width=\\\"560\\\" height=\\\"315\\\" src=\\\"https://www.youtube.com/embed/pi6Km-vKSVY?si=cRWayUGW1KOxl9In\\\" title=\\\"YouTube video player\\\" frameborder=\\\"0\\\" allow=\\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\\\" referrerpolicy=\\\"strict-origin-when-cross-origin\\\" allowfullscreen\u003e\u003c/iframe\u003e\",[2804,2808],{\"_31\":2805,\"_33\":2806,\"_35\":2807,\"_41\":42},\"dasham\",\"Dasha Metropolitansky\",\"dasham@microsoft.com\",{\"_31\":1166,\"_33\":1167,\"_35\":1168},[467],\"2025-10-30T14:13:58.313Z\",\"2025-11-01T01:53:35.440Z\",[2813],{\"_55\":285,\"_57\":2814,\"_20\":2815},\"https://www.youtube.com/watch?v=pi6Km-vKSVY\",\"Research Talk: VeriTrail\",[],{\"_18\":2818,\"_20\":2819,\"_22\":2820,\"_24\":558,\"_26\":2821,\"_28\":2822,\"_43\":2825,\"_48\":2826,\"_50\":2827,\"_52\":2828,\"_62\":2829,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-102\",\"Verifiable Election Technologies\",\"This project explores new, practical methods to enable voters to confirm that their private (and uncoercible) votes are correctly counted in real elections -- without having to trust any of the election software, hardware, or personnel.\",\"\u003ciframe src=\\\"https://microsoft.sharepoint.com/teams/MSRNVA01/_layouts/15/embed.aspx?UniqueId=97a82b03-d66c-453e-949d-65e3e212b3b9\u0026embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D\u0026referrer=StreamWebApp\u0026referrerScenario=EmbedDialog.Create\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" allowfullscreen title=\\\"58431.mp4\\\"\u003e\u003c/iframe\u003e\",[2823,2824],{\"_31\":1956,\"_33\":1957,\"_35\":1958,\"_41\":42},{\"_31\":1964,\"_33\":1965,\"_35\":1966},[],\"2025-10-30T14:13:58.195Z\",\"2025-11-01T02:33:02.879Z\",[],[],{\"_18\":2831,\"_20\":2832,\"_22\":2833,\"_24\":558,\"_26\":2834,\"_28\":2835,\"_43\":2845,\"_48\":2846,\"_50\":2847,\"_52\":2848,\"_62\":2849,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-103\",\"Verifying cryptographic software with Aeneas and Lean\",\"Microsoft is rewriting its core cryptographic library, SymCrypt, in Rust to eliminate memory safety issues and modernize security. Central to this effort is formal program verification ensuring that implementations are mathematically correct as specified and secure. Using tools like Aeneas and Lean provides a clean separation between code and proofs. Major components of the project are better proof automation and an extended Lean library to prove properties for a wide range of cryptographic algorithms.\",\"\u003ciframe src=\\\"https://microsoft.sharepoint.com/teams/MSRNVA01/_layouts/15/embed.aspx?UniqueId=f77b4b97-5467-4493-86de-c6db05c35a94\u0026embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D\u0026referrer=StreamWebApp\u0026referrerScenario=EmbedDialog.Create\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" allowfullscreen title=\\\"58422.mp4\\\"\u003e\u003c/iframe\u003e\",[2836,2837,2841],{\"_31\":1964,\"_33\":1965,\"_35\":1966,\"_41\":42},{\"_31\":2838,\"_33\":2839,\"_35\":2840},\"t-sonho\",\"Son Ho\",\"t-sonho@microsoft.com\",{\"_33\":2842,\"_31\":2843,\"_35\":2844,\"_41\":6},\"Cedric Fournet\",\"fournet\",\"fournet@microsoft.com\",[],\"2025-10-30T14:13:58.254Z\",\"2025-10-31T23:39:44.467Z\",[],[],{\"_18\":2851,\"_20\":2852,\"_22\":2853,\"_24\":837,\"_26\":27,\"_28\":2854,\"_43\":2863,\"_48\":2864,\"_50\":2865,\"_52\":2866,\"_62\":2867,\"_64\":101,\"_66\":149,\"_68\":150},\"RRS25-PROJ-069\",\"Vibe Gaming: Sketch It, Hear It, Play It\",\"As AI continues to reshape creative workflows, gaming emerges as a powerful medium to explore its full spectrum of capabilities, either through the game creation or playing experience. We move beyond the boundaries of traditional gaming to envision a future where player imagination is the only limit. In this paradigm, games become personal, shaped by the player’s assets, ideas, and interactions. Our research explores diverse AI capabilities, from game personalization to generative behaviors and adaptive mechanics. The demos showcase a range of explorations integrating AI into the gaming pipeline, including audio and video generation, multimodal input interpretation, and dynamic game creation. These examples invite us to rethink the role of AI, not just as a tool, but as a new creative medium for gaming.\",[2855,2856,2857,2858,2859,2860,2861,2862],{\"_31\":586,\"_33\":587,\"_35\":588},{\"_31\":2474,\"_33\":2475,\"_35\":2476},{\"_31\":1040,\"_41\":42,\"_33\":1041,\"_35\":1042},{\"_31\":2416,\"_33\":2415,\"_35\":2417},{\"_31\":530,\"_33\":531,\"_35\":532},{\"_31\":2543,\"_33\":2544,\"_35\":2545},{\"_31\":898,\"_33\":899,\"_35\":900},{\"_31\":1060,\"_33\":1061,\"_35\":1062},[837],\"2025-10-30T14:13:58.371Z\",\"2025-10-31T23:15:48.872Z\",[],[],{\"_18\":2869,\"_20\":2870,\"_22\":2871,\"_24\":837,\"_26\":27,\"_28\":2872,\"_43\":2877,\"_48\":2878,\"_50\":2879,\"_52\":2880,\"_62\":2881,\"_64\":101,\"_66\":149,\"_68\":2882},\"RRS25-PROJ-070\",\"Virtual peers: AI that works with us\",\"We do not want to live in a future where AI is just a tool, or a faceless agent, or our indentured servant. We want to live in a future where AI is a peer, a colleague, a friend, and one day, maybe even family. In the Future Experiences (FX) group, we are not waiting for this future. We are building it now. Come and see.\",[2873,2874,2875,2876],{\"_31\":840,\"_33\":841,\"_35\":842},{\"_31\":860,\"_33\":861,\"_35\":862},{\"_31\":868,\"_33\":869,\"_35\":870},{\"_31\":872,\"_33\":873,\"_35\":874,\"_41\":42},[837],\"2025-10-30T14:13:58.430Z\",\"2025-10-31T16:46:18.217Z\",[],[],\"3300\",{\"_18\":2884,\"_20\":2885,\"_22\":2886,\"_24\":456,\"_26\":2887,\"_28\":2888,\"_43\":2895,\"_48\":2896,\"_50\":2897,\"_52\":2898,\"_62\":2899,\"_64\":101,\"_66\":67,\"_68\":69},\"RRS25-PROJ-045\",\"What is Next After Diffusion and Auto-regressive Models?\",\"The machine learning landscape has seen remarkable advances in generative modeling (e.g., OpenAI’s DALL·E for image generation and ChatGPT for text generation), representation learning (e.g., OpenAI’s CLIP for text and image representation), and classification (e.g., ResNet for image classification). Yet each of these tasks typically relies on separate methods and training objectives.\\n\\nThis raises a natural question: Can one framework unify all three? Part of our motivation comes from Occam’s Razor, which favors simpler solutions whenever possible. More importantly, although these tasks differ in formulation, they share a common goal—extracting patterns from data—and can therefore potentially benefit from one another; a unified principle could facilitate such synergy.\\n\\nOur paper introduces the Latent Zoning Network (LZN) as a step toward this goal. It proposes a single shared latent space that naturally integrates these tasks into one unified framework.\\n\\nEarly experiments highlight the potential of this approach: LZN improves image generation quality over state-of-the-art diffusion models, outperforms seminal unsupervised representation learning methods like MoCo and SimCLR on ImageNet, and achieves competitive classification accuracy on CIFAR-10—all within a single framework. These results point toward a future where one framework can seamlessly handle multiple core ML tasks.\",\"\u003ciframe src=\\\"https://microsoft.sharepoint.com/teams/MSRNVA01/_layouts/15/embed.aspx?UniqueId=fb41496c-bac6-41e4-8196-ac11a129f77f\u0026embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D\u0026referrer=StreamWebApp\u0026referrerScenario=EmbedDialog.Create\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" scrolling=\\\"no\\\" allowfullscreen title=\\\"58414.mp4\\\"\u003e\u003c/iframe\u003e\",[2889,2893,2894],{\"_31\":2890,\"_33\":2891,\"_35\":2892},\"t-liuenshu\",\"Enshu Liu\",\"t-liuenshu@microsoft.com\",{\"_31\":2782,\"_33\":2783,\"_35\":2784},{\"_31\":2790,\"_33\":2791,\"_35\":2792,\"_41\":42},[467],\"2025-10-30T14:13:58.489Z\",\"2025-10-31T16:34:55.271Z\",[],[],{\"_18\":2901,\"_20\":2902,\"_22\":2903,\"_24\":107,\"_26\":27,\"_28\":2904,\"_43\":2913,\"_48\":2915,\"_50\":2916,\"_52\":2917,\"_62\":2918,\"_64\":101,\"_66\":149,\"_68\":150},\"RRS25-PROJ-030\",\"Working with AI: Measuring the Applicability of Generative AI to Occupations\",\"We classify the work activities performed by users in a 9-month sample of Bing Copilot conversations, as well as which are more or less successful. Using the O*NET work taxonomy, we then identify which occupations may find LLM chatbots most useful. We find that knowledge work and communication occupations have the highest overlap between their work tasks and AI capabilities.\",[2905,2906,2907,2908,2909],{\"_31\":1650,\"_33\":1651,\"_35\":1652,\"_41\":42},{\"_31\":2626,\"_33\":2627,\"_35\":2628},{\"_31\":1850,\"_33\":1851,\"_35\":1852},{\"_31\":2630,\"_33\":2631,\"_35\":2632},{\"_31\":2910,\"_33\":2911,\"_35\":2912},\"v-wangwilli\",\"Will Wang (ALLEGIS GROUP HOLDINGS INC)\",\"v-wangwilli@microsoft.com\",[2914],\"Productivity\",\"2025-10-30T14:13:58.576Z\",\"2025-10-31T23:01:55.327Z\",[],[],\"actionData\",\"errors\"]\n");</script><!--$--><script>window.__reactRouterContext.streamController.close();</script><!--/$--><!--/$--><script>$RC=function(b,c,e){c=document.getElementById(c);c.parentNode.removeChild(c);var a=document.getElementById(b);if(a){b=a.previousSibling;if(e)b.data="$!",a.setAttribute("data-dgst",e);else{e=b.parentNode;a=b.nextSibling;var f=0;do{if(a&&8===a.nodeType){var d=a.data;if("/$"===d)if(0===f)break;else f--;else"$"!==d&&"$?"!==d&&"$!"!==d||f++}d=a.nextSibling;e.removeChild(a);a=d}while(a);for(;c.firstChild;)e.insertBefore(c.firstChild,a);b.data="$"}b._reactRetry&&b._reactRetry()}};$RC("B:0","S:0")</script><script>$RC("B:1","S:1")</script></body></html>